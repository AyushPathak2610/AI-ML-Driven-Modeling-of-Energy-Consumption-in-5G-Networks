{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":1964.570467,"end_time":"2023-10-12T12:21:32.098865","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-10-12T11:48:47.528398","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"050531cb","cell_type":"code","source":"!pip install --upgrade plotly plotnine\n\n!pip install fastinference","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:06:02.741616Z","iopub.execute_input":"2024-11-07T10:06:02.741929Z","iopub.status.idle":"2024-11-07T10:07:09.369010Z","shell.execute_reply.started":"2024-11-07T10:06:02.741893Z","shell.execute_reply":"2024-11-07T10:07:09.367524Z"},"papermill":{"duration":0.012319,"end_time":"2023-10-12T11:48:50.586844","exception":false,"start_time":"2023-10-12T11:48:50.574525","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (5.22.0)\nCollecting plotly\n  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: plotnine in /opt/conda/lib/python3.10/site-packages (0.13.6)\nCollecting plotnine\n  Downloading plotnine-0.14.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly) (8.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from plotly) (21.3)\nCollecting matplotlib>=3.8.0 (from plotnine)\n  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: pandas>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from plotnine) (2.2.2)\nCollecting mizani~=0.13.0 (from plotnine)\n  Downloading mizani-0.13.0-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from plotnine) (1.26.4)\nRequirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from plotnine) (1.14.1)\nRequirement already satisfied: statsmodels>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from plotnine) (0.14.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.8.0->plotnine) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.8.0->plotnine) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.8.0->plotnine) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.8.0->plotnine) (1.4.5)\nRequirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.8.0->plotnine) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.8.0->plotnine) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.8.0->plotnine) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.2.0->plotnine) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.2.0->plotnine) (2024.1)\nRequirement already satisfied: patsy>=0.5.6 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.14.0->plotnine) (0.5.6)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.6->statsmodels>=0.14.0->plotnine) (1.16.0)\nDownloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading plotnine-0.14.1-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mizani-0.13.0-py3-none-any.whl (127 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: plotly, matplotlib, mizani, plotnine\n  Attempting uninstall: plotly\n    Found existing installation: plotly 5.22.0\n    Uninstalling plotly-5.22.0:\n      Successfully uninstalled plotly-5.22.0\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.5\n    Uninstalling matplotlib-3.7.5:\n      Successfully uninstalled matplotlib-3.7.5\n  Attempting uninstall: mizani\n    Found existing installation: mizani 0.11.4\n    Uninstalling mizani-0.11.4:\n      Successfully uninstalled mizani-0.11.4\n  Attempting uninstall: plotnine\n    Found existing installation: plotnine 0.13.6\n    Uninstalling plotnine-0.13.6:\n      Successfully uninstalled plotnine-0.13.6\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed matplotlib-3.9.2 mizani-0.13.0 plotly-5.24.1 plotnine-0.14.1\nCollecting fastinference\n  Downloading fastinference-0.0.36-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: fastai>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from fastinference) (2.7.17)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (24.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (21.3)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (0.0.7)\nRequirement already satisfied: fastcore<1.8,>=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (1.7.10)\nRequirement already satisfied: torchvision>=0.11 in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (0.19.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (3.9.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (2.2.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (2.32.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (6.0.2)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (1.0.3)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (10.3.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (1.14.1)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (3.7.6)\nRequirement already satisfied: torch<2.5,>=1.10 in /opt/conda/lib/python3.10/site-packages (from fastai>=2.0.0->fastinference) (2.4.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (0.12.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (4.66.4)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (2.9.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (3.1.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (70.0.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (3.4.1)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai>=2.0.0->fastinference) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->fastai>=2.0.0->fastinference) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->fastai>=2.0.0->fastinference) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fastai>=2.0.0->fastinference) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fastai>=2.0.0->fastinference) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fastai>=2.0.0->fastinference) (2024.8.30)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai>=2.0.0->fastinference) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai>=2.0.0->fastinference) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai>=2.0.0->fastinference) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai>=2.0.0->fastinference) (3.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch<2.5,>=1.10->fastai>=2.0.0->fastinference) (2024.6.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai>=2.0.0->fastinference) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai>=2.0.0->fastinference) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai>=2.0.0->fastinference) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai>=2.0.0->fastinference) (1.4.5)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai>=2.0.0->fastinference) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->fastai>=2.0.0->fastinference) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->fastai>=2.0.0->fastinference) (2024.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fastai>=2.0.0->fastinference) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fastai>=2.0.0->fastinference) (3.5.0)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai>=2.0.0->fastinference) (1.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai>=2.0.0->fastinference) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai>=2.0.0->fastinference) (2.23.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->fastai>=2.0.0->fastinference) (1.16.0)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai>=2.0.0->fastinference) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai>=2.0.0->fastinference) (0.1.4)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.0.0->fastinference) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.0.0->fastinference) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.0.0->fastinference) (13.7.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai>=2.0.0->fastinference) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai>=2.0.0->fastinference) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<4->fastai>=2.0.0->fastinference) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<2.5,>=1.10->fastai>=2.0.0->fastinference) (1.3.0)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai>=2.0.0->fastinference) (1.1.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.0.0->fastinference) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.0.0->fastinference) (2.18.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4->fastai>=2.0.0->fastinference) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai>=2.0.0->fastinference) (0.1.2)\nDownloading fastinference-0.0.36-py3-none-any.whl (30 kB)\nInstalling collected packages: fastinference\nSuccessfully installed fastinference-0.0.36\n","output_type":"stream"}],"execution_count":1},{"id":"d83b08b0","cell_type":"code","source":"import os\n\nimport pickle\n\nimport random\n\nimport warnings\n\nimport numpy as np\n\nimport pandas as pd\n\nimport seaborn as sns\n\nfrom tqdm import tqdm\n\nfrom fastai.tabular.all import * \n\n# from fastinference.tabular import *\n\nfrom sklearn.model_selection import GroupKFold\n\nfrom sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, SplineTransformer\n\n\n\n\n\nimport torch\n\nimport torch.nn as nn\n\nimport torch.optim as optim\n\nimport torch.nn.functional as F\n\nfrom torch.optim import Adam, SGD\n\nfrom torch.autograd import Variable\n\nfrom torch.utils.data import TensorDataset, DataLoader,Dataset\n\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n\n\n\nwarnings.simplefilter(\"ignore\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-11-07T10:08:29.864321Z","iopub.execute_input":"2024-11-07T10:08:29.865075Z","iopub.status.idle":"2024-11-07T10:08:34.544240Z","shell.execute_reply.started":"2024-11-07T10:08:29.865027Z","shell.execute_reply":"2024-11-07T10:08:34.543437Z"},"papermill":{"duration":5.676727,"end_time":"2023-10-12T11:48:56.268296","exception":false,"start_time":"2023-10-12T11:48:50.591569","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":2},{"id":"71e42b23","cell_type":"code","source":"def periodic_spline_transformer(period, n_splines=None, degree=3):\n\n    if n_splines is None:\n\n        n_splines = period\n\n    n_knots = n_splines + 1  # periodic and include_bias is True\n\n    return SplineTransformer(\n\n        degree=degree,\n\n        n_knots=n_knots,\n\n        knots=np.linspace(0, period, n_knots).reshape(n_knots, 1),\n\n        extrapolation=\"periodic\",\n\n        include_bias=True)\n\n\n\ndef seed_everything(seed=42):\n\n    random.seed(seed)\n\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\n#     os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n\n    np.random.seed(seed)\n\n    torch.manual_seed(seed)\n\n    torch.cuda.manual_seed(seed)\n\n    torch.backends.cudnn.deterministic = True\n\n\n\nset_seed(42)\n\nseed_everything(seed=42)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:08:51.422151Z","iopub.execute_input":"2024-11-07T10:08:51.423244Z","iopub.status.idle":"2024-11-07T10:08:51.437045Z","shell.execute_reply.started":"2024-11-07T10:08:51.423201Z","shell.execute_reply":"2024-11-07T10:08:51.436165Z"},"papermill":{"duration":0.020674,"end_time":"2023-10-12T11:48:56.294191","exception":false,"start_time":"2023-10-12T11:48:56.273517","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"id":"fbdaa52e","cell_type":"code","source":"set_seed(42)\n\nseed_everything(seed=42)\n\n\ndf_total = pd.read_csv(\"/kaggle/input/5g-project-data/ECdata.csv\",parse_dates=['Time'])\n\n# df_train = pd.read_csv(\"/kaggle/input/ecm-itu-zindi-kp-data/imgs_2023071012133740345.csv\",parse_dates=['Time'])\n\n# df_test = pd.read_csv(\"/kaggle/input/ecm-itu-zindi-kp-data/imgs_202307101549519358.csv\",parse_dates=['Time'])\n\ndf_cell = pd.read_csv(\"/kaggle/input/5g-project-data/CLdata.csv\",parse_dates=['Time'])\n\ndf_bs = pd.read_csv(\"/kaggle/input/5g-project-data/BSinfo.csv\")\n\ndf_features = df_cell.merge(df_bs,on=['BS','CellName'],how='outer')\n\ndf_features = df_features[df_features['CellName']=='Cell0'].reset_index(drop=True)\n\n# df_test['split'] = 'test'\n\n# df_train['split'] = 'train'\n\n# df_total = pd.concat([df_train,df_test],ignore_index=True)\n\ndf_total = df_total.merge(df_features,on=['BS','Time'],how='left')\n\ndf_total['ID'] = df_total['Time'].astype(str)+\"_\"+df_total['BS']\n\ndf_total['BS'] = df_total['BS'].str.replace(r'[a-zA-Z_]', '', regex=True).astype(int)\n\nfor col in ['RUType','Mode']:\n\n    df_total[col] = df_total[col].str.replace(r'[a-zA-Z]', '', regex=True).astype(int)\n\n\n\ndf_total.sort_values(['BS','Time'], ascending=True,ignore_index=True,inplace=True)\n\ndf_total['day'] = df_total['Time'].dt.day\n\ndf_total['weekday_number'] = df_total['Time'].dt.weekday\n\ndf_total['hour'] = df_total['Time'].dt.hour\n\n\n\nhour_df = df_total[['hour']].copy()\n\nsplines = periodic_spline_transformer(24, n_splines=12).fit_transform(hour_df)\n\nsplines_df = pd.DataFrame(splines,columns=[f\"hour_spline_{i}\" for i in range(splines.shape[1])])\n\ndf_total = pd.concat([df_total,splines_df],axis=1)\n\n\n\ndf_total = df_total.sort_values(['BS','Time'],ascending=True,ignore_index=True)\n\nall_shits = list(np.arange(1,4)) # \n\nfor shift_i in tqdm(all_shits):\n\n    for col in ['load','ESMode1','ESMode2','ESMode3','ESMode6','Time','Energy']:\n\n        df_total[f'{col}_T-{shift_i}'] = df_total.groupby(['BS'])[col].shift(shift_i)        \n\nfor shift_i in tqdm(all_shits):\n\n    df_total[f'Time_T-{shift_i}_hours_elapsed'] = (df_total[f'Time_T-{shift_i}']-df_total['Time']).dt.total_seconds() / 3600\n\n    del df_total[f'Time_T-{shift_i}']\n\nprint(df_total.shape)\n\n\n\nnum_bins = 100\n\ndf_total['load_bin'] = pd.cut(df_total['load'],bins=[round(i,2) for i in list(np.arange(0,1.01,0.01))],labels=[f'{i}' for i in range(num_bins)])\n\ndf_total['load_bin'] = df_total['load_bin'].astype(float).fillna(-1).astype(int)\n\n\n\nprint(df_total.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:18:04.400655Z","iopub.execute_input":"2024-11-07T10:18:04.401276Z","iopub.status.idle":"2024-11-07T10:18:05.897758Z","shell.execute_reply.started":"2024-11-07T10:18:04.401223Z","shell.execute_reply":"2024-11-07T10:18:05.896646Z"},"papermill":{"duration":1.364575,"end_time":"2023-10-12T11:48:57.663500","exception":false,"start_time":"2023-10-12T11:48:56.298925","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 3/3 [00:00<00:00, 35.31it/s]\n100%|██████████| 3/3 [00:00<00:00, 268.69it/s]","output_type":"stream"},{"name":"stdout","text":"(92629, 54)\n(92629, 55)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":4},{"id":"73ae4f4e","cell_type":"code","source":"sns.displot(df_total['Energy'])","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:18:13.672835Z","iopub.execute_input":"2024-11-07T10:18:13.673230Z","iopub.status.idle":"2024-11-07T10:18:14.344417Z","shell.execute_reply.started":"2024-11-07T10:18:13.673189Z","shell.execute_reply":"2024-11-07T10:18:14.343364Z"},"papermill":{"duration":0.563225,"end_time":"2023-10-12T11:48:58.231945","exception":false,"start_time":"2023-10-12T11:48:57.668720","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<seaborn.axisgrid.FacetGrid at 0x79c673b302e0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 500x500 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAekAAAHpCAYAAACmzsSXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxBUlEQVR4nO3dfVzVdZ7//ycXclDwgEKA5BWGgxdpeZVSbZPliMa0NdrO2JpDZZkuOqn7S3Mzx2xbXds0K8ptKnW3XKvZckpMM027IlOS8qJIBifdCMghOGIKevh8/3DO+XEUlYsDnzecx/12O7fbOZ/P+3x4fd4FTz8X7887yLIsSwAAwDjBdhcAAADqRkgDAGAoQhoAAEMR0gAAGIqQBgDAUIQ0AACGIqQBADAUIV0PlmXJ5XKJIeUAgJZESNfDsWPHFBUVpWPHjtldCgAggBDSAAAYipAGAMBQhDQAAIYipAEAMBQhDQCAoQhpAAAMRUgDAGAoQhoAAEMR0gAAGIqQBgDAUIQ0AACGIqQBADAUIQ0AgKEIaQAADEVIAwBgKEIaAABDEdIAABiKkAYAwFChdheAwOF2u1VQUOD9nJycrJCQEBsrAgCzEdJoMQUFBZqSla2I2EQdP1qk5zPTlZKSYndZAGAsQhotKiI2Uc6EHnaXAQCtAtekAQAwFCENAIChCGkAAAxFSAMAYChCGgAAQxHSAAAYipAGAMBQhDQAAIYipAEAMBQhDQCAoQhpAAAMRUgDAGAoQhoAAEMR0gAAGIqQBgDAUIQ0AACGIqQBADAUIQ0AgKEIaQAADEVIAwBgKEIaAABDEdIAABiKkAYAwFCENAAAhiKkAQAwFCENAIChCGkAAAxFSAMAYChCGgAAQxHSAAAYipAGAMBQhDQAAIYipAEAMBQhDQCAoQhpAAAMRUgDAGAoQhoAAEOF2l0AApNVU6PCwkJJUnJyskJCQmyuCADMw5E0bHG8rFgL1+dpSla2CgoK7C4HAIzEkTRsExGTqPBwh91lAICxOJIGAMBQhDQAAIYipAEAMBQhDQCAoQhpAAAMRUgDAGAoQhoAAEMR0gAAGIqQBgDAUMaE9JIlSxQUFKSZM2d6l508eVKZmZmKiYlRZGSkxo8fr5KSEp/vHT58WOnp6erQoYPi4uL0wAMP6PTp0z5ttm/frsGDB8vhcCg5OVmrV69ugT0CAKBpjAjpXbt26T//8z81cOBAn+WzZs3S22+/rddff107duxQUVGRxo0b513vdruVnp6u6upqffLJJ1qzZo1Wr16tBQsWeNscOnRI6enpGjlypPLy8jRz5kzdc8892rx5c4vtHwAAjWF7SFdWVmrixIn6wx/+oE6dOnmXV1RU6MUXX9SyZct0ww03aMiQIVq1apU++eQTffrpp5Kkd999VwcOHNDLL7+sK6+8UmPHjtWjjz6qrKwsVVdXS5JWrlyppKQkPfHEE+rbt6+mT5+u2267TcuXL7dlfwEAqC/bQzozM1Pp6ekaNWqUz/Lc3FydOnXKZ3mfPn3UvXt35eTkSJJycnI0YMAAxcfHe9ukpaXJ5XJp//793jZnbzstLc27jbpUVVXJ5XL5vAAAaGm2zoK1bt06ff7559q1a9c564qLixUWFqbo6Gif5fHx8SouLva2qR3QnvWedRdq43K5dOLECbVv3/6cn7148WI98sgjjd4vAAD8wbYj6SNHjuj+++/XK6+8ovDwcLvKqNO8efNUUVHhfR05csTukgAAAci2kM7NzVVpaakGDx6s0NBQhYaGaseOHXrqqacUGhqq+Ph4VVdXq7y83Od7JSUlSkhIkCQlJCScc7e35/PF2jidzjqPoiXJ4XDI6XT6vAAAaGm2hfSNN96ovXv3Ki8vz/saOnSoJk6c6H3frl07bd261fud/Px8HT58WKmpqZKk1NRU7d27V6Wlpd42W7ZskdPpVL9+/bxtam/D08azDQAATGXbNemOHTvq8ssv91kWERGhmJgY7/LJkydr9uzZ6ty5s5xOp2bMmKHU1FSNGDFCkjR69Gj169dPkyZN0tKlS1VcXKz58+crMzNTDodDkjR16lQ988wzmjNnju6++25t27ZNr732mrKzs1t2hwEAaCBbbxy7mOXLlys4OFjjx49XVVWV0tLS9Oyzz3rXh4SEaMOGDZo2bZpSU1MVERGhjIwMLVq0yNsmKSlJ2dnZmjVrllasWKGuXbvqhRdeUFpamh27BABAvQVZlmXZXYTpXC6XoqKiVFFRwfXpJsjPz9esV/fImdBDRftyFBoZo/Bwh5b/ZpBSUlLsLg8AjGP7OGkAAFA3QhoAAEMR0gAAGIqQBgDAUIQ0AACGIqQBADAUIQ0AgKEIaQAADEVIAwBgKEIaAABDEdIAABiKkAYAwFCENAAAhiKkAQAwFCENAIChCGkAAAxFSAMAYChCGgAAQxHSAAAYipAGAMBQhDQAAIYipAEAMBQhDQCAoQhpAAAMRUgDAGAoQhoAAEMR0gAAGIqQBgDAUIQ0AACGIqQBADAUIQ0AgKEIaQAADEVIAwBgKEIaAABDhdpdANo2t9utgoICSVJhYaEsy+aCAKAVIaTRrAoKCjQlK1sRsYn64WCeOnbra3dJANBqcLobzS4iNlHOhB5q3ynO7lIAoFUhpAEAMBQhDQCAoQhpAAAMxY1jsJVVU6PCwkLv5+TkZIWEhNhYEQCYg5CGrY6XFWvh+m8Vc2mFjh8t0vOZ6UpJSbG7LAAwAiEN20XEnLn7GwDgi2vSAAAYipAGAMBQhDQAAIYipAEAMBQhDQCAoQhpAAAMRUgDAGAoQhoAAEMR0gAAGIqQBgDAUIQ0AACGIqQBADAUIQ0AgKEIaQAADEVIAwBgKEIaAABDEdIAABiKkAYAwFCENAAAhiKkAQAwFCENAIChCGkAAAxFSAMAYChCGgAAQxHSAAAYipAGAMBQhDQAAIYipAEAMBQhDQCAoQhpAAAMRUgDAGAoQhoAAEMR0gAAGIqQBgDAULaG9HPPPaeBAwfK6XTK6XQqNTVV77zzjnf9yZMnlZmZqZiYGEVGRmr8+PEqKSnx2cbhw4eVnp6uDh06KC4uTg888IBOnz7t02b79u0aPHiwHA6HkpOTtXr16pbYPTSQVVOjwsJC5efnKz8/X2632+6SAMBWtoZ0165dtWTJEuXm5mr37t264YYbdMstt2j//v2SpFmzZuntt9/W66+/rh07dqioqEjjxo3zft/tdis9PV3V1dX65JNPtGbNGq1evVoLFizwtjl06JDS09M1cuRI5eXlaebMmbrnnnu0efPmFt9fXNjxsmItXJ+nWa/u0ZSsbBUUFEg689/ZE9yEN4BAEmRZlmV3EbV17txZjz/+uG677TZdcsklWrt2rW677TZJ0tdff62+ffsqJydHI0aM0DvvvKNf/vKXKioqUnx8vCRp5cqVmjt3rn744QeFhYVp7ty5ys7O1r59+7w/Y8KECSovL9emTZvqVZPL5VJUVJQqKirkdDr9v9NtWH5+vma9ukfOhB4q2pej0MgYxfX8mff96cq/nrMsrufP5Cr+Vst/M0gpKSnKz8/XlKxsRcQm6vjRIj2fma6UlBS7dw0Amp0x16TdbrfWrVun48ePKzU1Vbm5uTp16pRGjRrlbdOnTx91795dOTk5kqScnBwNGDDAG9CSlJaWJpfL5T0az8nJ8dmGp41nG3WpqqqSy+XyecFeEbGJcib0UERsot2lAECLsT2k9+7dq8jISDkcDk2dOlVvvvmm+vXrp+LiYoWFhSk6OtqnfXx8vIqLiyVJxcXFPgHtWe9Zd6E2LpdLJ06cqLOmxYsXKyoqyvvq1q2bP3YVAIAGsT2kU1JSlJeXp507d2ratGnKyMjQgQMHbK1p3rx5qqio8L6OHDliaz0AgMAUancBYWFhSk5OliQNGTJEu3bt0ooVK/Sb3/xG1dXVKi8v9zmaLikpUUJCgiQpISFBn332mc/2PHd/125z9h3hJSUlcjqdat++fZ01ORwOORwOv+wfAACNZfuR9NlqampUVVWlIUOGqF27dtq6dat3XX5+vg4fPqzU1FRJUmpqqvbu3avS0lJvmy1btsjpdKpfv37eNrW34Wnj2Qb8r/bd2IWFhTLr1kQAaD1sPZKeN2+exo4dq+7du+vYsWNau3attm/frs2bNysqKkqTJ0/W7Nmz1blzZzmdTs2YMUOpqakaMWKEJGn06NHq16+fJk2apKVLl6q4uFjz589XZmam90h46tSpeuaZZzRnzhzdfffd2rZtm1577TVlZ2fbuettWkFBgfdu7B8O5qljt752lwQArZKtIV1aWqrf/va3+v777xUVFaWBAwdq8+bN+sUvfiFJWr58uYKDgzV+/HhVVVUpLS1Nzz77rPf7ISEh2rBhg6ZNm6bU1FRFREQoIyNDixYt8rZJSkpSdna2Zs2apRUrVqhr16564YUXlJaW1uL7G0g8d2NXHi2yuxQAaLVsDekXX3zxguvDw8OVlZWlrKys87bp0aOHNm7ceMHtXH/99dqzZ0+jagQAwC7GXZMGAABnENIAABjK9iFYQF08k21I4g5xAAGLkIaRzky28a1iLq3gDnEAAYvT3TBWRMyZO8Tbd4qzuxQAsAUhDQCAoQhpAAAMRUgDAGAoQhoAAEMR0gAAGIqQBgDAUIQ0AACGIqQBADAUIQ0AgKEIaQAADEVIAwBgKEIaAABDEdIAABiKkAYAwFCENAAAhiKkAQAwFCENAIChCGkAAAxFSAMAYChCGgAAQxHSAAAYqlEh3atXL/31r389Z3l5ebl69erV5KIAAEAjQ/ovf/mL3G73Ocurqqr03XffNbkoAAAghTak8VtvveV9v3nzZkVFRXk/u91ubd26VT179vRbcQAABLIGhfStt94qSQoKClJGRobPunbt2qlnz5564okn/FYcAACBrEEhXVNTI0lKSkrSrl27FBsb2yxFAQCABoa0x6FDh/xdBwAAOEujQlqStm7dqq1bt6q0tNR7hO3x0ksvNbkwAAACXaNC+pFHHtGiRYs0dOhQdenSRUFBQf6uCwCAgNeokF65cqVWr16tSZMm+bseAADwN40aJ11dXa2rr77a37UAAIBaGhXS99xzj9auXevvWgAAQC2NOt198uRJPf/883rvvfc0cOBAtWvXzmf9smXL/FIcAACBrFEh/eWXX+rKK6+UJO3bt89nHTeRAQDgH40K6ffff9/fdQAAgLMwVSUAAIZq1JH0yJEjL3hae9u2bY0uCAAAnNGokPZcj/Y4deqU8vLytG/fvnMm3gD8yaqpUWFhofdzcnKyQkJCbKwIAJpPo0J6+fLldS5fuHChKisrm1QQcCHHy4q1cP23irm0QsePFun5zHSlpKTYXRYANAu/XpO+4447eG43ml1ETKKcCT0UEZtodykA0Kz8GtI5OTkKDw/35yYBAAhYjTrdPW7cOJ/PlmXp+++/1+7du/Xwww/7pTAAAAJdo0I6KirK53NwcLBSUlK0aNEijR492i+FAQAQ6BoV0qtWrfJ3HQAA4CyNCmmP3NxcffXVV5Kk/v37a9CgQX4pCgAANDKkS0tLNWHCBG3fvl3R0dGSpPLyco0cOVLr1q3TJZdc4s8aAQAISI26u3vGjBk6duyY9u/fr7KyMpWVlWnfvn1yuVz63e9+5+8aAQAISI06kt60aZPee+899e3b17usX79+ysrK4sYxAAD8pFFH0jU1NefMIS1J7dq1U01NTZOLAgAAjQzpG264Qffff7+Kioq8y7777jvNmjVLN954o9+KAwAgkDUqpJ955hm5XC717NlTl112mS677DIlJSXJ5XLp6aef9neNAAAEpEZdk+7WrZs+//xzvffee/r6668lSX379tWoUaP8WhwAAIGsQUfS27ZtU79+/eRyuRQUFKRf/OIXmjFjhmbMmKFhw4apf//++vDDD5urVgAAAkqDQvrJJ5/UvffeK6fTec66qKgo3XfffVq2bJnfigMAIJA1KKS/+OILjRkz5rzrR48erdzc3CYXBQAAGhjSJSUldQ698ggNDdUPP/zQ5KIAAEADQ/rSSy/Vvn37zrv+yy+/VJcuXZpcFMzjdruVn5+v/Px8ud1uu8sBgIDQoJC+6aab9PDDD+vkyZPnrDtx4oR+//vf65e//KXfioM5CgoKNCUrW1OyslVQUGB3OQAQEBo0BGv+/Pl644039LOf/UzTp09XSkqKJOnrr79WVlaW3G63HnrooWYpFPaLiE20uwQACCgNCun4+Hh98sknmjZtmubNmyfLsiRJQUFBSktLU1ZWluLj45ulUOBsVk2NCgsLvZ+Tk5MVEhJiY0UA4F8NfphJjx49tHHjRv34448qKCiQZVnq3bu3OnXq1Bz1Aed1vKxYC9d/q5hLK3T8aJGez0z3nt0BgLagUU8ck6ROnTpp2LBh/qwFaLCImEQ5E3rYXQYANItGPbsbAAA0P0IaAABDEdIAABiKkAYAwFCENAAAhiKkAQAwFCENAIChCGkAAAxFSAMAYChCGgAAQ9ka0osXL9awYcPUsWNHxcXF6dZbb1V+fr5Pm5MnTyozM1MxMTGKjIzU+PHjVVJS4tPm8OHDSk9PV4cOHRQXF6cHHnhAp0+f9mmzfft2DR48WA6HQ8nJyVq9enVz7x5akGeyDea7BtCW2BrSO3bsUGZmpj799FNt2bJFp06d0ujRo3X8+HFvm1mzZuntt9/W66+/rh07dqioqEjjxo3zrne73UpPT1d1dbU++eQTrVmzRqtXr9aCBQu8bQ4dOqT09HSNHDlSeXl5mjlzpu655x5t3ry5RfcXzefMZBt5zHcNoE1p9AQb/rBp0yafz6tXr1ZcXJxyc3N13XXXqaKiQi+++KLWrl2rG264QZK0atUq9e3bV59++qlGjBihd999VwcOHNB7772n+Ph4XXnllXr00Uc1d+5cLVy4UGFhYVq5cqWSkpL0xBNPSJL69u2rjz76SMuXL1daWlqL7zeaR0RMosLDHXaXAQB+Y9Q16YqKCklS586dJUm5ubk6deqURo0a5W3Tp08fde/eXTk5OZKknJwcDRgwwGce67S0NLlcLu3fv9/bpvY2PG082zhbVVWVXC6XzwsAgJZmTEjX1NRo5syZuuaaa3T55ZdLkoqLixUWFqbo6GiftvHx8SouLva2qR3QnvWedRdq43K5dOLEiXNqWbx4saKioryvbt26+WUfAQBoCGNCOjMzU/v27dO6devsLkXz5s1TRUWF93XkyBG7SwIABCBbr0l7TJ8+XRs2bNAHH3ygrl27epcnJCSourpa5eXlPkfTJSUlSkhI8Lb57LPPfLbnufu7dpuz7wgvKSmR0+lU+/btz6nH4XDI4eDaJgDAXrYeSVuWpenTp+vNN9/Utm3blJSU5LN+yJAhateunbZu3epdlp+fr8OHDys1NVWSlJqaqr1796q0tNTbZsuWLXI6nerXr5+3Te1teNp4toG2o/ZQLIZjAWjtbD2SzszM1Nq1a/WnP/1JHTt29F5DjoqKUvv27RUVFaXJkydr9uzZ6ty5s5xOp2bMmKHU1FSNGDFCkjR69Gj169dPkyZN0tKlS1VcXKz58+crMzPTezQ8depUPfPMM5ozZ47uvvtubdu2Ta+99pqys7Nt23c0jzNDsb5VzKUVOn60SM9npislJcXusgCgUWwN6eeee06SdP311/ssX7Vqle68805J0vLlyxUcHKzx48erqqpKaWlpevbZZ71tQ0JCtGHDBk2bNk2pqamKiIhQRkaGFi1a5G2TlJSk7OxszZo1SytWrFDXrl31wgsvMPyqjYqISZQzoYfdZQBAk9ka0pZlXbRNeHi4srKylJWVdd42PXr00MaNGy+4neuvv1579uxpcI1oG9xut89DTpKTkxUSEmJjRQBwcUbcOAY0t4KCAk3JylZEbCKnwQG0GoQ0AkZELKfBAbQuxoyTBgAAvghpAAAMRUgDAGAoQhoAAEMR0gAAGIqQBgDAUIQ0AACGIqQBADAUIQ0AgKF44hjwN7Wf7+2Z4jIkJITnfAOwDSGNNsszt7QkFRYW6mLzudR+vvcPB/MU3CFK4Q4Hz/kGYBtCGm1W7bmlfziYp47d+l70O57ne1ceLVJoZIzCwx0tUCkA1I1r0mjTPHNLt+8UZ3cpANBghDQAAIYipAEAMBQhDQCAoQhpAAAMxd3dwAXUHsYliTHTAFoUIQ1cQO1hXMePFjFmGkCLIqSBi/AM4wKAlsY1aQAADMWRNAJa7ed11+fRoQDQkghpBLSzn9ddn0eHAkBLIaQR8Go/r7u+ah+BS9z1DaB5ENJAI9Q+AueubwDNhZBGwGnoFJbn4zkCB4DmQkgj4DRmCksAsAMh3UbVvmbK9dJzecY+N+Q6NAC0NMZJt1Gea6ZTsrJ9bnACALQeHEm3YRGxiXaXAABoAo6kAQAwFCENAIChON0NHzykAwDMQUjDBw/pAABzENI4h+chHXU99CMoyObiACCAENI4r7oe+hEe7rC7LAAIGNw4hgvyPPSjfac4u0sBgIBDSAMAYChCGgAAQxHSAAAYihvHgHry1xSXAFBfhDRQT0xxCaClcbobaADudgfQkghpAAAMRUgDAGAoQhoAAEMR0gAAGIqQBgDAUIQ0AACGIqQBADAUIQ0AgKEIaQAADEVIAwBgKJ7dDTRR7Yk3JCk5OVkhISE2VgSgrSCkgSaqPfHG8aNFej4zXSkpKXaXBaANIKQBP/BMvAEA/kRIwy/cbrcKCgokMdcyAPgLIQ2/KCgo0JSsbEXEJjLXMgD4CXd3w28iYplrGQD8iSNpNAh3MgNAyyGk0SDcyQwALYeQRoNxJzMAtAyuSQMAYChCGgAAQxHSAAAYipAGAMBQhDQAAIYipAEAMBQhDQCAoQhpAAAMRUgDAGAoQhoAAEPxWFDAj5iABIA/EdKAHzEBCQB/IqQBP/NMQMJRNYCmsvWa9AcffKCbb75ZiYmJCgoK0vr1633WW5alBQsWqEuXLmrfvr1GjRqlgwcP+rQpKyvTxIkT5XQ6FR0drcmTJ6uystKnzZdffqm/+7u/U3h4uLp166alS5c2964BfzuqztOsV/doSla2CgoK7C4JQCtja0gfP35cV1xxhbKysupcv3TpUj311FNauXKldu7cqYiICKWlpenkyZPeNhMnTtT+/fu1ZcsWbdiwQR988IGmTJniXe9yuTR69Gj16NFDubm5evzxx7Vw4UI9//zzzb5/gOeoOiI2sUV/rtvtVn5+vvfldrtb9OcD8A9bT3ePHTtWY8eOrXOdZVl68sknNX/+fN1yyy2SpP/6r/9SfHy81q9frwkTJuirr77Spk2btGvXLg0dOlSS9PTTT+umm27Sf/zHfygxMVGvvPKKqqur9dJLLyksLEz9+/dXXl6eli1b5hPmQFtSUFCgKVnZiohN5No40IoZOwTr0KFDKi4u1qhRo7zLoqKiNHz4cOXk5EiScnJyFB0d7Q1oSRo1apSCg4O1c+dOb5vrrrtOYWFh3jZpaWnKz8/Xjz/+WOfPrqqqksvl8nkBrU1ErD1H8QD8x9iQLi4uliTFx8f7LI+Pj/euKy4uVlxcnM/60NBQde7c2adNXduo/TPOtnjxYkVFRXlf3bp1a/oOAQDQQMaGtJ3mzZuniooK7+vIkSN2l4Q2jmvIAOpi7BCshIQESVJJSYm6dOniXV5SUqIrr7zS26a0tNTne6dPn1ZZWZn3+wkJCSopKfFp4/nsaXM2h8Mhh8Phl/0A6oNryADqYuyRdFJSkhISErR161bvMpfLpZ07dyo1NVWSlJqaqvLycuXm5nrbbNu2TTU1NRo+fLi3zQcffKBTp05522zZskUpKSnq1KlTC+0NcHFcQwZwNltDurKyUnl5ecrLy5N05maxvLw8HT58WEFBQZo5c6b+9V//VW+99Zb27t2r3/72t0pMTNStt94qSerbt6/GjBmje++9V5999pk+/vhjTZ8+XRMmTFBi4pk/dP/4j/+osLAwTZ48Wfv379err76qFStWaPbs2TbtNQAA9WPr6e7du3dr5MiR3s+e4MzIyNDq1as1Z84cHT9+XFOmTFF5ebmuvfZabdq0SeHh4d7vvPLKK5o+fbpuvPFGBQcHa/z48Xrqqae866OiovTuu+8qMzNTQ4YMUWxsrBYsWMDwK7Rqbrfb+3AUnmQGtF22hvT1118vy7LOuz4oKEiLFi3SokWLztumc+fOWrt27QV/zsCBA/Xhhx82uk7AX2qHq1R3wNZ+nKjnBrKQkBCf94WFhVq88SsFBYnr10AbZuyNY0Bb4gleT7hGXnL+G8RqT9Lxw8E8BXeIUsylSee879itr8LDucERaMsIaaAFeIK35qcKdezWV86EHhds73mcaOXRIoVGxtT5HkDbR0ij0Wqfli0sLNQFrlxAZ4L3NEP7ADQAId3GNed0iWeflu3Yra9fthso/PGPHKbDBNo2QrqNqx2kzfGQjNqnZdEw/vhHTu1tVJb+n+al91evXr04swG0EYR0APAEKczjj3/k1N7GwvV5nNkA2hBjnzgGoOE8gd2+U9zFGwMwHiENAIChCGkAAAxFSAMAYChCGgAAQxHSAAAYipAGAMBQjJMG2jieSga0XoQ00MY191PnADQfQhoIADx1DmiduCYNAIChOJKG3G63CgoKJDHlZCCp/d9duvC16oa0BeA/hDRUUFCgKVnZiohNZGKGNu7s6TEXb/xKkZckXvRade3/R7iuDbQcQhqSpIhYppwMBHVNj1nfa9We/0cAtByuSQMBhpmygNaDkAYAwFCc7gbgc62am8IAc3AkDeBv16rzNCUr2+cubgD24kgagKQz16rDwx3Ntn2GcQENR0gDaBEM4wIajpAG4FX72rTb7ZYkhYSE+O0hNwzjAhqGkAbgdfY46uAOUYq5NKleD7nhdDbgf4Q0AB+ecdSVR4sUGhlT74fccDob8D9CGkCDXGh+as/pbIZ0Af5BSAeQC/1xBeqr9inxytL/07z0/urVq5fPdWtPm3DHVxxRA01ASAeQ2n9cOR2Jpqh9Snzh+jyfZ4HXbtOcQ7qAQEBIBxjPH1fAX2oHNgD/IqQBNJuzp8ZkrnKgYQhpAM2mrqkxAdQfz+4G0KyYGhNoPEIaAABDEdIAABiKa9IBiht6YCfG7AP1Q0gHKG7ogZ0Ysw/UDyEdwBjfCjsxZh+4OEIagK3Od+r7YrNqMesWAgEhDcBW5zv1fbFZtZh1C4GAkAZgu/Od+vbMqnXe711kPdDaEdIAjMGoA8AXIQ3AGIw6AHzxMBMARuExosD/j5AGAMBQnO5uQ2oPSeF6HgC0foR0G1J7SArX8wCg9eN0dxvjGZLC9Ty0JZ67vvPz8+V2u+0uB2gxhDQA45256ztPU7KyfZ4yBrR1nO4G0CpExCTKEdaOcdQIKIQ0gFaDcdQINJzuBtCqMI4agYSQBgDAUJzuBtCmMIUl2hJCGkCbwhSWaEsIaQCt3tmzZ3X423Xr2ssljqrR+hDSAFq98931XXs5R9VojQhpAG2C567vyqNFdS7nqBqtESENICDUPqquLP0/zUvvr169ekkisGEuQhpAwKh9tL1wfZ5PYPfo0UOSvGFNcMMEhDSAgHR2YNf8tEPBHaIUc2kS169hDEIaQMCLiEnUaYdDoZExcib0sLscwIsnjgEAYCiOpAHgLNwJDlMQ0gBwFsZXwxSENADUoa7x1W63WxJ3gKPlENIAcAFnP83Mcwc4Y63REghpALiI2sO1PHeA1zXWmsCGvxHSANBIdT0cxXMNOzk5mSkz0WSENAD4wdnXsAsLC7V441eKvIQpM9F4hHQrwUT2QOvguYZd81OFOnbry+QeaBJCupVgInug9fA8wcyjPpN78A9x1IWQbkUiYhPPeWRh7V/swsJCWZYdlQG4mAtN7tGrVy9Oj6NOhHQrVPvUWe1f7NqT3QMwV12B7fn9Pd/YbA/PUbfnvcRRd1sWUCGdlZWlxx9/XMXFxbriiiv09NNP66qrrrK7rAY7e9ym5xf77MnuAZivdmB71DU2u+anCu8Y7fON164d3hd770HQmy1gQvrVV1/V7NmztXLlSg0fPlxPPvmk0tLSlJ+fr7i4OLvLa7C6frEBtB1nj82uPUvX+cZr1w7vi72vHfrnC3rp4uHtueTmr6P72pfw+IdDAIX0smXLdO+99+quu+6SJK1cuVLZ2dl66aWX9OCDD7ZYHdwcAsDfzvewlQu9Pzv06wr6+hyley65nSgvbfLRfe3tyapp9DYudubgfG0l8/4mB0RIV1dXKzc3V/PmzfMuCw4O1qhRo5STk3NO+6qqKlVVVXk/V1RUSJJcLleTazl48KAmL1mt9tGX6ET5D3p4wvXq2bPnRb/3l7/8RRVFhTp18idVlhxR8LEKhch90fc1P7nq3Zbtsb1A215rqrXZt9fBqVMnf5K7ukpW6Mkzf2t++E7/38oCOeMS9ePhbxQSHlnn+8jEy1TTiO9dcHs/uZq0jbPfu09WXrRtff8m9+7du8lZ4NGxY0cFBQWdd31AhPTRo0fldrsVHx/vszw+Pl5ff/31Oe0XL16sRx555Jzl3bp183ttt/3xGb9vEwDQOC39N7miokJOp/O86wMipBtq3rx5mj17tvdzTU2NysrKFBMTc8F/8ZyPy+VSt27ddOTIkQv+xwh09FP90Vf1Qz/VD/1Uf/7uq44dO15wfUCEdGxsrEJCQlRSUuKzvKSkRAkJCee0dzgcctR6EIEkRUdHN7kOp9PJL0A90E/1R1/VD/1UP/RT/bVUXwU3+08wQFhYmIYMGaKtW7d6l9XU1Gjr1q1KTU21sTIAAM4vII6kJWn27NnKyMjQ0KFDddVVV+nJJ5/U8ePHvXd7AwBgmoAJ6d/85jf64YcftGDBAhUXF+vKK6/Upk2bzrmZrDk4HA79/ve/P+cUOnzRT/VHX9UP/VQ/9FP9tXRfBVkWT3sGAMBEAXFNGgCA1oiQBgDAUIQ0AACGIqQBADAUId0CsrKy1LNnT4WHh2v48OH67LPP7C7JVosXL9awYcPUsWNHxcXF6dZbb1V+fr5Pm5MnTyozM1MxMTGKjIzU+PHjz3kYTaBZsmSJgoKCNHPmTO8y+umM7777TnfccYdiYmLUvn17DRgwQLt37/autyxLCxYsUJcuXdS+fXuNGjVKBw8etLHilud2u/Xwww8rKSlJ7du312WXXaZHH31Ute8dDtR++uCDD3TzzTcrMTFRQUFBWr9+vc/6+vRLWVmZJk6cKKfTqejoaE2ePFmVlZVNL85Cs1q3bp0VFhZmvfTSS9b+/fute++914qOjrZKSkrsLs02aWlp1qpVq6x9+/ZZeXl51k033WR1797dqqys9LaZOnWq1a1bN2vr1q3W7t27rREjRlhXX321jVXb67PPPrN69uxpDRw40Lr//vu9y+knyyorK7N69Ohh3XnnndbOnTutwsJCa/PmzVZBQYG3zZIlS6yoqChr/fr11hdffGH9/d//vZWUlGSdOHHCxspb1mOPPWbFxMRYGzZssA4dOmS9/vrrVmRkpLVixQpvm0Dtp40bN1oPPfSQ9cYbb1iSrDfffNNnfX36ZcyYMdYVV1xhffrpp9aHH35oJScnW7fffnuTayOkm9lVV11lZWZmej+73W4rMTHRWrx4sY1VmaW0tNSSZO3YscOyLMsqLy+32rVrZ73++uveNl999ZUlycrJybGrTNscO3bM6t27t7Vlyxbr5z//uTek6acz5s6da1177bXnXV9TU2MlJCRYjz/+uHdZeXm55XA4rP/5n/9piRKNkJ6ebt19990+y8aNG2dNnDjRsiz6yePskK5Pvxw4cMCSZO3atcvb5p133rGCgoKs7777rkn1cLq7GXmmyBw1apR32YWmyAxUnqlAO3fuLEnKzc3VqVOnfPqtT58+6t69e0D2W2ZmptLT0336Q6KfPN566y0NHTpU//AP/6C4uDgNGjRIf/jDH7zrDx06pOLiYp9+ioqK0vDhwwOqn66++mpt3bpV33zzjSTpiy++0EcffaSxY8dKop/Opz79kpOTo+joaA0dOtTbZtSoUQoODtbOnTub9PMD5oljdmjoFJmBqKamRjNnztQ111yjyy+/XJJUXFyssLCwcyY1iY+PV3FxsQ1V2mfdunX6/PPPtWvXrnPW0U9nFBYW6rnnntPs2bP1L//yL9q1a5d+97vfKSwsTBkZGd6+qOv3MJD66cEHH5TL5VKfPn0UEhIit9utxx57TBMnTpQk+uk86tMvxcXFiouL81kfGhqqzp07N7nvCGnYKjMzU/v27dNHH31kdynGOXLkiO6//35t2bJF4eHhdpdjrJqaGg0dOlT/9m//JkkaNGiQ9u3bp5UrVyojI8Pm6szx2muv6ZVXXtHatWvVv39/5eXlaebMmUpMTKSfDMbp7mbU0CkyA8306dO1YcMGvf/+++ratat3eUJCgqqrq1VeXu7TPtD6LTc3V6WlpRo8eLBCQ0MVGhqqHTt26KmnnlJoaKji4+PpJ0ldunRRv379fJb17dtXhw8fliRvXwT67+EDDzygBx98UBMmTNCAAQM0adIkzZo1S4sXL5ZEP51PffolISFBpaWlPutPnz6tsrKyJvcdId2MmCKzbpZlafr06XrzzTe1bds2JSUl+awfMmSI2rVr59Nv+fn5Onz4cED124033qi9e/cqLy/P+xo6dKgmTpzofU8/Sddcc805Q/i++eYb9ejRQ5KUlJSkhIQEn35yuVzauXNnQPXTTz/9pOBg3z/5ISEhqqmpkUQ/nU99+iU1NVXl5eXKzc31ttm2bZtqamo0fPjwphXQpNvOcFHr1q2zHA6HtXr1auvAgQPWlClTrOjoaKu4uNju0mwzbdo0Kyoqytq+fbv1/fffe18//fSTt83UqVOt7t27W9u2bbN2795tpaamWqmpqTZWbYbad3dbFv1kWWeGp4WGhlqPPfaYdfDgQeuVV16xOnToYL388sveNkuWLLGio6OtP/3pT9aXX35p3XLLLQExtKi2jIwM69JLL/UOwXrjjTes2NhYa86cOd42gdpPx44ds/bs2WPt2bPHkmQtW7bM2rNnj/Xtt99allW/fhkzZow1aNAga+fOndZHH31k9e7dmyFYrcXTTz9tde/e3QoLC7Ouuuoq69NPP7W7JFtJqvO1atUqb5sTJ05Y//RP/2R16tTJ6tChg/WrX/3K+v777+0r2hBnhzT9dMbbb79tXX755ZbD4bD69OljPf/88z7ra2pqrIcfftiKj4+3HA6HdeONN1r5+fk2VWsPl8tl3X///Vb37t2t8PBwq1evXtZDDz1kVVVVedsEaj+9//77df5NysjIsCyrfv3y17/+1br99tutyMhIy+l0WnfddZd17NixJtfGVJUAABiKa9IAABiKkAYAwFCENAAAhiKkAQAwFCENAIChCGkAAAxFSAMAYChCGgAAQxHSAAAYipAGAtCdd96poKCgc15jxoyxuzQAtTCfNBCgxowZo1WrVvksczgczfbzqqurFRYW1mzbB9oijqSBAOVwOJSQkODz6tSpkyQpKChIL7zwgn71q1+pQ4cO6t27t9566y2f7+/bt09jx45VZGSk4uPjNWnSJB09etS7/vrrr9f06dM1c+ZMxcbGKi0tTZL01ltvqXfv3goPD9fIkSO1Zs0aBQUFqby8XMePH5fT6dQf//hHn5+1fv16RURE6NixY83cK4BZCGkAdXrkkUf061//Wl9++aVuuukmTZw4UWVlZZKk8vJy3XDDDRo0aJB2796tTZs2qaSkRL/+9a99trFmzRqFhYXp448/1sqVK3Xo0CHddtttuvXWW/XFF1/ovvvu00MPPeRtHxERoQkTJpxzhL9q1Srddttt6tixY/PvOGCSJs+jBaDVycjIsEJCQqyIiAif12OPPWZZ1pnpROfPn+9tX1lZaUmy3nnnHcuyLOvRRx+1Ro8e7bPNI0eOWJK8U/j9/Oc/twYNGuTTZu7cudbll1/us+yhhx6yJFk//vijZVmWtXPnTiskJMQqKiqyLMuySkpKrNDQUGv79u3+6wCgleCaNBCgRo4cqeeee85nWefOnb3vBw4c6H0fEREhp9Op0tJSSdIXX3yh999/X5GRkeds989//rN+9rOfSZKGDBnisy4/P1/Dhg3zWXbVVVed87l///5as2aNHnzwQb388svq0aOHrrvuukbsJdC6EdJAgIqIiFBycvJ517dr187nc1BQkGpqaiRJlZWVuvnmm/Xv//7v53yvS5cuPj+jMe655x5lZWXpwQcf1KpVq3TXXXcpKCioUdsCWjNCGkCDDR48WP/7v/+rnj17KjS0/n9GUlJStHHjRp9lu3btOqfdHXfcoTlz5uipp57SgQMHlJGR0eSagdaIG8eAAFVVVaXi4mKfV+27sy8kMzNTZWVluv3227Vr1y79+c9/1ubNm3XXXXfJ7Xaf93v33Xefvv76a82dO1fffPONXnvtNa1evVqSfI6UO3XqpHHjxumBBx7Q6NGj1bVr1ybtK9BaEdJAgNq0aZO6dOni87r22mvr9d3ExER9/PHHcrvdGj16tAYMGKCZM2cqOjpawcHn/7OSlJSkP/7xj3rjjTc0cOBAPffcc967u88eoz158mRVV1fr7rvvbvxOAq1ckGVZlt1FAAhcjz32mFauXKkjR474LP/v//5vzZo1S0VFRTwEBQGLa9IAWtSzzz6rYcOGKSYmRh9//LEef/xxTZ8+3bv+p59+0vfff68lS5bovvvuI6AR0DjdDaBFHTx4ULfccov69eunRx99VP/8z/+shQsXetcvXbpUffr0UUJCgubNm2dfoYABON0NAIChOJIGAMBQhDQAAIYipAEAMBQhDQCAoQhpAAAMRUgDAGAoQhoAAEMR0gAAGOr/AfVNTvDqMmczAAAAAElFTkSuQmCC"},"metadata":{}}],"execution_count":5},{"id":"d44ca917","cell_type":"code","source":"df_total.groupby(['Time'])[['Energy']].mean().plot()","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:18:28.201089Z","iopub.execute_input":"2024-11-07T10:18:28.201490Z","iopub.status.idle":"2024-11-07T10:18:28.512751Z","shell.execute_reply.started":"2024-11-07T10:18:28.201451Z","shell.execute_reply":"2024-11-07T10:18:28.511603Z"},"papermill":{"duration":0.268094,"end_time":"2023-10-12T11:48:58.505511","exception":false,"start_time":"2023-10-12T11:48:58.237417","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<Axes: xlabel='Time'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":6},{"id":"ce67b176","cell_type":"code","source":"df_total.groupby(['load'])[[\"Energy\"]].mean().plot()","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:18:28.791011Z","iopub.execute_input":"2024-11-07T10:18:28.791411Z","iopub.status.idle":"2024-11-07T10:18:29.558599Z","shell.execute_reply.started":"2024-11-07T10:18:28.791373Z","shell.execute_reply":"2024-11-07T10:18:29.557460Z"},"papermill":{"duration":0.661038,"end_time":"2023-10-12T11:48:59.172802","exception":false,"start_time":"2023-10-12T11:48:58.511764","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<Axes: xlabel='load'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":7},{"id":"e443bb02","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom scipy.signal import savgol_filter as sg\nfrom scipy.signal import sosfiltfilt, butter, sosfilt, sosfilt_zi\n\n# Seed setting functions (for reproducibility)\ndef set_seed(seed):\n    np.random.seed(seed)\n    import random\n    random.seed(seed)\n    import torch\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    import tensorflow as tf\n    tf.random.set_seed(seed)\n\ndef seed_everything(seed=42):\n    set_seed(seed)\n    print(f\"Seed set to {seed}\")\n\n# Call the function to set seed\nset_seed(42)\nseed_everything(42)\n\n# Savitzky-Golay Filter function\ndef add_sg(df):\n    w = 5  # Window length\n    p = 3  # Polynomial order\n\n    for si in tqdm(df.BS.unique()):\n        index = df.BS == si\n\n        # Ensure window size does not exceed the size of the data\n        group_size = len(df.loc[index, 'load'])\n        if group_size >= w:\n            df.loc[index, 'load_smooth'] = sg(df.loc[index, 'load'], w, p)\n            df.loc[index, 'load_diff'] = sg(df.loc[index, 'load'], w, p, 1)\n            df.loc[index, 'load_diff2'] = sg(df.loc[index, 'load'], w, p, 2)\n            df.loc[index, 'load_diff3'] = sg(df.loc[index, 'load'], w, p, 3)\n        else:\n            print(f\"Skipping BS {si} because its data length ({group_size}) is smaller than window length {w}.\")\n\n# Apply the Savitzky-Golay filter\nadd_sg(df_total)\nprint(df_total.shape)\n\n# SOS Filter function\ndef add_sosfiltfilt(df):\n    for si in tqdm(df.BS.unique()):\n        index = df.BS == si\n\n        # Check the length of the data for this group\n        group_size = len(df.loc[index, 'load'])\n        \n        # Skip groups with insufficient data for filtering\n        if group_size > 15:\n            # Define the filter coefficients\n            sos = butter(4, 0.125, output='sos')  # 4th order low-pass filter\n            sos8 = butter(8, 0.125, output='sos')  # 8th order low-pass filter\n\n            # Apply sosfiltfilt (which handles initial conditions automatically)\n            df.loc[index, 'load_sosfiltfilt'] = sosfiltfilt(sos, df.loc[index, 'load'])\n\n            # Apply sosfilt with initial condition using sos8\n            zi = np.array(df.loc[index, 'load'][:4]).mean() * sosfilt_zi(sos8)  # Calculate initial condition\n            df.loc[index, 'load_sosfilt'], _ = sosfilt(sos8, df.loc[index, 'load'], zi=zi)\n        else:\n            print(f\"Skipping BS {si} because its data length ({group_size}) is smaller than required for filtering.\")\n\n# Apply the SOS filter\nadd_sosfiltfilt(df_total)\nprint(df_total.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:22:53.802202Z","iopub.execute_input":"2024-11-07T10:22:53.802666Z","iopub.status.idle":"2024-11-07T10:23:03.743127Z","shell.execute_reply.started":"2024-11-07T10:22:53.802621Z","shell.execute_reply":"2024-11-07T10:23:03.741976Z"},"papermill":{"duration":11.450701,"end_time":"2023-10-12T11:49:10.630693","exception":false,"start_time":"2023-10-12T11:48:59.179992","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Seed set to 42\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▎| 865/923 [00:04<00:00, 180.61it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping BS 835 because its data length (1) is smaller than window length 5.\nSkipping BS 854 because its data length (1) is smaller than window length 5.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 923/923 [00:05<00:00, 173.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"(92629, 61)\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 860/923 [00:04<00:00, 206.20it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping BS 835 because its data length (1) is smaller than required for filtering.\nSkipping BS 854 because its data length (1) is smaller than required for filtering.\nSkipping BS 905 because its data length (13) is smaller than required for filtering.\nSkipping BS 921 because its data length (14) is smaller than required for filtering.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 923/923 [00:04<00:00, 201.49it/s]","output_type":"stream"},{"name":"stdout","text":"(92629, 61)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"id":"4d63c427-2ed1-47ce-8d27-423c30b09f99","cell_type":"code","source":"X = df_total.drop('Energy', axis=1)\ny = df_total['Energy']\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=42)\ntrain_df = pd.concat([X_train, y_train], axis=1)\ntest_df = pd.concat([X_test, y_test], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T10:29:19.806623Z","iopub.execute_input":"2024-11-07T10:29:19.807522Z","iopub.status.idle":"2024-11-07T10:29:20.003812Z","shell.execute_reply.started":"2024-11-07T10:29:19.807469Z","shell.execute_reply":"2024-11-07T10:29:20.002790Z"}},"outputs":[],"execution_count":13},{"id":"970f297e","cell_type":"code","source":"set_seed(42)\n\nseed_everything(seed=42)\n\n\n\ndf_total.drop(columns=['CellName','ESMode4','Time'],inplace=True)\n\n\n\nid_variable = 'ID'\n\nversion_nb = 'v4'\n\nTARGET = 'Energy'\n\n\n\n# train_df = df_total[df_total['split']=='train'].reset_index(drop=True)\n\n# test_df = df_total[df_total['split']=='test'].reset_index(drop=True)\n\ntrain_cols = [i for i in train_df if i not in ['Time','CellName','ID','Energy','split','w','BS','ESMode6']]\n\n\n\ncategorical_cols = ['RUType','Mode','load_bin']\n\n\n\nprint(train_df[train_cols].shape, test_df[train_cols].shape)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:29:41.230698Z","iopub.execute_input":"2024-11-07T10:29:41.231100Z","iopub.status.idle":"2024-11-07T10:29:41.281866Z","shell.execute_reply.started":"2024-11-07T10:29:41.231060Z","shell.execute_reply":"2024-11-07T10:29:41.280840Z"},"papermill":{"duration":0.176732,"end_time":"2023-10-12T11:49:10.819189","exception":false,"start_time":"2023-10-12T11:49:10.642457","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Seed set to 42\n(62061, 55) (30568, 55)\n","output_type":"stream"}],"execution_count":14},{"id":"c9ba0895","cell_type":"code","source":"set_seed(42)\n\nseed_everything(seed=42)\n\n\n\nremove_non_unique_cols = []\n\nprint('train single values ..')\n\nfor col in train_df:\n\n    if col in train_cols and col not in ['ESMode5']:\n\n        if train_df[col].nunique()<=1:\n\n            remove_non_unique_cols.append(col)\n\n            print(col,\":\",train_df[col].nunique())\n\nprint('test single values ..')\n\nfor col in test_df:\n\n    if col in train_cols and col not in ['ESMode5']:\n\n        if test_df[col].nunique()<=1:\n\n            remove_non_unique_cols.append(col)\n\n            print(col,\":\",test_df[col].nunique())\n\n\n\nprint('\\n',remove_non_unique_cols)\n\n\n\nfor col in train_df:\n\n    if col in train_cols:\n\n        if train_df[col].isnull().sum()/len(train_df)>=0.95:\n\n            print(col,\":\",train_df[col].isnull().sum()/len(train_df))\n\n            remove_non_unique_cols.append(col)\n\n\n\nfor col in test_df:\n\n    if col in train_cols:\n\n        if test_df[col].isnull().sum()/len(test_df)>=0.95:\n\n            print(col,\":\",test_df[col].isnull().sum()/len(test_df))\n\n            remove_non_unique_cols.append(col)\n\n            \n\nprint(len(train_cols))\n\ntrain_cols = [col for col in train_cols if col not in remove_non_unique_cols]\n\nprint(len(train_cols))\n\nprint(train_cols)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:29:52.191203Z","iopub.execute_input":"2024-11-07T10:29:52.191586Z","iopub.status.idle":"2024-11-07T10:29:52.298886Z","shell.execute_reply.started":"2024-11-07T10:29:52.191548Z","shell.execute_reply":"2024-11-07T10:29:52.297780Z"},"papermill":{"duration":0.130431,"end_time":"2023-10-12T11:49:10.961947","exception":false,"start_time":"2023-10-12T11:49:10.831516","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Seed set to 42\ntrain single values ..\nESMode4 : 1\ntest single values ..\nESMode4 : 1\n\n ['ESMode4', 'ESMode4']\n55\n54\n['load', 'ESMode1', 'ESMode2', 'ESMode3', 'ESMode5', 'RUType', 'Mode', 'Frequency', 'Bandwidth', 'Antennas', 'TXpower', 'day', 'weekday_number', 'hour', 'hour_spline_0', 'hour_spline_1', 'hour_spline_2', 'hour_spline_3', 'hour_spline_4', 'hour_spline_5', 'hour_spline_6', 'hour_spline_7', 'hour_spline_8', 'hour_spline_9', 'hour_spline_10', 'hour_spline_11', 'load_T-1', 'ESMode1_T-1', 'ESMode2_T-1', 'ESMode3_T-1', 'ESMode6_T-1', 'Energy_T-1', 'load_T-2', 'ESMode1_T-2', 'ESMode2_T-2', 'ESMode3_T-2', 'ESMode6_T-2', 'Energy_T-2', 'load_T-3', 'ESMode1_T-3', 'ESMode2_T-3', 'ESMode3_T-3', 'ESMode6_T-3', 'Energy_T-3', 'Time_T-1_hours_elapsed', 'Time_T-2_hours_elapsed', 'Time_T-3_hours_elapsed', 'load_bin', 'load_smooth', 'load_diff', 'load_diff2', 'load_diff3', 'load_sosfiltfilt', 'load_sosfilt']\n","output_type":"stream"}],"execution_count":15},{"id":"4cb52cf9","cell_type":"code","source":"from sklearn.model_selection import GroupKFold\n\n# Ensure that 'train_df' has an integer index (or reset it if needed)\ntrain_df = train_df.reset_index(drop=True)\n\n# Prepare the GroupKFold\nNfold = 10\ntrain_df['fold'] = -1  # Initialize a new 'fold' column\nstrafy_bin = train_df['BS'].astype('int')  # Assuming 'BS' is the stratification column\n\nskf = GroupKFold(n_splits=Nfold)\n\n# GroupKFold split\nfor i, (_, train_index) in enumerate(skf.split(train_df, train_df, groups=strafy_bin)):\n    train_df.iloc[train_index, train_df.columns.get_loc('fold')] = i  # Use iloc to set the fold\n\n# Now train_df has a 'fold' column with fold numbers assigned to each row.\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:33:36.625878Z","iopub.execute_input":"2024-11-07T10:33:36.626298Z","iopub.status.idle":"2024-11-07T10:33:36.679586Z","shell.execute_reply.started":"2024-11-07T10:33:36.626260Z","shell.execute_reply":"2024-11-07T10:33:36.678697Z"},"papermill":{"duration":0.03948,"end_time":"2023-10-12T11:49:11.014197","exception":false,"start_time":"2023-10-12T11:49:10.974717","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":17},{"id":"49944ca9","cell_type":"markdown","source":"### FastAI model","metadata":{"papermill":{"duration":0.011295,"end_time":"2023-10-12T11:49:11.037638","exception":false,"start_time":"2023-10-12T11:49:11.026343","status":"completed"},"tags":[]}},{"id":"6cc2c861","cell_type":"code","source":"set_seed(42)\n\nseed_everything(seed=42)\n\n\n\ndef mae(preds, targs):\n\n    x = (targs-preds)\n\n    return (abs(x)).mean()\n\n\n\ndef mape(preds, targs):\n\n    x = (targs-preds)/targs\n\n    return (abs(x)).mean()\n\n\n\ndef fit_fastai(Nfolds, train_df, test_df, train_cols, cat_feats, TARGET, model_path):\n\n    \n\n    oof_pred_fastai = np.zeros(train_df.shape[0], dtype=np.float32)\n\n    pred_fastai = np.zeros(test_df.shape[0], dtype=np.float32)\n\n    scores = []\n\n    scores_pvt = []\n\n    \n\n    train_df_fast = train_df[train_cols + [TARGET]].copy()\n\n    test_df = test_df.copy()\n\n    for col in train_df_fast.columns:\n\n        if col not in cat_feats:\n\n            train_df_fast[col] = train_df_fast[col].fillna(0)\n\n            test_df[col] = test_df[col].fillna(0)\n\n        else:\n\n            # Impute missing categorical values with the most frequent category\n\n            most_frequent_category = train_df_fast[col].mode().iloc[0]\n\n            train_df_fast[col] = train_df_fast[col].fillna(most_frequent_category)\n\n            test_df[col] = test_df[col].fillna(most_frequent_category)\n\n\n\n    train_df_fast[cat_feats] = train_df_fast[cat_feats].astype('category')\n\n    test_df[cat_feats] = test_df[cat_feats].astype('category')\n\n    \n\n    cont_nn = train_cols.copy()\n\n    for col in cat_feats:\n\n        cont_nn.remove(col)\n\n\n\n    cat_nn = cat_feats\n\n\n\n    layers =  [256, 512, 1024, 512, 256] #[256, 512, 1024, 512, 256]\n\n\n\n    val_pct, tst_preds = L(), L()\n\n\n\n    for fold in range(Nfolds):\n\n        print(\"*\"*10, f'Fold-{fold+1}', \"*\"*10)\n\n        train_idx = train_df.loc[train_df['fold']!=fold, :].index\n\n        valid_idx = train_df.loc[train_df['fold']==fold, :].index\n\n        splits = (L(list(train_idx)), L(list(valid_idx)))\n\n        dls = TabularPandas(train_df_fast, [Categorify, Normalize], cat_nn, cont_nn, splits = splits, y_names=TARGET,reduce_memory=False).dataloaders(1024)\n\n        learn = tabular_learner(dls, layers=layers, n_out=1, y_range = (0,100),loss_func = mae, metrics=AccumMetric(mae))\n\n#         print(learn.summary())\n\n#         learn.lr_find(suggest_funcs=(slide, valley))\n\n#         if os.path.isfile(model_path + f'models/nn_model_{fold}.pth'):\n\n#             learn = tabular_learner(dls, layers=layers, n_out=1, path = model_path)\n\n#             learn.load(f'nn_model_{fold}')\n\n#         else:\n\n        learn.fit_one_cycle(100, 2e-3, cbs=SaveModelCallback(monitor='mae', comp=np.less, fname=f'nn_model_{fold}'))\n\n\n\n        val_df = train_df.loc[train_df['fold']==fold]\n\n        val_dl = dls.test_dl(val_df[train_cols].fillna(0))\n\n        \n\n        preds, _ = learn.get_preds(dl=val_dl)\n\n        oof_pred_fastai[val_df.index] = preds.squeeze().numpy()\n\n       \n\n        score = mean_absolute_error(val_df[TARGET], oof_pred_fastai[val_df.index])\n\n        score_pvt = mean_absolute_percentage_error(val_df[TARGET], oof_pred_fastai[val_df.index])\n\n        \n\n        scores.append(score)\n\n        scores_pvt.append(score_pvt)\n\n        print(f'MAE for Fold-{fold+1}:', np.round(score, 3))\n\n        print(f'MAPE for Fold-{fold+1}:', np.round(score_pvt, 3))\n\n        \n\n        test_dl = dls.test_dl(test_df[train_cols])\n\n        preds, _ = learn.get_preds(dl=test_dl)\n\n        pred_fastai += preds.squeeze().numpy()/Nfolds\n\n\n\n#         display(test_df[train_cols].iloc[-5:])\n\n        \n\n#         exp = ShapInterpretation(learn, test_df[train_cols].iloc[-5:])\n\n#         exp.summary_plot()\n\n\n\n\n\n    score = mean_absolute_error(train_df[TARGET],oof_pred_fastai)\n\n    score_pvt = mean_absolute_percentage_error(train_df[TARGET],oof_pred_fastai)\n\n    \n\n    print(f'OOF MAE:', np.round(score, 3))\n\n    print(f'Average MAE:', f'{np.round(np.mean(scores), 3)}+/-{np.round(np.std(scores), 3)}')\n\n    \n\n    print(f'OOF MAPE:', np.round(score_pvt, 3))\n\n    print(f'Average MAPE:', f'{np.round(np.mean(scores_pvt), 3)}+/-{np.round(np.std(scores_pvt), 3)}')\n\n\n\n    return oof_pred_fastai, pred_fastai","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:33:55.383589Z","iopub.execute_input":"2024-11-07T10:33:55.384588Z","iopub.status.idle":"2024-11-07T10:33:55.410294Z","shell.execute_reply.started":"2024-11-07T10:33:55.384531Z","shell.execute_reply":"2024-11-07T10:33:55.409312Z"},"papermill":{"duration":0.029383,"end_time":"2023-10-12T11:49:11.079035","exception":false,"start_time":"2023-10-12T11:49:11.049652","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Seed set to 42\n","output_type":"stream"}],"execution_count":19},{"id":"a2b3b33e","cell_type":"code","source":"set_seed(42)\n\nseed_everything(seed=42)\n\n\n\nif Inference:\n\n    model_path = '../input/ecm-output-of-final-notebook/'\n\nelse:\n\n    model_path = './'\n\n\n\noof_pred_fastai, pred_fastai = fit_fastai(Nfold, train_df, test_df, train_cols, categorical_cols, TARGET, model_path)\n\n\n\ntrain_df = train_df.copy()\n\ntrain_df['oof_fastai'] = oof_pred_fastai","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:33:59.942038Z","iopub.execute_input":"2024-11-07T10:33:59.942509Z","iopub.status.idle":"2024-11-07T10:49:20.079084Z","shell.execute_reply.started":"2024-11-07T10:33:59.942463Z","shell.execute_reply":"2024-11-07T10:49:20.078017Z"},"papermill":{"duration":1008.822813,"end_time":"2023-10-12T12:05:59.912892","exception":false,"start_time":"2023-10-12T11:49:11.090079","status":"completed"},"tags":[],"trusted":true,"scrolled":true},"outputs":[{"name":"stdout","text":"Seed set to 42\n********** Fold-1 **********\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>mae</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>10.871793</td>\n      <td>6.981629</td>\n      <td>6.981629</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>7.674756</td>\n      <td>5.015224</td>\n      <td>5.015224</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6.064980</td>\n      <td>4.211987</td>\n      <td>4.211987</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5.069690</td>\n      <td>4.023963</td>\n      <td>4.023963</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.573433</td>\n      <td>3.565450</td>\n      <td>3.565450</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3.912013</td>\n      <td>2.988676</td>\n      <td>2.988676</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.798877</td>\n      <td>3.523429</td>\n      <td>3.523428</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.842104</td>\n      <td>2.931347</td>\n      <td>2.931347</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.587103</td>\n      <td>2.927865</td>\n      <td>2.927865</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>3.281593</td>\n      <td>2.382771</td>\n      <td>2.382771</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>3.093468</td>\n      <td>2.761848</td>\n      <td>2.761848</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.988611</td>\n      <td>2.355639</td>\n      <td>2.355639</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>3.112067</td>\n      <td>2.644483</td>\n      <td>2.644482</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.761216</td>\n      <td>2.390311</td>\n      <td>2.390311</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.591733</td>\n      <td>2.141882</td>\n      <td>2.141882</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.404871</td>\n      <td>1.715352</td>\n      <td>1.715352</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.091924</td>\n      <td>2.041990</td>\n      <td>2.041990</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.774736</td>\n      <td>1.826501</td>\n      <td>1.826501</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.623114</td>\n      <td>1.736015</td>\n      <td>1.736015</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.500053</td>\n      <td>1.581826</td>\n      <td>1.581826</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.466037</td>\n      <td>1.653912</td>\n      <td>1.653913</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.366934</td>\n      <td>1.240247</td>\n      <td>1.240247</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.316557</td>\n      <td>1.375099</td>\n      <td>1.375099</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.334483</td>\n      <td>1.362828</td>\n      <td>1.362828</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.352556</td>\n      <td>1.333201</td>\n      <td>1.333201</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.401873</td>\n      <td>1.937309</td>\n      <td>1.937309</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.404367</td>\n      <td>1.285494</td>\n      <td>1.285494</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.317695</td>\n      <td>1.457888</td>\n      <td>1.457888</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.318569</td>\n      <td>1.478671</td>\n      <td>1.478671</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.246558</td>\n      <td>1.229596</td>\n      <td>1.229596</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.229592</td>\n      <td>1.224745</td>\n      <td>1.224745</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.225916</td>\n      <td>1.218982</td>\n      <td>1.218982</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.198089</td>\n      <td>1.573539</td>\n      <td>1.573539</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>1.277792</td>\n      <td>1.243692</td>\n      <td>1.243692</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.233805</td>\n      <td>1.345127</td>\n      <td>1.345127</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.219732</td>\n      <td>1.355142</td>\n      <td>1.355142</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>1.170422</td>\n      <td>1.608741</td>\n      <td>1.608741</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>1.202297</td>\n      <td>1.320704</td>\n      <td>1.320705</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>1.205071</td>\n      <td>1.415063</td>\n      <td>1.415062</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.243802</td>\n      <td>1.374251</td>\n      <td>1.374251</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.249442</td>\n      <td>1.369257</td>\n      <td>1.369258</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>1.232687</td>\n      <td>1.404428</td>\n      <td>1.404427</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>1.187122</td>\n      <td>1.245565</td>\n      <td>1.245565</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>1.152378</td>\n      <td>1.115143</td>\n      <td>1.115143</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>1.152610</td>\n      <td>1.409097</td>\n      <td>1.409097</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.127617</td>\n      <td>1.258345</td>\n      <td>1.258345</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>1.156142</td>\n      <td>1.593846</td>\n      <td>1.593846</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>1.142622</td>\n      <td>1.310055</td>\n      <td>1.310055</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>1.108181</td>\n      <td>1.091933</td>\n      <td>1.091933</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>1.099622</td>\n      <td>1.114686</td>\n      <td>1.114686</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.103360</td>\n      <td>2.816753</td>\n      <td>2.816753</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>1.079398</td>\n      <td>1.070818</td>\n      <td>1.070817</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>1.142468</td>\n      <td>1.322142</td>\n      <td>1.322142</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>1.103179</td>\n      <td>1.183115</td>\n      <td>1.183115</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>1.126161</td>\n      <td>1.128343</td>\n      <td>1.128343</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.138128</td>\n      <td>1.074653</td>\n      <td>1.074653</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>1.071579</td>\n      <td>1.055831</td>\n      <td>1.055831</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>1.056752</td>\n      <td>1.113135</td>\n      <td>1.113135</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>1.059212</td>\n      <td>1.198784</td>\n      <td>1.198784</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>1.032499</td>\n      <td>1.136674</td>\n      <td>1.136674</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.041556</td>\n      <td>1.068335</td>\n      <td>1.068335</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>1.037018</td>\n      <td>1.072439</td>\n      <td>1.072439</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.979112</td>\n      <td>1.080275</td>\n      <td>1.080275</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>1.005951</td>\n      <td>1.038486</td>\n      <td>1.038486</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>1.029697</td>\n      <td>1.017487</td>\n      <td>1.017487</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.999849</td>\n      <td>1.456024</td>\n      <td>1.456024</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>1.029702</td>\n      <td>1.023106</td>\n      <td>1.023106</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>1.001618</td>\n      <td>1.029766</td>\n      <td>1.029766</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.995534</td>\n      <td>1.057027</td>\n      <td>1.057027</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.991726</td>\n      <td>1.056304</td>\n      <td>1.056304</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.954624</td>\n      <td>0.999610</td>\n      <td>0.999610</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.953361</td>\n      <td>1.044527</td>\n      <td>1.044527</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.950700</td>\n      <td>1.024659</td>\n      <td>1.024659</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.947750</td>\n      <td>1.045998</td>\n      <td>1.045998</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.937824</td>\n      <td>1.015543</td>\n      <td>1.015543</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.952088</td>\n      <td>0.995585</td>\n      <td>0.995585</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.927268</td>\n      <td>1.067384</td>\n      <td>1.067384</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.924174</td>\n      <td>1.033053</td>\n      <td>1.033053</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.916686</td>\n      <td>1.007815</td>\n      <td>1.007815</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.908912</td>\n      <td>0.980994</td>\n      <td>0.980994</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.899184</td>\n      <td>1.002374</td>\n      <td>1.002374</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.874484</td>\n      <td>0.997045</td>\n      <td>0.997045</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.908141</td>\n      <td>1.001312</td>\n      <td>1.001312</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.897142</td>\n      <td>1.038943</td>\n      <td>1.038943</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.876243</td>\n      <td>0.967078</td>\n      <td>0.967078</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.867222</td>\n      <td>0.983817</td>\n      <td>0.983817</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.857850</td>\n      <td>0.978038</td>\n      <td>0.978038</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.859100</td>\n      <td>0.968603</td>\n      <td>0.968603</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.889441</td>\n      <td>1.029162</td>\n      <td>1.029162</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.867074</td>\n      <td>0.988747</td>\n      <td>0.988747</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.868254</td>\n      <td>0.982322</td>\n      <td>0.982322</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.860411</td>\n      <td>0.985093</td>\n      <td>0.985093</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.863684</td>\n      <td>0.972012</td>\n      <td>0.972012</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.853615</td>\n      <td>0.996198</td>\n      <td>0.996198</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.826991</td>\n      <td>0.964262</td>\n      <td>0.964262</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.852585</td>\n      <td>0.993053</td>\n      <td>0.993053</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.849039</td>\n      <td>0.985836</td>\n      <td>0.985836</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.857152</td>\n      <td>0.998081</td>\n      <td>0.998081</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.829168</td>\n      <td>0.971396</td>\n      <td>0.971396</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.838816</td>\n      <td>0.974070</td>\n      <td>0.974070</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"Better model found at epoch 0 with mae value: 6.981629371643066.\nBetter model found at epoch 1 with mae value: 5.015223503112793.\nBetter model found at epoch 2 with mae value: 4.211986541748047.\nBetter model found at epoch 3 with mae value: 4.023963451385498.\nBetter model found at epoch 4 with mae value: 3.5654501914978027.\nBetter model found at epoch 5 with mae value: 2.988676071166992.\nBetter model found at epoch 7 with mae value: 2.931346893310547.\nBetter model found at epoch 8 with mae value: 2.9278647899627686.\nBetter model found at epoch 9 with mae value: 2.382770538330078.\nBetter model found at epoch 11 with mae value: 2.3556385040283203.\nBetter model found at epoch 14 with mae value: 2.1418817043304443.\nBetter model found at epoch 15 with mae value: 1.7153517007827759.\nBetter model found at epoch 19 with mae value: 1.5818257331848145.\nBetter model found at epoch 21 with mae value: 1.2402467727661133.\nBetter model found at epoch 29 with mae value: 1.2295960187911987.\nBetter model found at epoch 30 with mae value: 1.2247451543807983.\nBetter model found at epoch 31 with mae value: 1.2189817428588867.\nBetter model found at epoch 43 with mae value: 1.115142583847046.\nBetter model found at epoch 48 with mae value: 1.0919333696365356.\nBetter model found at epoch 51 with mae value: 1.070817470550537.\nBetter model found at epoch 56 with mae value: 1.0558308362960815.\nBetter model found at epoch 63 with mae value: 1.0384855270385742.\nBetter model found at epoch 64 with mae value: 1.017486572265625.\nBetter model found at epoch 70 with mae value: 0.9996095299720764.\nBetter model found at epoch 75 with mae value: 0.9955848455429077.\nBetter model found at epoch 79 with mae value: 0.9809937477111816.\nBetter model found at epoch 84 with mae value: 0.9670782089233398.\nBetter model found at epoch 94 with mae value: 0.9642623662948608.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"MAE for Fold-1: 0.964\nMAPE for Fold-1: 0.035\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"********** Fold-2 **********\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>mae</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>11.755648</td>\n      <td>10.082140</td>\n      <td>10.082140</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>8.144567</td>\n      <td>7.153311</td>\n      <td>7.153311</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6.098210</td>\n      <td>6.416761</td>\n      <td>6.416760</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5.144058</td>\n      <td>5.043830</td>\n      <td>5.043830</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.571835</td>\n      <td>4.115295</td>\n      <td>4.115295</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3.921026</td>\n      <td>4.232346</td>\n      <td>4.232346</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.802929</td>\n      <td>3.713941</td>\n      <td>3.713941</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.333535</td>\n      <td>2.755500</td>\n      <td>2.755499</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.149287</td>\n      <td>2.555913</td>\n      <td>2.555913</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.929458</td>\n      <td>2.403666</td>\n      <td>2.403666</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.697175</td>\n      <td>2.291064</td>\n      <td>2.291064</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.544744</td>\n      <td>2.304916</td>\n      <td>2.304916</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.590084</td>\n      <td>2.754439</td>\n      <td>2.754438</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.320955</td>\n      <td>2.174219</td>\n      <td>2.174219</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.242720</td>\n      <td>2.083926</td>\n      <td>2.083926</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.012692</td>\n      <td>1.604757</td>\n      <td>1.604757</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.022708</td>\n      <td>2.129422</td>\n      <td>2.129422</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.683672</td>\n      <td>1.827215</td>\n      <td>1.827215</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.472339</td>\n      <td>1.271793</td>\n      <td>1.271793</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.387819</td>\n      <td>1.266252</td>\n      <td>1.266252</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.354013</td>\n      <td>1.387175</td>\n      <td>1.387175</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.341393</td>\n      <td>1.879578</td>\n      <td>1.879578</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.358358</td>\n      <td>1.398997</td>\n      <td>1.398997</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.410439</td>\n      <td>2.422634</td>\n      <td>2.422634</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.367511</td>\n      <td>1.251977</td>\n      <td>1.251977</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.327830</td>\n      <td>1.399460</td>\n      <td>1.399460</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.357927</td>\n      <td>1.330495</td>\n      <td>1.330495</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.325489</td>\n      <td>1.341204</td>\n      <td>1.341204</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.331107</td>\n      <td>1.167690</td>\n      <td>1.167690</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.295199</td>\n      <td>1.502989</td>\n      <td>1.502989</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.302235</td>\n      <td>1.362806</td>\n      <td>1.362806</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.252644</td>\n      <td>1.368636</td>\n      <td>1.368636</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.301901</td>\n      <td>1.486909</td>\n      <td>1.486909</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>1.243660</td>\n      <td>1.252587</td>\n      <td>1.252587</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.239000</td>\n      <td>1.244878</td>\n      <td>1.244878</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.260436</td>\n      <td>1.265848</td>\n      <td>1.265848</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>1.179688</td>\n      <td>1.355540</td>\n      <td>1.355540</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>1.230637</td>\n      <td>1.195609</td>\n      <td>1.195609</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>1.202867</td>\n      <td>1.377711</td>\n      <td>1.377712</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.166364</td>\n      <td>1.239676</td>\n      <td>1.239676</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.165511</td>\n      <td>1.403932</td>\n      <td>1.403932</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>1.135394</td>\n      <td>1.196110</td>\n      <td>1.196110</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>1.177427</td>\n      <td>1.350356</td>\n      <td>1.350356</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>1.168242</td>\n      <td>1.082356</td>\n      <td>1.082356</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>1.117044</td>\n      <td>1.250343</td>\n      <td>1.250343</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.109609</td>\n      <td>1.081692</td>\n      <td>1.081692</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>1.077581</td>\n      <td>1.094190</td>\n      <td>1.094190</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>1.125802</td>\n      <td>1.409301</td>\n      <td>1.409301</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>1.157549</td>\n      <td>1.369977</td>\n      <td>1.369977</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>1.181940</td>\n      <td>1.188603</td>\n      <td>1.188603</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.213775</td>\n      <td>1.231126</td>\n      <td>1.231126</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>1.154663</td>\n      <td>1.405552</td>\n      <td>1.405552</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>1.069446</td>\n      <td>1.166566</td>\n      <td>1.166566</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>1.062552</td>\n      <td>1.102069</td>\n      <td>1.102068</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>1.061693</td>\n      <td>1.144838</td>\n      <td>1.144838</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.148415</td>\n      <td>1.235682</td>\n      <td>1.235682</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>1.067939</td>\n      <td>1.170656</td>\n      <td>1.170656</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>1.090051</td>\n      <td>1.100479</td>\n      <td>1.100479</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>1.055732</td>\n      <td>1.183401</td>\n      <td>1.183401</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>1.028443</td>\n      <td>1.114220</td>\n      <td>1.114221</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.998344</td>\n      <td>1.041814</td>\n      <td>1.041814</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>1.003990</td>\n      <td>1.029626</td>\n      <td>1.029626</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>1.018591</td>\n      <td>1.043494</td>\n      <td>1.043494</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>1.050808</td>\n      <td>1.026139</td>\n      <td>1.026139</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>1.026422</td>\n      <td>1.405042</td>\n      <td>1.405042</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>1.008122</td>\n      <td>0.998200</td>\n      <td>0.998200</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.960461</td>\n      <td>1.023565</td>\n      <td>1.023565</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>0.983672</td>\n      <td>1.048866</td>\n      <td>1.048866</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.970641</td>\n      <td>1.088594</td>\n      <td>1.088594</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.986645</td>\n      <td>1.161480</td>\n      <td>1.161479</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.976697</td>\n      <td>1.107067</td>\n      <td>1.107068</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.953987</td>\n      <td>1.031424</td>\n      <td>1.031424</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.922596</td>\n      <td>0.988912</td>\n      <td>0.988912</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.931537</td>\n      <td>1.001301</td>\n      <td>1.001301</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.927639</td>\n      <td>1.014005</td>\n      <td>1.014005</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.895053</td>\n      <td>1.011661</td>\n      <td>1.011661</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.919467</td>\n      <td>1.006964</td>\n      <td>1.006964</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.888766</td>\n      <td>0.994084</td>\n      <td>0.994084</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.893282</td>\n      <td>1.028319</td>\n      <td>1.028319</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.904456</td>\n      <td>1.046299</td>\n      <td>1.046299</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.891678</td>\n      <td>0.993327</td>\n      <td>0.993327</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.877729</td>\n      <td>0.998357</td>\n      <td>0.998357</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.864837</td>\n      <td>0.990290</td>\n      <td>0.990290</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.873829</td>\n      <td>0.964529</td>\n      <td>0.964529</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.851762</td>\n      <td>0.974015</td>\n      <td>0.974015</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.856843</td>\n      <td>0.952436</td>\n      <td>0.952436</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.855285</td>\n      <td>0.981245</td>\n      <td>0.981245</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.862893</td>\n      <td>0.970665</td>\n      <td>0.970665</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.864289</td>\n      <td>0.976218</td>\n      <td>0.976218</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.834649</td>\n      <td>0.961294</td>\n      <td>0.961294</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.840670</td>\n      <td>0.972376</td>\n      <td>0.972376</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.820130</td>\n      <td>0.989930</td>\n      <td>0.989930</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.807684</td>\n      <td>0.981658</td>\n      <td>0.981658</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.849405</td>\n      <td>0.956271</td>\n      <td>0.956271</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.819534</td>\n      <td>0.959073</td>\n      <td>0.959073</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.864691</td>\n      <td>0.972546</td>\n      <td>0.972546</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.830793</td>\n      <td>0.956841</td>\n      <td>0.956841</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.819935</td>\n      <td>0.962693</td>\n      <td>0.962693</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.834130</td>\n      <td>0.980591</td>\n      <td>0.980591</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.840358</td>\n      <td>0.962228</td>\n      <td>0.962228</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"Better model found at epoch 0 with mae value: 10.08213996887207.\nBetter model found at epoch 1 with mae value: 7.153310775756836.\nBetter model found at epoch 2 with mae value: 6.416760444641113.\nBetter model found at epoch 3 with mae value: 5.043830394744873.\nBetter model found at epoch 4 with mae value: 4.115294933319092.\nBetter model found at epoch 6 with mae value: 3.7139410972595215.\nBetter model found at epoch 7 with mae value: 2.7554988861083984.\nBetter model found at epoch 8 with mae value: 2.5559134483337402.\nBetter model found at epoch 9 with mae value: 2.403665542602539.\nBetter model found at epoch 10 with mae value: 2.2910640239715576.\nBetter model found at epoch 13 with mae value: 2.1742188930511475.\nBetter model found at epoch 14 with mae value: 2.083926200866699.\nBetter model found at epoch 15 with mae value: 1.6047569513320923.\nBetter model found at epoch 18 with mae value: 1.2717928886413574.\nBetter model found at epoch 19 with mae value: 1.2662522792816162.\nBetter model found at epoch 24 with mae value: 1.2519768476486206.\nBetter model found at epoch 28 with mae value: 1.1676901578903198.\nBetter model found at epoch 43 with mae value: 1.0823564529418945.\nBetter model found at epoch 45 with mae value: 1.0816923379898071.\nBetter model found at epoch 60 with mae value: 1.0418139696121216.\nBetter model found at epoch 61 with mae value: 1.0296257734298706.\nBetter model found at epoch 63 with mae value: 1.0261386632919312.\nBetter model found at epoch 65 with mae value: 0.9982004761695862.\nBetter model found at epoch 72 with mae value: 0.9889119863510132.\nBetter model found at epoch 83 with mae value: 0.9645285606384277.\nBetter model found at epoch 85 with mae value: 0.9524362087249756.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"MAE for Fold-2: 0.952\nMAPE for Fold-2: 0.034\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"********** Fold-3 **********\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>mae</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>11.491208</td>\n      <td>9.041254</td>\n      <td>9.041253</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>8.014298</td>\n      <td>6.724891</td>\n      <td>6.724890</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6.255936</td>\n      <td>5.476451</td>\n      <td>5.476451</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5.376544</td>\n      <td>4.693520</td>\n      <td>4.693520</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.751556</td>\n      <td>4.067316</td>\n      <td>4.067317</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>4.220012</td>\n      <td>3.796328</td>\n      <td>3.796328</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.895694</td>\n      <td>3.691572</td>\n      <td>3.691573</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.840033</td>\n      <td>3.138646</td>\n      <td>3.138646</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.488613</td>\n      <td>3.520416</td>\n      <td>3.520416</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>3.476490</td>\n      <td>3.457568</td>\n      <td>3.457568</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>3.285280</td>\n      <td>3.237149</td>\n      <td>3.237149</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>3.239320</td>\n      <td>3.036033</td>\n      <td>3.036033</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>3.002991</td>\n      <td>3.115920</td>\n      <td>3.115919</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.883976</td>\n      <td>3.138389</td>\n      <td>3.138389</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.616944</td>\n      <td>2.961328</td>\n      <td>2.961328</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.531055</td>\n      <td>3.730675</td>\n      <td>3.730675</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.463761</td>\n      <td>3.420195</td>\n      <td>3.420196</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>2.076882</td>\n      <td>1.735660</td>\n      <td>1.735660</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.661633</td>\n      <td>1.801640</td>\n      <td>1.801640</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.523952</td>\n      <td>1.719690</td>\n      <td>1.719690</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.412422</td>\n      <td>1.472014</td>\n      <td>1.472015</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.366730</td>\n      <td>1.530850</td>\n      <td>1.530850</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.318450</td>\n      <td>1.526288</td>\n      <td>1.526288</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.311097</td>\n      <td>1.334392</td>\n      <td>1.334392</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.403216</td>\n      <td>1.382783</td>\n      <td>1.382783</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.347554</td>\n      <td>1.449192</td>\n      <td>1.449191</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.335143</td>\n      <td>1.407959</td>\n      <td>1.407959</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.314995</td>\n      <td>1.367351</td>\n      <td>1.367351</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.302568</td>\n      <td>1.872387</td>\n      <td>1.872387</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.229468</td>\n      <td>1.360266</td>\n      <td>1.360266</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.237200</td>\n      <td>1.594825</td>\n      <td>1.594825</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.247443</td>\n      <td>1.357453</td>\n      <td>1.357453</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.293970</td>\n      <td>1.180181</td>\n      <td>1.180181</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>1.298026</td>\n      <td>1.199696</td>\n      <td>1.199696</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.309471</td>\n      <td>1.359914</td>\n      <td>1.359915</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.203340</td>\n      <td>1.216376</td>\n      <td>1.216376</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>1.228692</td>\n      <td>1.105035</td>\n      <td>1.105035</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>1.161674</td>\n      <td>1.087875</td>\n      <td>1.087874</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>1.161154</td>\n      <td>1.113959</td>\n      <td>1.113959</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.155653</td>\n      <td>1.048264</td>\n      <td>1.048264</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.181324</td>\n      <td>1.127782</td>\n      <td>1.127782</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>1.191415</td>\n      <td>1.217090</td>\n      <td>1.217090</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>1.211088</td>\n      <td>1.509057</td>\n      <td>1.509057</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>1.149716</td>\n      <td>1.078010</td>\n      <td>1.078010</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>1.124230</td>\n      <td>1.112757</td>\n      <td>1.112757</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.136212</td>\n      <td>1.165858</td>\n      <td>1.165858</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>1.104522</td>\n      <td>1.047152</td>\n      <td>1.047152</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>1.127028</td>\n      <td>1.180625</td>\n      <td>1.180625</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>1.080409</td>\n      <td>1.102154</td>\n      <td>1.102154</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>1.061295</td>\n      <td>1.148067</td>\n      <td>1.148067</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.049690</td>\n      <td>1.064753</td>\n      <td>1.064753</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>1.075609</td>\n      <td>1.077691</td>\n      <td>1.077691</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>1.074595</td>\n      <td>1.034826</td>\n      <td>1.034826</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>1.059842</td>\n      <td>1.172652</td>\n      <td>1.172652</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>1.055741</td>\n      <td>0.992216</td>\n      <td>0.992216</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.091741</td>\n      <td>1.142102</td>\n      <td>1.142102</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>1.099568</td>\n      <td>1.213686</td>\n      <td>1.213686</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>1.074695</td>\n      <td>1.186353</td>\n      <td>1.186353</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>1.039752</td>\n      <td>0.993865</td>\n      <td>0.993865</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>0.999373</td>\n      <td>1.044502</td>\n      <td>1.044502</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.019910</td>\n      <td>1.049558</td>\n      <td>1.049558</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>1.020095</td>\n      <td>1.010825</td>\n      <td>1.010825</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>1.034032</td>\n      <td>1.022012</td>\n      <td>1.022012</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>0.983626</td>\n      <td>1.102790</td>\n      <td>1.102790</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>0.996091</td>\n      <td>0.995585</td>\n      <td>0.995585</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.982233</td>\n      <td>1.103906</td>\n      <td>1.103906</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.954275</td>\n      <td>1.117235</td>\n      <td>1.117235</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>1.006231</td>\n      <td>1.059111</td>\n      <td>1.059111</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.957079</td>\n      <td>1.019626</td>\n      <td>1.019626</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.939193</td>\n      <td>1.037300</td>\n      <td>1.037300</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.931714</td>\n      <td>1.003546</td>\n      <td>1.003546</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.921146</td>\n      <td>1.027429</td>\n      <td>1.027429</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.930084</td>\n      <td>0.983776</td>\n      <td>0.983776</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.900032</td>\n      <td>0.964626</td>\n      <td>0.964626</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.930114</td>\n      <td>1.022217</td>\n      <td>1.022217</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.899121</td>\n      <td>0.985279</td>\n      <td>0.985279</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.871713</td>\n      <td>0.960112</td>\n      <td>0.960112</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.882715</td>\n      <td>0.986013</td>\n      <td>0.986013</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.884302</td>\n      <td>0.987997</td>\n      <td>0.987997</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.873734</td>\n      <td>0.976529</td>\n      <td>0.976529</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.882455</td>\n      <td>0.962926</td>\n      <td>0.962926</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.877702</td>\n      <td>0.971448</td>\n      <td>0.971448</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.850846</td>\n      <td>0.952894</td>\n      <td>0.952894</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.840043</td>\n      <td>0.960478</td>\n      <td>0.960478</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.817478</td>\n      <td>0.971261</td>\n      <td>0.971261</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.826437</td>\n      <td>0.969463</td>\n      <td>0.969463</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.859516</td>\n      <td>0.955855</td>\n      <td>0.955855</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.864080</td>\n      <td>0.969454</td>\n      <td>0.969454</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.841776</td>\n      <td>0.952191</td>\n      <td>0.952191</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.830884</td>\n      <td>0.958057</td>\n      <td>0.958057</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.831772</td>\n      <td>0.963417</td>\n      <td>0.963417</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.841622</td>\n      <td>0.956868</td>\n      <td>0.956868</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.822599</td>\n      <td>0.955720</td>\n      <td>0.955720</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.805858</td>\n      <td>0.962218</td>\n      <td>0.962219</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.826066</td>\n      <td>0.967708</td>\n      <td>0.967708</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.829464</td>\n      <td>0.951445</td>\n      <td>0.951445</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.861646</td>\n      <td>0.961602</td>\n      <td>0.961602</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.814251</td>\n      <td>0.955960</td>\n      <td>0.955960</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.821112</td>\n      <td>0.961501</td>\n      <td>0.961501</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.812731</td>\n      <td>0.957014</td>\n      <td>0.957014</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"Better model found at epoch 0 with mae value: 9.041253089904785.\nBetter model found at epoch 1 with mae value: 6.724890232086182.\nBetter model found at epoch 2 with mae value: 5.4764509201049805.\nBetter model found at epoch 3 with mae value: 4.693519592285156.\nBetter model found at epoch 4 with mae value: 4.06731653213501.\nBetter model found at epoch 5 with mae value: 3.79632830619812.\nBetter model found at epoch 6 with mae value: 3.691572666168213.\nBetter model found at epoch 7 with mae value: 3.138646125793457.\nBetter model found at epoch 11 with mae value: 3.0360329151153564.\nBetter model found at epoch 14 with mae value: 2.96132755279541.\nBetter model found at epoch 17 with mae value: 1.735660195350647.\nBetter model found at epoch 19 with mae value: 1.7196900844573975.\nBetter model found at epoch 20 with mae value: 1.4720145463943481.\nBetter model found at epoch 23 with mae value: 1.3343919515609741.\nBetter model found at epoch 32 with mae value: 1.180180549621582.\nBetter model found at epoch 36 with mae value: 1.1050353050231934.\nBetter model found at epoch 37 with mae value: 1.087874412536621.\nBetter model found at epoch 39 with mae value: 1.0482642650604248.\nBetter model found at epoch 46 with mae value: 1.047151803970337.\nBetter model found at epoch 52 with mae value: 1.0348258018493652.\nBetter model found at epoch 54 with mae value: 0.9922155737876892.\nBetter model found at epoch 72 with mae value: 0.9837756156921387.\nBetter model found at epoch 73 with mae value: 0.9646264910697937.\nBetter model found at epoch 76 with mae value: 0.9601115584373474.\nBetter model found at epoch 82 with mae value: 0.9528942704200745.\nBetter model found at epoch 88 with mae value: 0.9521912336349487.\nBetter model found at epoch 95 with mae value: 0.9514446258544922.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"MAE for Fold-3: 0.951\nMAPE for Fold-3: 0.033\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"********** Fold-4 **********\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>mae</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>11.821734</td>\n      <td>7.636468</td>\n      <td>7.636468</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>8.042247</td>\n      <td>5.505301</td>\n      <td>5.505301</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6.236462</td>\n      <td>4.655416</td>\n      <td>4.655416</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5.105339</td>\n      <td>3.344075</td>\n      <td>3.344075</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.468698</td>\n      <td>3.561128</td>\n      <td>3.561128</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>4.082038</td>\n      <td>3.079891</td>\n      <td>3.079891</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.657696</td>\n      <td>2.355044</td>\n      <td>2.355044</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.518024</td>\n      <td>2.315542</td>\n      <td>2.315542</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.391320</td>\n      <td>2.427428</td>\n      <td>2.427428</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>3.042325</td>\n      <td>2.517496</td>\n      <td>2.517496</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.899757</td>\n      <td>2.267892</td>\n      <td>2.267892</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.594222</td>\n      <td>2.228534</td>\n      <td>2.228534</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.603790</td>\n      <td>1.834757</td>\n      <td>1.834757</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.617732</td>\n      <td>2.215752</td>\n      <td>2.215752</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.338713</td>\n      <td>1.906842</td>\n      <td>1.906842</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.138204</td>\n      <td>1.579512</td>\n      <td>1.579512</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.088814</td>\n      <td>2.036856</td>\n      <td>2.036855</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.911335</td>\n      <td>1.512167</td>\n      <td>1.512167</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.747672</td>\n      <td>1.517671</td>\n      <td>1.517671</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.609310</td>\n      <td>1.435202</td>\n      <td>1.435202</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.601071</td>\n      <td>1.556289</td>\n      <td>1.556289</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.501460</td>\n      <td>1.258122</td>\n      <td>1.258122</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.405092</td>\n      <td>1.240214</td>\n      <td>1.240214</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.415364</td>\n      <td>1.461514</td>\n      <td>1.461514</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.474947</td>\n      <td>1.485129</td>\n      <td>1.485129</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.509523</td>\n      <td>1.361267</td>\n      <td>1.361267</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.436670</td>\n      <td>1.650018</td>\n      <td>1.650018</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.390355</td>\n      <td>1.903652</td>\n      <td>1.903652</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.402509</td>\n      <td>1.175304</td>\n      <td>1.175304</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.362358</td>\n      <td>1.294142</td>\n      <td>1.294143</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.388484</td>\n      <td>1.278549</td>\n      <td>1.278549</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.379624</td>\n      <td>1.194318</td>\n      <td>1.194318</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.404426</td>\n      <td>1.258637</td>\n      <td>1.258637</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>1.329704</td>\n      <td>1.170628</td>\n      <td>1.170628</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.267507</td>\n      <td>1.073139</td>\n      <td>1.073139</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.250394</td>\n      <td>1.121890</td>\n      <td>1.121890</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>1.241250</td>\n      <td>1.224197</td>\n      <td>1.224197</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>1.347693</td>\n      <td>1.204347</td>\n      <td>1.204347</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>1.260835</td>\n      <td>1.037294</td>\n      <td>1.037294</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.198492</td>\n      <td>0.981580</td>\n      <td>0.981580</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.230793</td>\n      <td>1.086130</td>\n      <td>1.086130</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>1.214355</td>\n      <td>1.008616</td>\n      <td>1.008616</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>1.143954</td>\n      <td>1.028267</td>\n      <td>1.028267</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>1.159320</td>\n      <td>1.084771</td>\n      <td>1.084772</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>1.227143</td>\n      <td>1.086924</td>\n      <td>1.086924</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.202064</td>\n      <td>1.012134</td>\n      <td>1.012134</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>1.194483</td>\n      <td>0.948145</td>\n      <td>0.948145</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>1.218968</td>\n      <td>1.059276</td>\n      <td>1.059276</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>1.174436</td>\n      <td>1.117280</td>\n      <td>1.117280</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>1.137174</td>\n      <td>1.192282</td>\n      <td>1.192282</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.186933</td>\n      <td>1.079781</td>\n      <td>1.079781</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>1.174460</td>\n      <td>0.998161</td>\n      <td>0.998161</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>1.161678</td>\n      <td>1.242828</td>\n      <td>1.242828</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>1.181257</td>\n      <td>1.160257</td>\n      <td>1.160257</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>1.122863</td>\n      <td>1.039002</td>\n      <td>1.039002</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.195168</td>\n      <td>1.152187</td>\n      <td>1.152187</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>1.197284</td>\n      <td>1.033245</td>\n      <td>1.033245</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>1.162745</td>\n      <td>0.987237</td>\n      <td>0.987237</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>1.154732</td>\n      <td>1.097596</td>\n      <td>1.097596</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>1.102166</td>\n      <td>0.970833</td>\n      <td>0.970833</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.100068</td>\n      <td>1.014684</td>\n      <td>1.014684</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>1.171538</td>\n      <td>0.986153</td>\n      <td>0.986153</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>1.148392</td>\n      <td>1.031706</td>\n      <td>1.031706</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>1.105297</td>\n      <td>0.984529</td>\n      <td>0.984529</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>1.098444</td>\n      <td>0.924234</td>\n      <td>0.924234</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>1.067801</td>\n      <td>0.871273</td>\n      <td>0.871273</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>1.048860</td>\n      <td>0.866488</td>\n      <td>0.866488</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>1.046975</td>\n      <td>0.863414</td>\n      <td>0.863414</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>1.068452</td>\n      <td>1.034977</td>\n      <td>1.034977</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>1.061484</td>\n      <td>0.912311</td>\n      <td>0.912311</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.025573</td>\n      <td>0.869819</td>\n      <td>0.869819</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.999594</td>\n      <td>0.981155</td>\n      <td>0.981155</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>1.001867</td>\n      <td>0.855375</td>\n      <td>0.855375</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>1.023811</td>\n      <td>1.021036</td>\n      <td>1.021036</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>1.005772</td>\n      <td>0.889462</td>\n      <td>0.889462</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.980716</td>\n      <td>0.898338</td>\n      <td>0.898338</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>1.014098</td>\n      <td>0.900401</td>\n      <td>0.900401</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>1.021783</td>\n      <td>0.967414</td>\n      <td>0.967414</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.996565</td>\n      <td>0.885844</td>\n      <td>0.885845</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.992930</td>\n      <td>0.877553</td>\n      <td>0.877553</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.982476</td>\n      <td>0.855359</td>\n      <td>0.855359</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.960486</td>\n      <td>0.872565</td>\n      <td>0.872565</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.945228</td>\n      <td>0.897310</td>\n      <td>0.897310</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.961319</td>\n      <td>0.848921</td>\n      <td>0.848921</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.967508</td>\n      <td>0.901665</td>\n      <td>0.901665</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.934706</td>\n      <td>0.849192</td>\n      <td>0.849192</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.933304</td>\n      <td>0.848980</td>\n      <td>0.848980</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.949182</td>\n      <td>0.864772</td>\n      <td>0.864772</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.920818</td>\n      <td>0.844690</td>\n      <td>0.844690</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.905800</td>\n      <td>0.849349</td>\n      <td>0.849349</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.898717</td>\n      <td>0.840585</td>\n      <td>0.840585</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.897209</td>\n      <td>0.842905</td>\n      <td>0.842905</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.893117</td>\n      <td>0.830275</td>\n      <td>0.830275</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.894098</td>\n      <td>0.838234</td>\n      <td>0.838234</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.895441</td>\n      <td>0.843033</td>\n      <td>0.843033</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.908883</td>\n      <td>0.840454</td>\n      <td>0.840454</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.930226</td>\n      <td>0.840508</td>\n      <td>0.840508</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.913544</td>\n      <td>0.834023</td>\n      <td>0.834023</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.895347</td>\n      <td>0.833092</td>\n      <td>0.833092</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.897549</td>\n      <td>0.835173</td>\n      <td>0.835173</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"Better model found at epoch 0 with mae value: 7.636467933654785.\nBetter model found at epoch 1 with mae value: 5.505300998687744.\nBetter model found at epoch 2 with mae value: 4.655416488647461.\nBetter model found at epoch 3 with mae value: 3.3440754413604736.\nBetter model found at epoch 5 with mae value: 3.0798914432525635.\nBetter model found at epoch 6 with mae value: 2.35504412651062.\nBetter model found at epoch 7 with mae value: 2.315541982650757.\nBetter model found at epoch 10 with mae value: 2.2678916454315186.\nBetter model found at epoch 11 with mae value: 2.228534460067749.\nBetter model found at epoch 12 with mae value: 1.8347569704055786.\nBetter model found at epoch 15 with mae value: 1.5795122385025024.\nBetter model found at epoch 17 with mae value: 1.5121673345565796.\nBetter model found at epoch 19 with mae value: 1.4352020025253296.\nBetter model found at epoch 21 with mae value: 1.2581223249435425.\nBetter model found at epoch 22 with mae value: 1.2402143478393555.\nBetter model found at epoch 28 with mae value: 1.1753038167953491.\nBetter model found at epoch 33 with mae value: 1.1706277132034302.\nBetter model found at epoch 34 with mae value: 1.073138952255249.\nBetter model found at epoch 38 with mae value: 1.0372941493988037.\nBetter model found at epoch 39 with mae value: 0.9815797209739685.\nBetter model found at epoch 46 with mae value: 0.9481446146965027.\nBetter model found at epoch 64 with mae value: 0.9242343306541443.\nBetter model found at epoch 65 with mae value: 0.87127286195755.\nBetter model found at epoch 66 with mae value: 0.8664882779121399.\nBetter model found at epoch 67 with mae value: 0.8634141087532043.\nBetter model found at epoch 72 with mae value: 0.8553746342658997.\nBetter model found at epoch 80 with mae value: 0.8553587198257446.\nBetter model found at epoch 83 with mae value: 0.8489206433296204.\nBetter model found at epoch 88 with mae value: 0.844690203666687.\nBetter model found at epoch 90 with mae value: 0.840585470199585.\nBetter model found at epoch 92 with mae value: 0.8302749395370483.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"MAE for Fold-4: 0.83\nMAPE for Fold-4: 0.036\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"********** Fold-5 **********\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>mae</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>11.244002</td>\n      <td>8.714982</td>\n      <td>8.714982</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>7.823749</td>\n      <td>5.702768</td>\n      <td>5.702767</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>5.978137</td>\n      <td>4.347606</td>\n      <td>4.347605</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4.919407</td>\n      <td>3.781791</td>\n      <td>3.781791</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.253207</td>\n      <td>2.843874</td>\n      <td>2.843874</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3.973585</td>\n      <td>2.860926</td>\n      <td>2.860926</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.473954</td>\n      <td>2.574931</td>\n      <td>2.574932</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.625612</td>\n      <td>2.910616</td>\n      <td>2.910616</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.114041</td>\n      <td>2.211833</td>\n      <td>2.211833</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.836160</td>\n      <td>2.560751</td>\n      <td>2.560751</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.607897</td>\n      <td>1.863027</td>\n      <td>1.863027</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.520490</td>\n      <td>1.804798</td>\n      <td>1.804798</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.404217</td>\n      <td>2.209417</td>\n      <td>2.209417</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.235131</td>\n      <td>2.215649</td>\n      <td>2.215649</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.018584</td>\n      <td>1.622686</td>\n      <td>1.622686</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.921043</td>\n      <td>2.547257</td>\n      <td>2.547257</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.901307</td>\n      <td>1.926026</td>\n      <td>1.926027</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.741049</td>\n      <td>2.233416</td>\n      <td>2.233416</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.655218</td>\n      <td>1.913864</td>\n      <td>1.913864</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.582628</td>\n      <td>1.828289</td>\n      <td>1.828289</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.500496</td>\n      <td>1.809709</td>\n      <td>1.809709</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.486738</td>\n      <td>1.767582</td>\n      <td>1.767582</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.423493</td>\n      <td>1.554827</td>\n      <td>1.554827</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.593418</td>\n      <td>2.478200</td>\n      <td>2.478200</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.414531</td>\n      <td>1.322411</td>\n      <td>1.322411</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.357229</td>\n      <td>1.277868</td>\n      <td>1.277867</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.291945</td>\n      <td>1.185751</td>\n      <td>1.185751</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.262163</td>\n      <td>1.282347</td>\n      <td>1.282347</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.279968</td>\n      <td>1.355658</td>\n      <td>1.355658</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.283661</td>\n      <td>1.142684</td>\n      <td>1.142684</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.239719</td>\n      <td>1.268924</td>\n      <td>1.268924</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.218875</td>\n      <td>1.548337</td>\n      <td>1.548337</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.210970</td>\n      <td>1.068625</td>\n      <td>1.068625</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>1.274614</td>\n      <td>1.323898</td>\n      <td>1.323898</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.250656</td>\n      <td>1.324094</td>\n      <td>1.324094</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.303431</td>\n      <td>1.257722</td>\n      <td>1.257722</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>1.289633</td>\n      <td>1.661292</td>\n      <td>1.661292</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>1.368886</td>\n      <td>1.158272</td>\n      <td>1.158272</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>1.280238</td>\n      <td>1.079656</td>\n      <td>1.079656</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.345159</td>\n      <td>1.215930</td>\n      <td>1.215930</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.227487</td>\n      <td>1.096835</td>\n      <td>1.096835</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>1.199349</td>\n      <td>1.338458</td>\n      <td>1.338458</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>1.215905</td>\n      <td>1.085786</td>\n      <td>1.085786</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>1.213768</td>\n      <td>1.286812</td>\n      <td>1.286812</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>1.186515</td>\n      <td>1.102721</td>\n      <td>1.102721</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.237685</td>\n      <td>1.395757</td>\n      <td>1.395757</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>1.191784</td>\n      <td>1.417728</td>\n      <td>1.417728</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>1.191133</td>\n      <td>1.067963</td>\n      <td>1.067963</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>1.166440</td>\n      <td>1.132107</td>\n      <td>1.132107</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>1.160297</td>\n      <td>1.115872</td>\n      <td>1.115872</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.172985</td>\n      <td>1.376803</td>\n      <td>1.376803</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>1.140052</td>\n      <td>1.201780</td>\n      <td>1.201780</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>1.197566</td>\n      <td>1.184662</td>\n      <td>1.184662</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>1.145121</td>\n      <td>1.037142</td>\n      <td>1.037142</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>1.099078</td>\n      <td>1.280774</td>\n      <td>1.280774</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.108774</td>\n      <td>1.139496</td>\n      <td>1.139496</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>1.076007</td>\n      <td>1.084405</td>\n      <td>1.084405</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>1.047962</td>\n      <td>1.174898</td>\n      <td>1.174898</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>1.025440</td>\n      <td>1.161770</td>\n      <td>1.161770</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>1.007205</td>\n      <td>1.086093</td>\n      <td>1.086093</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.997550</td>\n      <td>1.008523</td>\n      <td>1.008524</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>1.018572</td>\n      <td>1.043100</td>\n      <td>1.043100</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.981755</td>\n      <td>1.240960</td>\n      <td>1.240960</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>0.992439</td>\n      <td>1.091150</td>\n      <td>1.091150</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>1.001648</td>\n      <td>1.137172</td>\n      <td>1.137172</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.968729</td>\n      <td>1.041803</td>\n      <td>1.041804</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.961634</td>\n      <td>1.060244</td>\n      <td>1.060244</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>0.948634</td>\n      <td>0.955592</td>\n      <td>0.955592</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>1.013111</td>\n      <td>1.071285</td>\n      <td>1.071286</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>1.001831</td>\n      <td>1.046123</td>\n      <td>1.046124</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.986421</td>\n      <td>1.045345</td>\n      <td>1.045346</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.952520</td>\n      <td>1.052130</td>\n      <td>1.052130</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.957484</td>\n      <td>0.966234</td>\n      <td>0.966234</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.930472</td>\n      <td>0.940771</td>\n      <td>0.940771</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.922610</td>\n      <td>0.952439</td>\n      <td>0.952439</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.950861</td>\n      <td>0.996465</td>\n      <td>0.996465</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.925799</td>\n      <td>0.949037</td>\n      <td>0.949037</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.923849</td>\n      <td>0.953306</td>\n      <td>0.953306</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.901845</td>\n      <td>0.951698</td>\n      <td>0.951698</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.883214</td>\n      <td>0.925218</td>\n      <td>0.925218</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.892850</td>\n      <td>0.946963</td>\n      <td>0.946963</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.868131</td>\n      <td>0.937457</td>\n      <td>0.937457</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.871538</td>\n      <td>0.951539</td>\n      <td>0.951540</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.857055</td>\n      <td>0.919703</td>\n      <td>0.919703</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.864735</td>\n      <td>0.935728</td>\n      <td>0.935728</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.852856</td>\n      <td>0.939532</td>\n      <td>0.939532</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.842474</td>\n      <td>0.940776</td>\n      <td>0.940776</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.857143</td>\n      <td>0.923277</td>\n      <td>0.923277</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.859933</td>\n      <td>0.941038</td>\n      <td>0.941038</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.866456</td>\n      <td>0.941169</td>\n      <td>0.941169</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.847351</td>\n      <td>0.930985</td>\n      <td>0.930985</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.848573</td>\n      <td>0.941717</td>\n      <td>0.941717</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.861646</td>\n      <td>0.919864</td>\n      <td>0.919864</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.850388</td>\n      <td>0.914649</td>\n      <td>0.914649</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.823254</td>\n      <td>0.917272</td>\n      <td>0.917272</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.823296</td>\n      <td>0.918592</td>\n      <td>0.918592</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.816303</td>\n      <td>0.911195</td>\n      <td>0.911195</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.841420</td>\n      <td>0.918657</td>\n      <td>0.918657</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.832149</td>\n      <td>0.937275</td>\n      <td>0.937275</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.817150</td>\n      <td>0.944428</td>\n      <td>0.944428</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"Better model found at epoch 0 with mae value: 8.714982032775879.\nBetter model found at epoch 1 with mae value: 5.7027668952941895.\nBetter model found at epoch 2 with mae value: 4.347605228424072.\nBetter model found at epoch 3 with mae value: 3.7817912101745605.\nBetter model found at epoch 4 with mae value: 2.8438735008239746.\nBetter model found at epoch 6 with mae value: 2.5749318599700928.\nBetter model found at epoch 8 with mae value: 2.2118327617645264.\nBetter model found at epoch 10 with mae value: 1.8630268573760986.\nBetter model found at epoch 11 with mae value: 1.8047983646392822.\nBetter model found at epoch 14 with mae value: 1.6226856708526611.\nBetter model found at epoch 22 with mae value: 1.554827332496643.\nBetter model found at epoch 24 with mae value: 1.3224109411239624.\nBetter model found at epoch 25 with mae value: 1.2778674364089966.\nBetter model found at epoch 26 with mae value: 1.1857510805130005.\nBetter model found at epoch 29 with mae value: 1.1426843404769897.\nBetter model found at epoch 32 with mae value: 1.0686253309249878.\nBetter model found at epoch 47 with mae value: 1.067962884902954.\nBetter model found at epoch 53 with mae value: 1.0371419191360474.\nBetter model found at epoch 60 with mae value: 1.0085235834121704.\nBetter model found at epoch 67 with mae value: 0.955592155456543.\nBetter model found at epoch 73 with mae value: 0.9407713413238525.\nBetter model found at epoch 79 with mae value: 0.9252182841300964.\nBetter model found at epoch 83 with mae value: 0.9197027087211609.\nBetter model found at epoch 93 with mae value: 0.9146491885185242.\nBetter model found at epoch 96 with mae value: 0.9111951589584351.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"MAE for Fold-5: 0.911\nMAPE for Fold-5: 0.033\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"********** Fold-6 **********\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>mae</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>12.110085</td>\n      <td>7.028585</td>\n      <td>7.028585</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>8.233215</td>\n      <td>5.086394</td>\n      <td>5.086394</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6.478325</td>\n      <td>4.104659</td>\n      <td>4.104659</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5.536225</td>\n      <td>4.262086</td>\n      <td>4.262087</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.836021</td>\n      <td>3.796441</td>\n      <td>3.796441</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>4.208514</td>\n      <td>2.882856</td>\n      <td>2.882856</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.748383</td>\n      <td>3.043335</td>\n      <td>3.043335</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.633778</td>\n      <td>2.805310</td>\n      <td>2.805310</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.453684</td>\n      <td>2.792796</td>\n      <td>2.792796</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>3.363680</td>\n      <td>2.488014</td>\n      <td>2.488014</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>3.286498</td>\n      <td>2.474382</td>\n      <td>2.474382</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>3.005587</td>\n      <td>2.288610</td>\n      <td>2.288610</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.878542</td>\n      <td>3.080743</td>\n      <td>3.080743</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.840365</td>\n      <td>2.224916</td>\n      <td>2.224916</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.517238</td>\n      <td>2.044688</td>\n      <td>2.044688</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.299647</td>\n      <td>1.887752</td>\n      <td>1.887752</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.250215</td>\n      <td>2.037268</td>\n      <td>2.037268</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.891534</td>\n      <td>1.330064</td>\n      <td>1.330064</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.557819</td>\n      <td>1.256012</td>\n      <td>1.256012</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.450695</td>\n      <td>1.204134</td>\n      <td>1.204134</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.481378</td>\n      <td>1.266370</td>\n      <td>1.266370</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.383406</td>\n      <td>1.232327</td>\n      <td>1.232327</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.512024</td>\n      <td>1.617858</td>\n      <td>1.617858</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.434336</td>\n      <td>1.421534</td>\n      <td>1.421534</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.434258</td>\n      <td>1.125799</td>\n      <td>1.125799</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.402441</td>\n      <td>1.159277</td>\n      <td>1.159277</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.307438</td>\n      <td>1.305517</td>\n      <td>1.305517</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.278628</td>\n      <td>1.149275</td>\n      <td>1.149275</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.292536</td>\n      <td>1.226518</td>\n      <td>1.226518</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.326659</td>\n      <td>1.238103</td>\n      <td>1.238103</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.240024</td>\n      <td>1.194199</td>\n      <td>1.194199</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.236108</td>\n      <td>1.217930</td>\n      <td>1.217930</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.224158</td>\n      <td>1.196495</td>\n      <td>1.196495</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>1.272490</td>\n      <td>1.214119</td>\n      <td>1.214119</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.239451</td>\n      <td>1.406578</td>\n      <td>1.406577</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.245067</td>\n      <td>1.203442</td>\n      <td>1.203442</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>1.250833</td>\n      <td>1.155887</td>\n      <td>1.155887</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>1.247356</td>\n      <td>1.411953</td>\n      <td>1.411953</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>1.175386</td>\n      <td>1.069849</td>\n      <td>1.069849</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.162764</td>\n      <td>1.200528</td>\n      <td>1.200528</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.205634</td>\n      <td>1.039158</td>\n      <td>1.039158</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>1.176299</td>\n      <td>0.990163</td>\n      <td>0.990163</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>1.169612</td>\n      <td>1.232360</td>\n      <td>1.232360</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>1.130616</td>\n      <td>1.052556</td>\n      <td>1.052556</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>1.173046</td>\n      <td>1.384252</td>\n      <td>1.384252</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.168504</td>\n      <td>1.076557</td>\n      <td>1.076557</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>1.143094</td>\n      <td>0.945020</td>\n      <td>0.945020</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>1.137912</td>\n      <td>1.095088</td>\n      <td>1.095088</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>1.114139</td>\n      <td>1.249555</td>\n      <td>1.249555</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>1.074403</td>\n      <td>0.941413</td>\n      <td>0.941413</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.050537</td>\n      <td>1.076880</td>\n      <td>1.076880</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>1.125651</td>\n      <td>1.042631</td>\n      <td>1.042631</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>1.096725</td>\n      <td>0.983209</td>\n      <td>0.983209</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>1.077979</td>\n      <td>1.202950</td>\n      <td>1.202950</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>1.104419</td>\n      <td>1.000971</td>\n      <td>1.000971</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.087288</td>\n      <td>1.051511</td>\n      <td>1.051511</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>1.115342</td>\n      <td>0.958816</td>\n      <td>0.958816</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>1.106843</td>\n      <td>0.959678</td>\n      <td>0.959678</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>1.064430</td>\n      <td>0.921324</td>\n      <td>0.921324</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>1.002942</td>\n      <td>0.935014</td>\n      <td>0.935014</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.030615</td>\n      <td>0.960126</td>\n      <td>0.960126</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>1.059780</td>\n      <td>1.092736</td>\n      <td>1.092736</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>1.088552</td>\n      <td>1.031113</td>\n      <td>1.031113</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>1.051034</td>\n      <td>1.032098</td>\n      <td>1.032098</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>1.020367</td>\n      <td>0.892467</td>\n      <td>0.892467</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.978290</td>\n      <td>0.920677</td>\n      <td>0.920677</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>1.007531</td>\n      <td>0.985598</td>\n      <td>0.985598</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>0.967997</td>\n      <td>0.975429</td>\n      <td>0.975429</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.949067</td>\n      <td>0.949821</td>\n      <td>0.949821</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.975698</td>\n      <td>1.043682</td>\n      <td>1.043682</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.971808</td>\n      <td>0.892257</td>\n      <td>0.892257</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.932136</td>\n      <td>0.917806</td>\n      <td>0.917806</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.923074</td>\n      <td>1.003150</td>\n      <td>1.003150</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.965730</td>\n      <td>1.038680</td>\n      <td>1.038679</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.954269</td>\n      <td>0.900969</td>\n      <td>0.900969</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.951388</td>\n      <td>0.907560</td>\n      <td>0.907560</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.930519</td>\n      <td>0.983205</td>\n      <td>0.983205</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.943774</td>\n      <td>0.925686</td>\n      <td>0.925686</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.915865</td>\n      <td>0.930058</td>\n      <td>0.930058</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.889535</td>\n      <td>0.931920</td>\n      <td>0.931920</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.904445</td>\n      <td>0.892140</td>\n      <td>0.892140</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.876691</td>\n      <td>0.908357</td>\n      <td>0.908357</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.922466</td>\n      <td>0.909903</td>\n      <td>0.909903</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.921404</td>\n      <td>0.897932</td>\n      <td>0.897933</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.918476</td>\n      <td>0.883857</td>\n      <td>0.883857</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.913782</td>\n      <td>0.892670</td>\n      <td>0.892670</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.885529</td>\n      <td>0.914147</td>\n      <td>0.914147</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.904337</td>\n      <td>0.915251</td>\n      <td>0.915251</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.889594</td>\n      <td>0.911503</td>\n      <td>0.911503</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.908247</td>\n      <td>0.890216</td>\n      <td>0.890216</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.888062</td>\n      <td>0.891889</td>\n      <td>0.891889</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.871580</td>\n      <td>0.880145</td>\n      <td>0.880145</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.880282</td>\n      <td>0.893035</td>\n      <td>0.893035</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.871156</td>\n      <td>0.906609</td>\n      <td>0.906609</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.894797</td>\n      <td>0.926908</td>\n      <td>0.926908</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.859701</td>\n      <td>0.878009</td>\n      <td>0.878009</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.870007</td>\n      <td>0.873923</td>\n      <td>0.873923</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.858067</td>\n      <td>0.896751</td>\n      <td>0.896751</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.847021</td>\n      <td>0.877172</td>\n      <td>0.877172</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.835376</td>\n      <td>0.897549</td>\n      <td>0.897549</td>\n      <td>00:01</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"Better model found at epoch 0 with mae value: 7.028584957122803.\nBetter model found at epoch 1 with mae value: 5.0863938331604.\nBetter model found at epoch 2 with mae value: 4.104659080505371.\nBetter model found at epoch 4 with mae value: 3.796441078186035.\nBetter model found at epoch 5 with mae value: 2.8828563690185547.\nBetter model found at epoch 7 with mae value: 2.805309534072876.\nBetter model found at epoch 8 with mae value: 2.7927958965301514.\nBetter model found at epoch 9 with mae value: 2.488013744354248.\nBetter model found at epoch 10 with mae value: 2.474381685256958.\nBetter model found at epoch 11 with mae value: 2.288609743118286.\nBetter model found at epoch 13 with mae value: 2.2249162197113037.\nBetter model found at epoch 14 with mae value: 2.044687509536743.\nBetter model found at epoch 15 with mae value: 1.8877519369125366.\nBetter model found at epoch 17 with mae value: 1.330064296722412.\nBetter model found at epoch 18 with mae value: 1.2560120820999146.\nBetter model found at epoch 19 with mae value: 1.2041343450546265.\nBetter model found at epoch 24 with mae value: 1.1257988214492798.\nBetter model found at epoch 38 with mae value: 1.069848656654358.\nBetter model found at epoch 40 with mae value: 1.0391578674316406.\nBetter model found at epoch 41 with mae value: 0.9901633262634277.\nBetter model found at epoch 46 with mae value: 0.9450197219848633.\nBetter model found at epoch 49 with mae value: 0.9414129257202148.\nBetter model found at epoch 58 with mae value: 0.9213238954544067.\nBetter model found at epoch 64 with mae value: 0.8924667835235596.\nBetter model found at epoch 70 with mae value: 0.8922572731971741.\nBetter model found at epoch 80 with mae value: 0.8921396732330322.\nBetter model found at epoch 84 with mae value: 0.8838566541671753.\nBetter model found at epoch 91 with mae value: 0.8801448941230774.\nBetter model found at epoch 95 with mae value: 0.8780089616775513.\nBetter model found at epoch 96 with mae value: 0.8739229440689087.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"MAE for Fold-6: 0.874\nMAPE for Fold-6: 0.034\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"********** Fold-7 **********\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>mae</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>11.770735</td>\n      <td>6.704153</td>\n      <td>6.704154</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>8.137540</td>\n      <td>4.614427</td>\n      <td>4.614427</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6.383796</td>\n      <td>4.008382</td>\n      <td>4.008383</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5.400767</td>\n      <td>3.140087</td>\n      <td>3.140087</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.801307</td>\n      <td>2.806794</td>\n      <td>2.806794</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>4.192533</td>\n      <td>2.705454</td>\n      <td>2.705455</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.751668</td>\n      <td>2.437171</td>\n      <td>2.437171</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.736883</td>\n      <td>2.350288</td>\n      <td>2.350288</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.535474</td>\n      <td>2.494153</td>\n      <td>2.494153</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>3.517663</td>\n      <td>2.593009</td>\n      <td>2.593009</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>3.360928</td>\n      <td>2.240851</td>\n      <td>2.240851</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>3.176965</td>\n      <td>1.962592</td>\n      <td>1.962592</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.894953</td>\n      <td>1.837544</td>\n      <td>1.837544</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.641683</td>\n      <td>1.594903</td>\n      <td>1.594903</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.424712</td>\n      <td>1.962253</td>\n      <td>1.962253</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.243857</td>\n      <td>1.607973</td>\n      <td>1.607973</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.195134</td>\n      <td>2.026769</td>\n      <td>2.026769</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.994623</td>\n      <td>2.087397</td>\n      <td>2.087397</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.705699</td>\n      <td>1.284941</td>\n      <td>1.284941</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.596784</td>\n      <td>1.203834</td>\n      <td>1.203834</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.445474</td>\n      <td>1.233516</td>\n      <td>1.233516</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.353427</td>\n      <td>1.141954</td>\n      <td>1.141954</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.410513</td>\n      <td>1.181216</td>\n      <td>1.181216</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.403813</td>\n      <td>1.504130</td>\n      <td>1.504130</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.370768</td>\n      <td>1.574047</td>\n      <td>1.574047</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.418394</td>\n      <td>1.425480</td>\n      <td>1.425479</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.399654</td>\n      <td>1.220980</td>\n      <td>1.220980</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.349702</td>\n      <td>1.496535</td>\n      <td>1.496535</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.281758</td>\n      <td>1.030519</td>\n      <td>1.030519</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.251963</td>\n      <td>1.317865</td>\n      <td>1.317865</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.258691</td>\n      <td>1.065291</td>\n      <td>1.065291</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.285498</td>\n      <td>1.204488</td>\n      <td>1.204488</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.299903</td>\n      <td>1.063709</td>\n      <td>1.063709</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>1.268436</td>\n      <td>1.043637</td>\n      <td>1.043637</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.218412</td>\n      <td>1.134699</td>\n      <td>1.134699</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.205059</td>\n      <td>1.098613</td>\n      <td>1.098613</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>1.199443</td>\n      <td>1.076201</td>\n      <td>1.076201</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>1.156153</td>\n      <td>1.089726</td>\n      <td>1.089726</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>1.124803</td>\n      <td>1.315305</td>\n      <td>1.315305</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.167962</td>\n      <td>1.081338</td>\n      <td>1.081338</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.146693</td>\n      <td>1.042588</td>\n      <td>1.042588</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>1.191567</td>\n      <td>0.966744</td>\n      <td>0.966744</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>1.151286</td>\n      <td>1.163509</td>\n      <td>1.163509</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>1.145918</td>\n      <td>0.974395</td>\n      <td>0.974395</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>1.129434</td>\n      <td>1.137731</td>\n      <td>1.137731</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.124442</td>\n      <td>0.967039</td>\n      <td>0.967040</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>1.198894</td>\n      <td>1.283837</td>\n      <td>1.283837</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>1.141683</td>\n      <td>0.991297</td>\n      <td>0.991297</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>1.144476</td>\n      <td>0.994480</td>\n      <td>0.994480</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>1.113522</td>\n      <td>1.140424</td>\n      <td>1.140424</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.096483</td>\n      <td>1.146472</td>\n      <td>1.146472</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>1.108794</td>\n      <td>0.986283</td>\n      <td>0.986284</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>1.142513</td>\n      <td>1.055767</td>\n      <td>1.055767</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>1.117422</td>\n      <td>1.229225</td>\n      <td>1.229225</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>1.073891</td>\n      <td>0.910400</td>\n      <td>0.910400</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.093787</td>\n      <td>0.913414</td>\n      <td>0.913414</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>1.068707</td>\n      <td>0.944860</td>\n      <td>0.944860</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>1.053525</td>\n      <td>0.901690</td>\n      <td>0.901690</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>1.059405</td>\n      <td>0.904968</td>\n      <td>0.904968</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>1.067118</td>\n      <td>0.984794</td>\n      <td>0.984794</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.044083</td>\n      <td>0.903413</td>\n      <td>0.903413</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>1.030244</td>\n      <td>0.901572</td>\n      <td>0.901572</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>1.076406</td>\n      <td>1.049111</td>\n      <td>1.049111</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>1.067146</td>\n      <td>0.915247</td>\n      <td>0.915247</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>1.015255</td>\n      <td>0.891031</td>\n      <td>0.891031</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.990576</td>\n      <td>1.108965</td>\n      <td>1.108965</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>1.010606</td>\n      <td>0.899171</td>\n      <td>0.899171</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>0.983724</td>\n      <td>0.878816</td>\n      <td>0.878816</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.961315</td>\n      <td>0.871216</td>\n      <td>0.871216</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.949624</td>\n      <td>0.903077</td>\n      <td>0.903077</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.962853</td>\n      <td>0.882021</td>\n      <td>0.882021</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.951866</td>\n      <td>0.936144</td>\n      <td>0.936144</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.955005</td>\n      <td>0.890232</td>\n      <td>0.890232</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.954261</td>\n      <td>0.902827</td>\n      <td>0.902827</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.955907</td>\n      <td>0.933926</td>\n      <td>0.933926</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.955629</td>\n      <td>0.902181</td>\n      <td>0.902181</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.959468</td>\n      <td>0.878123</td>\n      <td>0.878123</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.985933</td>\n      <td>0.920230</td>\n      <td>0.920230</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.982442</td>\n      <td>0.867980</td>\n      <td>0.867980</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.976630</td>\n      <td>0.898589</td>\n      <td>0.898589</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.964827</td>\n      <td>0.870626</td>\n      <td>0.870626</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.940373</td>\n      <td>0.863667</td>\n      <td>0.863667</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.918510</td>\n      <td>0.866585</td>\n      <td>0.866585</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.936040</td>\n      <td>0.864844</td>\n      <td>0.864844</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.902057</td>\n      <td>0.844404</td>\n      <td>0.844404</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.902933</td>\n      <td>0.858833</td>\n      <td>0.858833</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.875498</td>\n      <td>0.852188</td>\n      <td>0.852188</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.896242</td>\n      <td>0.852235</td>\n      <td>0.852235</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.866548</td>\n      <td>0.841913</td>\n      <td>0.841913</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.840658</td>\n      <td>0.844857</td>\n      <td>0.844857</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.883561</td>\n      <td>0.833751</td>\n      <td>0.833750</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.863502</td>\n      <td>0.842237</td>\n      <td>0.842237</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.870257</td>\n      <td>0.844313</td>\n      <td>0.844313</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.862736</td>\n      <td>0.840248</td>\n      <td>0.840248</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.854599</td>\n      <td>0.838002</td>\n      <td>0.838002</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.856793</td>\n      <td>0.839957</td>\n      <td>0.839957</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.831870</td>\n      <td>0.845060</td>\n      <td>0.845060</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.847796</td>\n      <td>0.839789</td>\n      <td>0.839789</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.834450</td>\n      <td>0.845812</td>\n      <td>0.845812</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.832351</td>\n      <td>0.844721</td>\n      <td>0.844721</td>\n      <td>00:01</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"Better model found at epoch 0 with mae value: 6.704154014587402.\nBetter model found at epoch 1 with mae value: 4.614427089691162.\nBetter model found at epoch 2 with mae value: 4.008382797241211.\nBetter model found at epoch 3 with mae value: 3.1400868892669678.\nBetter model found at epoch 4 with mae value: 2.8067941665649414.\nBetter model found at epoch 5 with mae value: 2.7054545879364014.\nBetter model found at epoch 6 with mae value: 2.4371707439422607.\nBetter model found at epoch 7 with mae value: 2.350287914276123.\nBetter model found at epoch 10 with mae value: 2.2408511638641357.\nBetter model found at epoch 11 with mae value: 1.962592363357544.\nBetter model found at epoch 12 with mae value: 1.8375438451766968.\nBetter model found at epoch 13 with mae value: 1.5949028730392456.\nBetter model found at epoch 18 with mae value: 1.2849409580230713.\nBetter model found at epoch 19 with mae value: 1.2038341760635376.\nBetter model found at epoch 21 with mae value: 1.141953945159912.\nBetter model found at epoch 28 with mae value: 1.030518889427185.\nBetter model found at epoch 41 with mae value: 0.9667442440986633.\nBetter model found at epoch 54 with mae value: 0.9104003310203552.\nBetter model found at epoch 57 with mae value: 0.9016904234886169.\nBetter model found at epoch 61 with mae value: 0.9015722274780273.\nBetter model found at epoch 64 with mae value: 0.8910312652587891.\nBetter model found at epoch 67 with mae value: 0.8788159489631653.\nBetter model found at epoch 68 with mae value: 0.8712159991264343.\nBetter model found at epoch 78 with mae value: 0.8679795265197754.\nBetter model found at epoch 81 with mae value: 0.8636665940284729.\nBetter model found at epoch 84 with mae value: 0.8444038033485413.\nBetter model found at epoch 88 with mae value: 0.8419128656387329.\nBetter model found at epoch 90 with mae value: 0.8337504863739014.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"MAE for Fold-7: 0.834\nMAPE for Fold-7: 0.036\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"********** Fold-8 **********\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>mae</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>10.489977</td>\n      <td>8.959808</td>\n      <td>8.959808</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>7.298845</td>\n      <td>6.538944</td>\n      <td>6.538943</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>5.732342</td>\n      <td>5.677785</td>\n      <td>5.677785</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4.846160</td>\n      <td>4.605932</td>\n      <td>4.605932</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.258869</td>\n      <td>4.121872</td>\n      <td>4.121871</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>4.016469</td>\n      <td>4.438451</td>\n      <td>4.438451</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.669470</td>\n      <td>3.497224</td>\n      <td>3.497224</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.393999</td>\n      <td>2.955010</td>\n      <td>2.955010</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.129114</td>\n      <td>2.955488</td>\n      <td>2.955488</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.893302</td>\n      <td>2.437298</td>\n      <td>2.437298</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.729865</td>\n      <td>2.791799</td>\n      <td>2.791799</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.634803</td>\n      <td>2.768143</td>\n      <td>2.768143</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.525779</td>\n      <td>2.215732</td>\n      <td>2.215733</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.236305</td>\n      <td>1.965620</td>\n      <td>1.965620</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.115665</td>\n      <td>1.972057</td>\n      <td>1.972057</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.002494</td>\n      <td>1.872103</td>\n      <td>1.872103</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.870078</td>\n      <td>2.157975</td>\n      <td>2.157975</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.901144</td>\n      <td>2.820279</td>\n      <td>2.820279</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.897653</td>\n      <td>2.182941</td>\n      <td>2.182941</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.640613</td>\n      <td>1.615284</td>\n      <td>1.615284</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.532631</td>\n      <td>1.612830</td>\n      <td>1.612830</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.612452</td>\n      <td>1.903531</td>\n      <td>1.903531</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.533603</td>\n      <td>1.812105</td>\n      <td>1.812105</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.536625</td>\n      <td>2.490920</td>\n      <td>2.490920</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.490458</td>\n      <td>1.868446</td>\n      <td>1.868446</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.426137</td>\n      <td>1.282131</td>\n      <td>1.282131</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.475842</td>\n      <td>1.703564</td>\n      <td>1.703564</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.553466</td>\n      <td>3.116652</td>\n      <td>3.116652</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.552421</td>\n      <td>1.864883</td>\n      <td>1.864883</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.476721</td>\n      <td>1.477056</td>\n      <td>1.477056</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.399851</td>\n      <td>1.383188</td>\n      <td>1.383188</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.361864</td>\n      <td>1.435271</td>\n      <td>1.435271</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.331246</td>\n      <td>1.381075</td>\n      <td>1.381075</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>1.309131</td>\n      <td>1.342894</td>\n      <td>1.342894</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.261854</td>\n      <td>1.276470</td>\n      <td>1.276470</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.273122</td>\n      <td>1.420912</td>\n      <td>1.420912</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>1.275267</td>\n      <td>1.101213</td>\n      <td>1.101213</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>1.233999</td>\n      <td>1.350060</td>\n      <td>1.350060</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>1.321226</td>\n      <td>1.994703</td>\n      <td>1.994702</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.254286</td>\n      <td>1.259156</td>\n      <td>1.259156</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.202020</td>\n      <td>1.198792</td>\n      <td>1.198792</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>1.162406</td>\n      <td>1.197128</td>\n      <td>1.197128</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>1.137927</td>\n      <td>1.167807</td>\n      <td>1.167807</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>1.135925</td>\n      <td>1.195837</td>\n      <td>1.195837</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>1.103432</td>\n      <td>1.197445</td>\n      <td>1.197445</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.120022</td>\n      <td>1.169971</td>\n      <td>1.169971</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>1.099293</td>\n      <td>1.300029</td>\n      <td>1.300029</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>1.105523</td>\n      <td>1.087314</td>\n      <td>1.087314</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>1.110588</td>\n      <td>1.023430</td>\n      <td>1.023430</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>1.066252</td>\n      <td>1.130459</td>\n      <td>1.130459</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.051197</td>\n      <td>1.023861</td>\n      <td>1.023861</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>1.047610</td>\n      <td>1.185915</td>\n      <td>1.185915</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>1.042149</td>\n      <td>1.069457</td>\n      <td>1.069457</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>1.088411</td>\n      <td>1.325725</td>\n      <td>1.325725</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>1.043388</td>\n      <td>1.202210</td>\n      <td>1.202210</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.052291</td>\n      <td>1.102832</td>\n      <td>1.102832</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>1.030516</td>\n      <td>1.098194</td>\n      <td>1.098194</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>1.025956</td>\n      <td>1.065967</td>\n      <td>1.065967</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>1.020177</td>\n      <td>1.056036</td>\n      <td>1.056036</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>1.070211</td>\n      <td>1.263870</td>\n      <td>1.263870</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.077441</td>\n      <td>1.061508</td>\n      <td>1.061508</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>1.066598</td>\n      <td>1.087090</td>\n      <td>1.087090</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>1.056901</td>\n      <td>1.060806</td>\n      <td>1.060806</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>1.035632</td>\n      <td>1.143367</td>\n      <td>1.143367</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>1.041923</td>\n      <td>1.107757</td>\n      <td>1.107757</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>1.039913</td>\n      <td>1.074320</td>\n      <td>1.074320</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>1.014819</td>\n      <td>1.017499</td>\n      <td>1.017499</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>0.972332</td>\n      <td>1.023791</td>\n      <td>1.023791</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.974560</td>\n      <td>1.098023</td>\n      <td>1.098023</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.951810</td>\n      <td>1.081387</td>\n      <td>1.081388</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.927368</td>\n      <td>1.020156</td>\n      <td>1.020156</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.960743</td>\n      <td>1.178141</td>\n      <td>1.178141</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.922740</td>\n      <td>1.043959</td>\n      <td>1.043959</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.942073</td>\n      <td>0.992177</td>\n      <td>0.992177</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.941703</td>\n      <td>1.007874</td>\n      <td>1.007874</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.955589</td>\n      <td>1.007220</td>\n      <td>1.007220</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.922341</td>\n      <td>0.973994</td>\n      <td>0.973994</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.894648</td>\n      <td>0.995811</td>\n      <td>0.995811</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.898059</td>\n      <td>0.990928</td>\n      <td>0.990928</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.887581</td>\n      <td>1.014449</td>\n      <td>1.014449</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.891547</td>\n      <td>0.969661</td>\n      <td>0.969661</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.911925</td>\n      <td>1.007941</td>\n      <td>1.007942</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.903454</td>\n      <td>1.000240</td>\n      <td>1.000240</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.878827</td>\n      <td>0.969618</td>\n      <td>0.969618</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.897514</td>\n      <td>0.989045</td>\n      <td>0.989045</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.900487</td>\n      <td>0.951358</td>\n      <td>0.951358</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.872140</td>\n      <td>0.968046</td>\n      <td>0.968046</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.851527</td>\n      <td>0.969533</td>\n      <td>0.969533</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.847748</td>\n      <td>0.936303</td>\n      <td>0.936303</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.856339</td>\n      <td>0.961977</td>\n      <td>0.961977</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.855767</td>\n      <td>0.948935</td>\n      <td>0.948935</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.861338</td>\n      <td>0.960091</td>\n      <td>0.960091</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.840602</td>\n      <td>0.946786</td>\n      <td>0.946786</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.843838</td>\n      <td>0.946385</td>\n      <td>0.946385</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.815435</td>\n      <td>0.956460</td>\n      <td>0.956460</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.818138</td>\n      <td>0.940178</td>\n      <td>0.940178</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.826447</td>\n      <td>0.938189</td>\n      <td>0.938189</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.827608</td>\n      <td>0.950141</td>\n      <td>0.950141</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.836970</td>\n      <td>0.936583</td>\n      <td>0.936583</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.843369</td>\n      <td>0.971561</td>\n      <td>0.971561</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"Better model found at epoch 0 with mae value: 8.959808349609375.\nBetter model found at epoch 1 with mae value: 6.538942813873291.\nBetter model found at epoch 2 with mae value: 5.677785396575928.\nBetter model found at epoch 3 with mae value: 4.605931758880615.\nBetter model found at epoch 4 with mae value: 4.121871471405029.\nBetter model found at epoch 6 with mae value: 3.4972238540649414.\nBetter model found at epoch 7 with mae value: 2.955010175704956.\nBetter model found at epoch 9 with mae value: 2.437297821044922.\nBetter model found at epoch 12 with mae value: 2.2157325744628906.\nBetter model found at epoch 13 with mae value: 1.9656200408935547.\nBetter model found at epoch 15 with mae value: 1.8721027374267578.\nBetter model found at epoch 19 with mae value: 1.6152840852737427.\nBetter model found at epoch 20 with mae value: 1.6128302812576294.\nBetter model found at epoch 25 with mae value: 1.2821308374404907.\nBetter model found at epoch 34 with mae value: 1.2764701843261719.\nBetter model found at epoch 36 with mae value: 1.101212739944458.\nBetter model found at epoch 47 with mae value: 1.0873135328292847.\nBetter model found at epoch 48 with mae value: 1.0234295129776.\nBetter model found at epoch 66 with mae value: 1.0174987316131592.\nBetter model found at epoch 73 with mae value: 0.9921769499778748.\nBetter model found at epoch 76 with mae value: 0.9739941954612732.\nBetter model found at epoch 80 with mae value: 0.969660758972168.\nBetter model found at epoch 83 with mae value: 0.9696180820465088.\nBetter model found at epoch 85 with mae value: 0.9513581395149231.\nBetter model found at epoch 88 with mae value: 0.9363031983375549.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"MAE for Fold-8: 0.936\nMAPE for Fold-8: 0.038\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"********** Fold-9 **********\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>mae</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>11.320457</td>\n      <td>8.202053</td>\n      <td>8.202053</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>7.789918</td>\n      <td>5.808343</td>\n      <td>5.808342</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6.134809</td>\n      <td>4.729730</td>\n      <td>4.729730</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5.284949</td>\n      <td>4.707319</td>\n      <td>4.707319</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.459031</td>\n      <td>3.486302</td>\n      <td>3.486301</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>4.089468</td>\n      <td>3.412260</td>\n      <td>3.412259</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.862557</td>\n      <td>3.294147</td>\n      <td>3.294146</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.575818</td>\n      <td>3.249023</td>\n      <td>3.249023</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.502957</td>\n      <td>3.444307</td>\n      <td>3.444307</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>3.503499</td>\n      <td>3.332826</td>\n      <td>3.332826</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>3.294967</td>\n      <td>3.367468</td>\n      <td>3.367468</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>3.105715</td>\n      <td>2.546802</td>\n      <td>2.546801</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>3.092425</td>\n      <td>2.788919</td>\n      <td>2.788919</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.893238</td>\n      <td>2.955967</td>\n      <td>2.955967</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.761398</td>\n      <td>2.734262</td>\n      <td>2.734262</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.530363</td>\n      <td>2.288156</td>\n      <td>2.288156</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.260004</td>\n      <td>2.096605</td>\n      <td>2.096605</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.934591</td>\n      <td>1.865057</td>\n      <td>1.865057</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.688480</td>\n      <td>1.840284</td>\n      <td>1.840284</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.556544</td>\n      <td>1.537179</td>\n      <td>1.537179</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.403762</td>\n      <td>1.427006</td>\n      <td>1.427006</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.356023</td>\n      <td>1.615697</td>\n      <td>1.615697</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.388415</td>\n      <td>1.743119</td>\n      <td>1.743119</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.350908</td>\n      <td>1.260579</td>\n      <td>1.260579</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.335983</td>\n      <td>1.291500</td>\n      <td>1.291500</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.314777</td>\n      <td>1.569702</td>\n      <td>1.569702</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.262616</td>\n      <td>1.489096</td>\n      <td>1.489096</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.314010</td>\n      <td>1.534258</td>\n      <td>1.534258</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.299013</td>\n      <td>1.292002</td>\n      <td>1.292002</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.256658</td>\n      <td>1.233843</td>\n      <td>1.233843</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.275480</td>\n      <td>1.522663</td>\n      <td>1.522663</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.258540</td>\n      <td>1.431448</td>\n      <td>1.431448</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.204852</td>\n      <td>1.201814</td>\n      <td>1.201813</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>1.185539</td>\n      <td>1.313814</td>\n      <td>1.313814</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.183712</td>\n      <td>1.260273</td>\n      <td>1.260273</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.305481</td>\n      <td>1.340754</td>\n      <td>1.340754</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>1.416009</td>\n      <td>1.227690</td>\n      <td>1.227690</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>1.312746</td>\n      <td>1.322952</td>\n      <td>1.322952</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>1.243139</td>\n      <td>1.196746</td>\n      <td>1.196746</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.314540</td>\n      <td>1.380085</td>\n      <td>1.380085</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.264809</td>\n      <td>1.121886</td>\n      <td>1.121887</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>1.277702</td>\n      <td>1.347258</td>\n      <td>1.347258</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>1.236820</td>\n      <td>1.137520</td>\n      <td>1.137520</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>1.194842</td>\n      <td>1.224898</td>\n      <td>1.224898</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>1.188073</td>\n      <td>1.185019</td>\n      <td>1.185019</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.276661</td>\n      <td>1.139905</td>\n      <td>1.139905</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>1.401917</td>\n      <td>1.206104</td>\n      <td>1.206104</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>1.284487</td>\n      <td>1.176789</td>\n      <td>1.176789</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>1.295936</td>\n      <td>1.246493</td>\n      <td>1.246493</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>1.201129</td>\n      <td>1.235125</td>\n      <td>1.235125</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.241765</td>\n      <td>1.636616</td>\n      <td>1.636616</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>1.244699</td>\n      <td>1.101957</td>\n      <td>1.101957</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>1.177513</td>\n      <td>1.124264</td>\n      <td>1.124264</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>1.168666</td>\n      <td>1.016501</td>\n      <td>1.016501</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>1.177604</td>\n      <td>1.110432</td>\n      <td>1.110432</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.142795</td>\n      <td>1.398178</td>\n      <td>1.398178</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>1.168520</td>\n      <td>1.011038</td>\n      <td>1.011038</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>1.148719</td>\n      <td>1.081671</td>\n      <td>1.081671</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>1.147706</td>\n      <td>1.128448</td>\n      <td>1.128448</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>1.112544</td>\n      <td>1.250065</td>\n      <td>1.250065</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.093460</td>\n      <td>1.020672</td>\n      <td>1.020672</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>1.065377</td>\n      <td>1.027793</td>\n      <td>1.027793</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>1.087999</td>\n      <td>1.039734</td>\n      <td>1.039734</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>1.025468</td>\n      <td>1.054616</td>\n      <td>1.054616</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>1.018386</td>\n      <td>1.026615</td>\n      <td>1.026615</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>1.042043</td>\n      <td>1.050513</td>\n      <td>1.050513</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>1.021452</td>\n      <td>0.997701</td>\n      <td>0.997701</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>1.020160</td>\n      <td>0.970070</td>\n      <td>0.970070</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>1.016728</td>\n      <td>1.003492</td>\n      <td>1.003492</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.981244</td>\n      <td>0.969516</td>\n      <td>0.969516</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.983219</td>\n      <td>1.024097</td>\n      <td>1.024097</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.989442</td>\n      <td>1.115412</td>\n      <td>1.115412</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.981624</td>\n      <td>0.930572</td>\n      <td>0.930572</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.984471</td>\n      <td>0.995226</td>\n      <td>0.995226</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.994838</td>\n      <td>1.002071</td>\n      <td>1.002072</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.965409</td>\n      <td>0.935875</td>\n      <td>0.935875</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.932371</td>\n      <td>1.016865</td>\n      <td>1.016865</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.938670</td>\n      <td>0.962256</td>\n      <td>0.962256</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.926358</td>\n      <td>0.972018</td>\n      <td>0.972018</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.919847</td>\n      <td>0.963012</td>\n      <td>0.963012</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.907584</td>\n      <td>0.979955</td>\n      <td>0.979955</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.921505</td>\n      <td>0.947954</td>\n      <td>0.947954</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.912610</td>\n      <td>0.946841</td>\n      <td>0.946841</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.909944</td>\n      <td>0.951173</td>\n      <td>0.951173</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.944075</td>\n      <td>0.965577</td>\n      <td>0.965577</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.920499</td>\n      <td>0.930040</td>\n      <td>0.930040</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.882760</td>\n      <td>0.935158</td>\n      <td>0.935158</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.880481</td>\n      <td>0.924754</td>\n      <td>0.924754</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.902812</td>\n      <td>0.919316</td>\n      <td>0.919316</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.906186</td>\n      <td>0.924945</td>\n      <td>0.924945</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.884472</td>\n      <td>0.934793</td>\n      <td>0.934793</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.881496</td>\n      <td>0.940599</td>\n      <td>0.940599</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.872621</td>\n      <td>0.926777</td>\n      <td>0.926777</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.864788</td>\n      <td>0.920391</td>\n      <td>0.920391</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.884869</td>\n      <td>0.920313</td>\n      <td>0.920313</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.859860</td>\n      <td>0.924246</td>\n      <td>0.924246</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.856193</td>\n      <td>0.915951</td>\n      <td>0.915951</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.873299</td>\n      <td>0.921943</td>\n      <td>0.921943</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.857362</td>\n      <td>0.921996</td>\n      <td>0.921996</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.854044</td>\n      <td>0.931753</td>\n      <td>0.931753</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"Better model found at epoch 0 with mae value: 8.20205307006836.\nBetter model found at epoch 1 with mae value: 5.808341979980469.\nBetter model found at epoch 2 with mae value: 4.729729652404785.\nBetter model found at epoch 3 with mae value: 4.707319259643555.\nBetter model found at epoch 4 with mae value: 3.4863011837005615.\nBetter model found at epoch 5 with mae value: 3.412259340286255.\nBetter model found at epoch 6 with mae value: 3.2941462993621826.\nBetter model found at epoch 7 with mae value: 3.2490227222442627.\nBetter model found at epoch 11 with mae value: 2.5468013286590576.\nBetter model found at epoch 15 with mae value: 2.2881557941436768.\nBetter model found at epoch 16 with mae value: 2.096604585647583.\nBetter model found at epoch 17 with mae value: 1.8650569915771484.\nBetter model found at epoch 18 with mae value: 1.840283989906311.\nBetter model found at epoch 19 with mae value: 1.5371789932250977.\nBetter model found at epoch 20 with mae value: 1.4270058870315552.\nBetter model found at epoch 23 with mae value: 1.2605786323547363.\nBetter model found at epoch 29 with mae value: 1.2338429689407349.\nBetter model found at epoch 32 with mae value: 1.2018134593963623.\nBetter model found at epoch 38 with mae value: 1.1967461109161377.\nBetter model found at epoch 40 with mae value: 1.1218866109848022.\nBetter model found at epoch 51 with mae value: 1.1019569635391235.\nBetter model found at epoch 53 with mae value: 1.0165010690689087.\nBetter model found at epoch 56 with mae value: 1.011038064956665.\nBetter model found at epoch 66 with mae value: 0.9977005124092102.\nBetter model found at epoch 67 with mae value: 0.9700697064399719.\nBetter model found at epoch 69 with mae value: 0.969515860080719.\nBetter model found at epoch 72 with mae value: 0.9305720329284668.\nBetter model found at epoch 85 with mae value: 0.9300399422645569.\nBetter model found at epoch 87 with mae value: 0.9247542023658752.\nBetter model found at epoch 88 with mae value: 0.9193159937858582.\nBetter model found at epoch 96 with mae value: 0.9159505367279053.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"MAE for Fold-9: 0.916\nMAPE for Fold-9: 0.035\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"********** Fold-10 **********\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>mae</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>12.403419</td>\n      <td>7.893864</td>\n      <td>7.893864</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>8.370242</td>\n      <td>6.000122</td>\n      <td>6.000122</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6.412959</td>\n      <td>5.109375</td>\n      <td>5.109375</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5.290493</td>\n      <td>4.758902</td>\n      <td>4.758901</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.656608</td>\n      <td>5.009459</td>\n      <td>5.009459</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>4.283100</td>\n      <td>4.601528</td>\n      <td>4.601528</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.832090</td>\n      <td>3.402177</td>\n      <td>3.402176</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.291791</td>\n      <td>3.328538</td>\n      <td>3.328538</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.999818</td>\n      <td>2.556926</td>\n      <td>2.556926</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.898556</td>\n      <td>2.385085</td>\n      <td>2.385085</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.746481</td>\n      <td>3.006990</td>\n      <td>3.006990</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.643337</td>\n      <td>2.428815</td>\n      <td>2.428815</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.492005</td>\n      <td>2.184473</td>\n      <td>2.184473</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.281399</td>\n      <td>2.550786</td>\n      <td>2.550786</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.195768</td>\n      <td>2.192122</td>\n      <td>2.192122</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.041354</td>\n      <td>2.077963</td>\n      <td>2.077963</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.940653</td>\n      <td>2.168324</td>\n      <td>2.168324</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.691604</td>\n      <td>1.511324</td>\n      <td>1.511324</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.538311</td>\n      <td>1.693030</td>\n      <td>1.693031</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.475887</td>\n      <td>1.369794</td>\n      <td>1.369794</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.436945</td>\n      <td>1.353978</td>\n      <td>1.353978</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.402744</td>\n      <td>1.433784</td>\n      <td>1.433784</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.424665</td>\n      <td>1.279928</td>\n      <td>1.279928</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.373492</td>\n      <td>1.396752</td>\n      <td>1.396752</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.350785</td>\n      <td>1.589929</td>\n      <td>1.589929</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.308004</td>\n      <td>1.339708</td>\n      <td>1.339707</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.395536</td>\n      <td>1.207568</td>\n      <td>1.207568</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.344576</td>\n      <td>1.900868</td>\n      <td>1.900868</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.356627</td>\n      <td>1.438850</td>\n      <td>1.438850</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.276907</td>\n      <td>1.040349</td>\n      <td>1.040349</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.250440</td>\n      <td>1.220747</td>\n      <td>1.220747</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.311803</td>\n      <td>1.584459</td>\n      <td>1.584459</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.265702</td>\n      <td>1.143817</td>\n      <td>1.143817</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>1.246582</td>\n      <td>1.180689</td>\n      <td>1.180689</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.227853</td>\n      <td>1.222400</td>\n      <td>1.222400</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.230213</td>\n      <td>1.323755</td>\n      <td>1.323755</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>1.188687</td>\n      <td>1.066898</td>\n      <td>1.066898</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>1.193844</td>\n      <td>1.034010</td>\n      <td>1.034010</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>1.172509</td>\n      <td>1.111691</td>\n      <td>1.111691</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.158436</td>\n      <td>1.221725</td>\n      <td>1.221725</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.191713</td>\n      <td>1.575656</td>\n      <td>1.575656</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>1.171168</td>\n      <td>1.078571</td>\n      <td>1.078571</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>1.168667</td>\n      <td>1.350923</td>\n      <td>1.350923</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>1.152982</td>\n      <td>1.198043</td>\n      <td>1.198043</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>1.132015</td>\n      <td>1.060072</td>\n      <td>1.060072</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.118145</td>\n      <td>1.035599</td>\n      <td>1.035599</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>1.146506</td>\n      <td>1.243211</td>\n      <td>1.243211</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>1.124222</td>\n      <td>1.023986</td>\n      <td>1.023985</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>1.123880</td>\n      <td>1.064348</td>\n      <td>1.064348</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>1.080692</td>\n      <td>1.012226</td>\n      <td>1.012226</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.056005</td>\n      <td>1.008311</td>\n      <td>1.008311</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>1.089236</td>\n      <td>1.045298</td>\n      <td>1.045298</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>1.102040</td>\n      <td>1.078890</td>\n      <td>1.078890</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>1.077545</td>\n      <td>0.981619</td>\n      <td>0.981619</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>1.041115</td>\n      <td>1.085878</td>\n      <td>1.085878</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.052625</td>\n      <td>1.148399</td>\n      <td>1.148399</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>1.047287</td>\n      <td>1.047102</td>\n      <td>1.047102</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>1.030901</td>\n      <td>1.113273</td>\n      <td>1.113273</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>1.058596</td>\n      <td>1.029677</td>\n      <td>1.029677</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>1.015379</td>\n      <td>0.956034</td>\n      <td>0.956034</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.015422</td>\n      <td>1.005534</td>\n      <td>1.005534</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>0.997208</td>\n      <td>0.992222</td>\n      <td>0.992222</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.964995</td>\n      <td>1.007473</td>\n      <td>1.007473</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>0.957180</td>\n      <td>1.060981</td>\n      <td>1.060981</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>0.971304</td>\n      <td>0.985219</td>\n      <td>0.985219</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>1.015102</td>\n      <td>0.982458</td>\n      <td>0.982458</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.995281</td>\n      <td>0.970846</td>\n      <td>0.970846</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>1.026449</td>\n      <td>1.115806</td>\n      <td>1.115806</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>1.011769</td>\n      <td>1.028547</td>\n      <td>1.028547</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.998864</td>\n      <td>0.965696</td>\n      <td>0.965696</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.990359</td>\n      <td>0.947560</td>\n      <td>0.947560</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.956155</td>\n      <td>0.951263</td>\n      <td>0.951263</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.982174</td>\n      <td>1.008265</td>\n      <td>1.008265</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.950356</td>\n      <td>0.939053</td>\n      <td>0.939053</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.953311</td>\n      <td>0.926461</td>\n      <td>0.926461</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.936141</td>\n      <td>0.955458</td>\n      <td>0.955458</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.916146</td>\n      <td>0.948971</td>\n      <td>0.948971</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.907007</td>\n      <td>0.992570</td>\n      <td>0.992569</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.897596</td>\n      <td>0.918287</td>\n      <td>0.918287</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.879141</td>\n      <td>0.927751</td>\n      <td>0.927751</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.878560</td>\n      <td>0.934127</td>\n      <td>0.934127</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.867278</td>\n      <td>0.942663</td>\n      <td>0.942663</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.891326</td>\n      <td>0.957179</td>\n      <td>0.957179</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.918450</td>\n      <td>0.940949</td>\n      <td>0.940949</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.900651</td>\n      <td>0.952105</td>\n      <td>0.952105</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.888298</td>\n      <td>0.910537</td>\n      <td>0.910537</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.875964</td>\n      <td>0.939739</td>\n      <td>0.939739</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.855443</td>\n      <td>0.930943</td>\n      <td>0.930943</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.865081</td>\n      <td>0.921558</td>\n      <td>0.921558</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.870442</td>\n      <td>0.939485</td>\n      <td>0.939485</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.835275</td>\n      <td>0.928010</td>\n      <td>0.928010</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.823159</td>\n      <td>0.918074</td>\n      <td>0.918074</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.836896</td>\n      <td>0.912770</td>\n      <td>0.912770</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.840077</td>\n      <td>0.916360</td>\n      <td>0.916360</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.819764</td>\n      <td>0.941575</td>\n      <td>0.941575</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.833775</td>\n      <td>0.913827</td>\n      <td>0.913827</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.821665</td>\n      <td>0.913826</td>\n      <td>0.913826</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.831636</td>\n      <td>0.918580</td>\n      <td>0.918580</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.830087</td>\n      <td>0.912972</td>\n      <td>0.912971</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.836205</td>\n      <td>0.936724</td>\n      <td>0.936724</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"Better model found at epoch 0 with mae value: 7.893863677978516.\nBetter model found at epoch 1 with mae value: 6.0001220703125.\nBetter model found at epoch 2 with mae value: 5.109375.\nBetter model found at epoch 3 with mae value: 4.758901119232178.\nBetter model found at epoch 5 with mae value: 4.601528167724609.\nBetter model found at epoch 6 with mae value: 3.4021763801574707.\nBetter model found at epoch 7 with mae value: 3.328537940979004.\nBetter model found at epoch 8 with mae value: 2.5569257736206055.\nBetter model found at epoch 9 with mae value: 2.385085105895996.\nBetter model found at epoch 12 with mae value: 2.1844727993011475.\nBetter model found at epoch 15 with mae value: 2.077962636947632.\nBetter model found at epoch 17 with mae value: 1.5113240480422974.\nBetter model found at epoch 19 with mae value: 1.3697943687438965.\nBetter model found at epoch 20 with mae value: 1.353978157043457.\nBetter model found at epoch 22 with mae value: 1.2799277305603027.\nBetter model found at epoch 26 with mae value: 1.2075684070587158.\nBetter model found at epoch 29 with mae value: 1.0403491258621216.\nBetter model found at epoch 37 with mae value: 1.0340098142623901.\nBetter model found at epoch 47 with mae value: 1.0239853858947754.\nBetter model found at epoch 49 with mae value: 1.0122261047363281.\nBetter model found at epoch 50 with mae value: 1.00831139087677.\nBetter model found at epoch 53 with mae value: 0.9816185235977173.\nBetter model found at epoch 59 with mae value: 0.9560343027114868.\nBetter model found at epoch 70 with mae value: 0.9475600123405457.\nBetter model found at epoch 73 with mae value: 0.9390530586242676.\nBetter model found at epoch 74 with mae value: 0.9264606237411499.\nBetter model found at epoch 78 with mae value: 0.9182870984077454.\nBetter model found at epoch 85 with mae value: 0.9105374217033386.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"MAE for Fold-10: 0.911\nMAPE for Fold-10: 0.033\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"OOF MAE: 0.908\nAverage MAE: 0.908+/-0.045\nOOF MAPE: 0.034\nAverage MAPE: 0.034+/-0.002\n","output_type":"stream"}],"execution_count":20},{"id":"0ee6323e","cell_type":"code","source":"set_seed(42)\n\nseed_everything(seed=42)\n\n\n\nsubmission_fastai = pd.DataFrame(data = {'Time': test_df['ID'].values, 'Energy': pred_fastai})\n\nprint(submission_fastai.head())\n\nsubmission_fastai.to_csv(f'/kaggle/working/submission_fastai.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:49:26.612852Z","iopub.execute_input":"2024-11-07T10:49:26.613985Z","iopub.status.idle":"2024-11-07T10:49:26.759773Z","shell.execute_reply.started":"2024-11-07T10:49:26.613907Z","shell.execute_reply":"2024-11-07T10:49:26.758709Z"},"papermill":{"duration":0.099767,"end_time":"2023-10-12T12:06:00.046655","exception":false,"start_time":"2023-10-12T12:05:59.946888","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Seed set to 42\n                        Time     Energy\n0  2023-01-02 10:00:00_B_595  46.955750\n1   2023-01-01 06:00:00_B_21  19.685436\n2  2023-01-03 00:00:00_B_495  13.765328\n3  2023-01-06 09:00:00_B_728  57.806194\n4  2023-01-01 04:00:00_B_298  39.278046\n","output_type":"stream"}],"execution_count":21},{"id":"c7b9d051","cell_type":"code","source":"# OOF MAE: 0.908\n# Average MAE: 0.908+/-0.045\n# OOF MAPE: 0.034\n# Average MAPE: 0.034+/-0.002","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:18:37.391609Z","iopub.status.idle":"2024-11-07T10:18:37.391994Z","shell.execute_reply.started":"2024-11-07T10:18:37.391788Z","shell.execute_reply":"2024-11-07T10:18:37.391808Z"},"papermill":{"duration":0.040723,"end_time":"2023-10-12T12:06:00.120898","exception":false,"start_time":"2023-10-12T12:06:00.080175","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"bae2d8ae","cell_type":"markdown","source":"### Keras Model","metadata":{"papermill":{"duration":0.032334,"end_time":"2023-10-12T12:06:00.186156","exception":false,"start_time":"2023-10-12T12:06:00.153822","status":"completed"},"tags":[]}},{"id":"bc41f070","cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.backend import sigmoid  # Correct import\nfrom tensorflow.keras.utils import get_custom_objects\nfrom tensorflow.keras.layers import Activation\n\n# For random seed consistency\nimport numpy as np\nimport random\n\ndef set_seed(seed=42):\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n\n# Ensure the seed is set\nset_seed(42)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:53:07.958590Z","iopub.execute_input":"2024-11-07T10:53:07.959441Z","iopub.status.idle":"2024-11-07T10:53:08.032922Z","shell.execute_reply.started":"2024-11-07T10:53:07.959387Z","shell.execute_reply":"2024-11-07T10:53:08.032122Z"},"papermill":{"duration":8.568898,"end_time":"2023-10-12T12:06:08.787938","exception":false,"start_time":"2023-10-12T12:06:00.219040","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":23},{"id":"7917e6c7","cell_type":"code","source":"set_seed(42)\n\nseed_everything(seed=42)\n\ntf.random.set_seed(42)\n\n\n\ndef mean_absolute_error(y_true, y_pred):\n\n         return K.mean(K.abs( (y_true - y_pred)))\n\n\n\nes = tf.keras.callbacks.EarlyStopping(\n\n    monitor='val_loss', patience=50, verbose=0,\n\n    mode='min',restore_best_weights=True)\n\n\n\nplateau = tf.keras.callbacks.ReduceLROnPlateau(\n\n    monitor='val_loss', factor=0.25, patience=8, verbose=0,\n\n    mode='min')\n\n\n\ndef swish(x, beta = 1):\n\n    return (x * sigmoid(beta * x))\n\n\n\ndef mish(x, beta = 1):\n\n    return (x * K.tanh(K.softplus(x)))\n\n\n\n\n\nget_custom_objects().update({'swish': Activation(swish)})\n\nget_custom_objects().update({'mish': Activation(mish)})","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:53:21.447021Z","iopub.execute_input":"2024-11-07T10:53:21.447402Z","iopub.status.idle":"2024-11-07T10:53:21.459249Z","shell.execute_reply.started":"2024-11-07T10:53:21.447365Z","shell.execute_reply":"2024-11-07T10:53:21.458361Z"},"papermill":{"duration":0.053512,"end_time":"2023-10-12T12:06:08.875277","exception":false,"start_time":"2023-10-12T12:06:08.821765","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Seed set to 42\n","output_type":"stream"}],"execution_count":24},{"id":"b8b965e1","cell_type":"code","source":"set_seed(42)\n\nseed_everything(seed=42)\n\ntf.random.set_seed(42)\n\n\n\ndef base_model(hidden_units, embedding_size, train_cols, \n\n               categorical_cols, uniques):\n\n\n\n    n_cont=0\n\n    initial_inputs=[]\n\n    for col in categorical_cols:\n\n        temp_input = keras.Input(shape=(1,), name=col)\n\n        n_cont+=1\n\n        initial_inputs.append(temp_input)\n\n        \n\n    num_input = keras.Input(shape=(len(train_cols)-n_cont,), name='num_data')\n\n    initial_inputs.append(num_input)\n\n\n\n    #embedding, flatenning and concatenating\n\n    all_inputs=[]\n\n    for i, col in enumerate(categorical_cols):\n\n        temp_embedded = keras.layers.Embedding(int(uniques[col]), embedding_size, \n\n                                               input_length=1, name=f'{col}_embedding')(initial_inputs[i])\n\n        temp_flattened = keras.layers.Flatten()(temp_embedded)\n\n        all_inputs.append(temp_flattened)\n\n    \n\n    all_inputs.append(num_input)\n\n    out = keras.layers.Concatenate()(all_inputs)\n\n    \n\n    # Add one or more hidden layers\n\n    for n_hidden in hidden_units:\n\n        out = keras.layers.Dense(n_hidden, activation='swish')(out)\n\n\n\n    # A single output: our predicted rating\n\n    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n\n\n\n    model = keras.Model(inputs = initial_inputs, outputs = out)\n\n    \n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:53:24.917841Z","iopub.execute_input":"2024-11-07T10:53:24.918344Z","iopub.status.idle":"2024-11-07T10:53:24.930999Z","shell.execute_reply.started":"2024-11-07T10:53:24.918287Z","shell.execute_reply":"2024-11-07T10:53:24.929825Z"},"papermill":{"duration":0.043103,"end_time":"2023-10-12T12:06:08.951232","exception":false,"start_time":"2023-10-12T12:06:08.908129","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Seed set to 42\n","output_type":"stream"}],"execution_count":25},{"id":"9db379bf","cell_type":"code","source":"set_seed(42)\n\nseed_everything(seed=42)\n\ntf.random.set_seed(42)\n\n\n\ndef fit_keras_nn(Nfolds, train_df, test_df, train_cols, cat_cols, TARGET, \n\n                   model_path):\n\n    \n\n    model_name = 'Keras_NN'\n\n    oof_keras = np.zeros(train_df.shape[0])\n\n    pred_keras = np.zeros(test_df.shape[0])\n\n    scores=[]\n\n    scores_pvt = []\n\n    \n\n    train_df = train_df.copy()\n\n    test_df = test_df.copy()\n\n    train_df = train_df.fillna(0)\n\n    test_df = test_df.fillna(0)\n\n    \n\n    cont_cols = train_cols.copy()\n\n    uniques={}\n\n    for col in cat_cols:\n\n        cont_cols.remove(col)\n\n        le = LabelEncoder()\n\n        le.fit(pd.concat([train_df[col], test_df[col]]))\n\n        train_df[col] = le.transform(train_df[col].values)\n\n        test_df[col] = le.transform(test_df[col].values)\n\n        uniques[col] = len(pd.concat([train_df[col], test_df[col]], axis=0).unique())\n\n        \n\n    scaler = StandardScaler().fit(pd.concat([train_df[cont_cols], test_df[cont_cols]], axis=0))       \n\n    train_df[cont_cols] = scaler.transform(train_df[cont_cols].values)\n\n    test_df[cont_cols] = scaler.transform(test_df[cont_cols].values)\n\n    \n\n    test_inputs=[]\n\n    for col in cat_cols:\n\n        test_inputs.append(test_df[col].values)\n\n        \n\n    test_inputs.append(test_df[cont_cols].values)\n\n    \n\n    for fold in range(Nfolds):\n\n        \n\n        print(\"*\"*10, f'Fold-{fold+1}', \"*\"*10,)\n\n      \n\n        X_train = train_df.loc[train_df.fold!=fold, train_cols]\n\n        y_train = train_df.loc[train_df.fold!=fold, TARGET]\n\n        X_val = train_df.loc[train_df.fold==fold, train_cols]\n\n        y_val = train_df.loc[train_df.fold==fold, TARGET]\n\n        \n\n        model = base_model(hidden_units=(256, 512, 1024, 512, 256), embedding_size=16, #16\n\n                           train_cols=train_cols, categorical_cols=cat_cols, \n\n                          uniques=uniques)\n\n    \n\n        model.compile(\n\n            keras.optimizers.Adam(learning_rate=0.002),\n\n            loss=mean_absolute_error\n\n        )\n\n\n\n\n\n        train_inputs=[]\n\n        for col in cat_cols:\n\n            train_inputs.append(X_train[col].values)\n\n    \n\n        train_inputs.append(X_train[cont_cols].values)\n\n\n\n        val_inputs=[]\n\n        for col in cat_cols:\n\n            val_inputs.append(X_val[col].values)\n\n\n\n        val_inputs.append(X_val[cont_cols].values)\n\n        \n\n#         if os.path.isfile(model_path + f'{model_name}_{fold}.h5'):\n\n#             model =  keras.models.load_model(model_path + f'{model_name}_{fold}.h5', \n\n#                                              custom_objects={'swish': swish, 'Activation': Activation, \n\n#                                                              'mean_absolute_error':mean_absolute_error})\n\n        \n\n#         else:\n\n\n\n        model.fit(train_inputs, \n\n                  y_train.values,               \n\n                  batch_size=1024,\n\n                  epochs=1000,\n\n                  validation_data=(val_inputs, y_val.values),\n\n                  callbacks=[es, plateau],\n\n                  validation_batch_size=len(y_val),\n\n                  shuffle=True, verbose = 1)\n\n\n\n        model.save(f\"{model_name}_{fold}.h5\")\n\n            \n\n        preds = model.predict(val_inputs).reshape(1,-1)[0]\n\n        \n\n        score = mean_absolute_error(y_val.values, preds)\n\n        score_pvt = mean_absolute_percentage_error(y_val.values, preds)\n\n        scores.append(score)\n\n        scores_pvt.append(score_pvt)\n\n        oof_keras[X_val.index] = preds\n\n        \n\n        print(f'MAE for Fold-{fold+1}:', np.round(score, 3))\n\n        print(f'MAPE for Fold-{fold+1}:', np.round(score_pvt, 3))\n\n        \n\n        pred_keras += model.predict(test_inputs).reshape(1,-1)[0]/Nfolds\n\n        \n\n    score = mean_absolute_error(train_df[TARGET],oof_keras)\n\n    score_pvt = mean_absolute_percentage_error(train_df[TARGET],oof_keras)\n\n    print(f'OOF MAE:', np.round(score, 3))\n\n    print(f'Average MAE:', f'{np.round(np.mean(scores), 3)}+/-{np.round(np.std(scores), 3)}')\n\n    print(f'OOF MAPE:', np.round(score_pvt, 3))\n\n    print(f'Average MAPE:', f'{np.round(np.mean(scores_pvt), 3)}+/-{np.round(np.std(scores_pvt), 3)}')\n\n    \n\n        \n\n    return oof_keras, pred_keras","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:53:27.940216Z","iopub.execute_input":"2024-11-07T10:53:27.940602Z","iopub.status.idle":"2024-11-07T10:53:27.964119Z","shell.execute_reply.started":"2024-11-07T10:53:27.940564Z","shell.execute_reply":"2024-11-07T10:53:27.963017Z"},"papermill":{"duration":0.052968,"end_time":"2023-10-12T12:06:09.037231","exception":false,"start_time":"2023-10-12T12:06:08.984263","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Seed set to 42\n","output_type":"stream"}],"execution_count":26},{"id":"b7fe9117","cell_type":"code","source":"set_seed(42)\n\nseed_everything(seed=42)\n\ntf.random.set_seed(42)\n\n\n\nif Inference:\n\n    model_path = '../input/ecm-output-of-final-notebook/'\n\nelse:\n\n    model_path = './'\n\n    \n\noof_pred_keras, pred_keras = fit_keras_nn(Nfold, train_df, test_df, train_cols, categorical_cols, TARGET, model_path)\n\ntrain_df = train_df.copy()\n\ntrain_df['oof_keras'] = oof_pred_keras","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:53:57.843493Z","iopub.execute_input":"2024-11-07T10:53:57.843883Z","iopub.status.idle":"2024-11-07T10:58:42.399581Z","shell.execute_reply.started":"2024-11-07T10:53:57.843846Z","shell.execute_reply":"2024-11-07T10:58:42.398502Z"},"papermill":{"duration":907.127569,"end_time":"2023-10-12T12:21:16.205130","exception":false,"start_time":"2023-10-12T12:06:09.077561","status":"completed"},"tags":[],"trusted":true,"scrolled":true},"outputs":[{"name":"stdout","text":"Seed set to 42\n********** Fold-1 **********\nEpoch 1/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 11.4270 - val_loss: 1.6944 - learning_rate: 0.0020\nEpoch 2/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6058 - val_loss: 1.3935 - learning_rate: 0.0020\nEpoch 3/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3655 - val_loss: 1.3460 - learning_rate: 0.0020\nEpoch 4/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3629 - val_loss: 1.4440 - learning_rate: 0.0020\nEpoch 5/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3062 - val_loss: 1.3163 - learning_rate: 0.0020\nEpoch 6/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2773 - val_loss: 1.4146 - learning_rate: 0.0020\nEpoch 7/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2240 - val_loss: 1.1664 - learning_rate: 0.0020\nEpoch 8/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1921 - val_loss: 1.2611 - learning_rate: 0.0020\nEpoch 9/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1818 - val_loss: 1.1711 - learning_rate: 0.0020\nEpoch 10/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1672 - val_loss: 1.1839 - learning_rate: 0.0020\nEpoch 11/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1815 - val_loss: 1.2013 - learning_rate: 0.0020\nEpoch 12/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1456 - val_loss: 1.1876 - learning_rate: 0.0020\nEpoch 13/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1537 - val_loss: 1.1513 - learning_rate: 0.0020\nEpoch 14/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0925 - val_loss: 1.1213 - learning_rate: 0.0020\nEpoch 15/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0794 - val_loss: 1.1115 - learning_rate: 0.0020\nEpoch 16/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0574 - val_loss: 1.2696 - learning_rate: 0.0020\nEpoch 17/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0894 - val_loss: 1.0884 - learning_rate: 0.0020\nEpoch 18/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0411 - val_loss: 1.0898 - learning_rate: 0.0020\nEpoch 19/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0841 - val_loss: 1.4672 - learning_rate: 0.0020\nEpoch 20/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3584 - val_loss: 1.1099 - learning_rate: 0.0020\nEpoch 21/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0565 - val_loss: 1.0721 - learning_rate: 0.0020\nEpoch 22/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9980 - val_loss: 1.0812 - learning_rate: 0.0020\nEpoch 23/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9892 - val_loss: 1.1276 - learning_rate: 0.0020\nEpoch 24/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.0150 - val_loss: 1.0483 - learning_rate: 0.0020\nEpoch 25/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9706 - val_loss: 1.0919 - learning_rate: 0.0020\nEpoch 26/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9856 - val_loss: 1.0956 - learning_rate: 0.0020\nEpoch 27/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0082 - val_loss: 1.0198 - learning_rate: 0.0020\nEpoch 28/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9610 - val_loss: 1.0398 - learning_rate: 0.0020\nEpoch 29/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9970 - val_loss: 1.0701 - learning_rate: 0.0020\nEpoch 30/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9580 - val_loss: 1.0337 - learning_rate: 0.0020\nEpoch 31/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9452 - val_loss: 1.0312 - learning_rate: 0.0020\nEpoch 32/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9602 - val_loss: 1.0708 - learning_rate: 0.0020\nEpoch 33/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9397 - val_loss: 1.0106 - learning_rate: 0.0020\nEpoch 34/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9512 - val_loss: 1.0534 - learning_rate: 0.0020\nEpoch 35/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9479 - val_loss: 1.0224 - learning_rate: 0.0020\nEpoch 36/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9253 - val_loss: 1.0215 - learning_rate: 0.0020\nEpoch 37/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9346 - val_loss: 1.0393 - learning_rate: 0.0020\nEpoch 38/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9357 - val_loss: 1.0347 - learning_rate: 0.0020\nEpoch 39/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9122 - val_loss: 1.0425 - learning_rate: 0.0020\nEpoch 40/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9095 - val_loss: 0.9991 - learning_rate: 0.0020\nEpoch 41/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8964 - val_loss: 0.9921 - learning_rate: 0.0020\nEpoch 42/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8995 - val_loss: 0.9898 - learning_rate: 0.0020\nEpoch 43/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9260 - val_loss: 1.2599 - learning_rate: 0.0020\nEpoch 44/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0420 - val_loss: 1.0549 - learning_rate: 0.0020\nEpoch 45/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9210 - val_loss: 1.1137 - learning_rate: 0.0020\nEpoch 46/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0131 - val_loss: 1.0208 - learning_rate: 0.0020\nEpoch 47/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9151 - val_loss: 1.0862 - learning_rate: 0.0020\nEpoch 48/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9190 - val_loss: 1.1828 - learning_rate: 0.0020\nEpoch 49/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9689 - val_loss: 1.0504 - learning_rate: 0.0020\nEpoch 50/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8677 - val_loss: 1.0742 - learning_rate: 0.0020\nEpoch 51/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8530 - val_loss: 0.9337 - learning_rate: 5.0000e-04\nEpoch 52/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7885 - val_loss: 0.9296 - learning_rate: 5.0000e-04\nEpoch 53/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7803 - val_loss: 0.9269 - learning_rate: 5.0000e-04\nEpoch 54/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7748 - val_loss: 0.9252 - learning_rate: 5.0000e-04\nEpoch 55/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7722 - val_loss: 0.9250 - learning_rate: 5.0000e-04\nEpoch 56/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7678 - val_loss: 0.9223 - learning_rate: 5.0000e-04\nEpoch 57/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7634 - val_loss: 0.9269 - learning_rate: 5.0000e-04\nEpoch 58/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7627 - val_loss: 0.9229 - learning_rate: 5.0000e-04\nEpoch 59/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7584 - val_loss: 0.9290 - learning_rate: 5.0000e-04\nEpoch 60/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7565 - val_loss: 0.9255 - learning_rate: 5.0000e-04\nEpoch 61/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7533 - val_loss: 0.9252 - learning_rate: 5.0000e-04\nEpoch 62/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7532 - val_loss: 0.9267 - learning_rate: 5.0000e-04\nEpoch 63/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7533 - val_loss: 0.9257 - learning_rate: 5.0000e-04\nEpoch 64/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7506 - val_loss: 0.9268 - learning_rate: 5.0000e-04\nEpoch 65/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7375 - val_loss: 0.9069 - learning_rate: 1.2500e-04\nEpoch 66/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7318 - val_loss: 0.9050 - learning_rate: 1.2500e-04\nEpoch 67/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7282 - val_loss: 0.9048 - learning_rate: 1.2500e-04\nEpoch 68/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7260 - val_loss: 0.9042 - learning_rate: 1.2500e-04\nEpoch 69/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7242 - val_loss: 0.9027 - learning_rate: 1.2500e-04\nEpoch 70/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7231 - val_loss: 0.9022 - learning_rate: 1.2500e-04\nEpoch 71/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7214 - val_loss: 0.9037 - learning_rate: 1.2500e-04\nEpoch 72/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7206 - val_loss: 0.9032 - learning_rate: 1.2500e-04\nEpoch 73/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7191 - val_loss: 0.9029 - learning_rate: 1.2500e-04\nEpoch 74/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7175 - val_loss: 0.9019 - learning_rate: 1.2500e-04\nEpoch 75/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7165 - val_loss: 0.9018 - learning_rate: 1.2500e-04\nEpoch 76/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7156 - val_loss: 0.9018 - learning_rate: 1.2500e-04\nEpoch 77/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7148 - val_loss: 0.9022 - learning_rate: 1.2500e-04\nEpoch 78/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7131 - val_loss: 0.9032 - learning_rate: 1.2500e-04\nEpoch 79/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7132 - val_loss: 0.9010 - learning_rate: 1.2500e-04\nEpoch 80/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7110 - val_loss: 0.9018 - learning_rate: 1.2500e-04\nEpoch 81/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7104 - val_loss: 0.9019 - learning_rate: 1.2500e-04\nEpoch 82/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7094 - val_loss: 0.9022 - learning_rate: 1.2500e-04\nEpoch 83/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7082 - val_loss: 0.9009 - learning_rate: 1.2500e-04\nEpoch 84/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7066 - val_loss: 0.9003 - learning_rate: 1.2500e-04\nEpoch 85/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7054 - val_loss: 0.9011 - learning_rate: 1.2500e-04\nEpoch 86/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7042 - val_loss: 0.8990 - learning_rate: 1.2500e-04\nEpoch 87/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7036 - val_loss: 0.9006 - learning_rate: 1.2500e-04\nEpoch 88/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7022 - val_loss: 0.9006 - learning_rate: 1.2500e-04\nEpoch 89/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7020 - val_loss: 0.9008 - learning_rate: 1.2500e-04\nEpoch 90/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7011 - val_loss: 0.9000 - learning_rate: 1.2500e-04\nEpoch 91/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6995 - val_loss: 0.9031 - learning_rate: 1.2500e-04\nEpoch 92/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7004 - val_loss: 0.9000 - learning_rate: 1.2500e-04\nEpoch 93/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6979 - val_loss: 0.9000 - learning_rate: 1.2500e-04\nEpoch 94/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6975 - val_loss: 0.9013 - learning_rate: 1.2500e-04\nEpoch 95/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6961 - val_loss: 0.8979 - learning_rate: 3.1250e-05\nEpoch 96/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6933 - val_loss: 0.8987 - learning_rate: 3.1250e-05\nEpoch 97/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6919 - val_loss: 0.8982 - learning_rate: 3.1250e-05\nEpoch 98/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6912 - val_loss: 0.8985 - learning_rate: 3.1250e-05\nEpoch 99/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6904 - val_loss: 0.8985 - learning_rate: 3.1250e-05\nEpoch 100/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6898 - val_loss: 0.8986 - learning_rate: 3.1250e-05\nEpoch 101/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6893 - val_loss: 0.8988 - learning_rate: 3.1250e-05\nEpoch 102/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6888 - val_loss: 0.8987 - learning_rate: 3.1250e-05\nEpoch 103/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6884 - val_loss: 0.8984 - learning_rate: 3.1250e-05\nEpoch 104/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6868 - val_loss: 0.8969 - learning_rate: 7.8125e-06\nEpoch 105/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6851 - val_loss: 0.8970 - learning_rate: 7.8125e-06\nEpoch 106/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6847 - val_loss: 0.8971 - learning_rate: 7.8125e-06\nEpoch 107/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6843 - val_loss: 0.8972 - learning_rate: 7.8125e-06\nEpoch 108/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6842 - val_loss: 0.8972 - learning_rate: 7.8125e-06\nEpoch 109/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6840 - val_loss: 0.8972 - learning_rate: 7.8125e-06\nEpoch 110/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6838 - val_loss: 0.8972 - learning_rate: 7.8125e-06\nEpoch 111/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6837 - val_loss: 0.8972 - learning_rate: 7.8125e-06\nEpoch 112/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6835 - val_loss: 0.8973 - learning_rate: 7.8125e-06\nEpoch 113/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6829 - val_loss: 0.8976 - learning_rate: 1.9531e-06\nEpoch 114/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6825 - val_loss: 0.8977 - learning_rate: 1.9531e-06\nEpoch 115/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6823 - val_loss: 0.8977 - learning_rate: 1.9531e-06\nEpoch 116/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6822 - val_loss: 0.8977 - learning_rate: 1.9531e-06\nEpoch 117/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6822 - val_loss: 0.8977 - learning_rate: 1.9531e-06\nEpoch 118/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6821 - val_loss: 0.8977 - learning_rate: 1.9531e-06\nEpoch 119/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6821 - val_loss: 0.8977 - learning_rate: 1.9531e-06\nEpoch 120/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6820 - val_loss: 0.8978 - learning_rate: 1.9531e-06\nEpoch 121/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6818 - val_loss: 0.8980 - learning_rate: 4.8828e-07\nEpoch 122/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6817 - val_loss: 0.8980 - learning_rate: 4.8828e-07\nEpoch 123/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6816 - val_loss: 0.8980 - learning_rate: 4.8828e-07\nEpoch 124/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6816 - val_loss: 0.8980 - learning_rate: 4.8828e-07\nEpoch 125/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6816 - val_loss: 0.8980 - learning_rate: 4.8828e-07\nEpoch 126/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6815 - val_loss: 0.8980 - learning_rate: 4.8828e-07\nEpoch 127/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6815 - val_loss: 0.8980 - learning_rate: 4.8828e-07\nEpoch 128/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6815 - val_loss: 0.8980 - learning_rate: 4.8828e-07\nEpoch 129/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 1.2207e-07\nEpoch 130/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 1.2207e-07\nEpoch 131/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 1.2207e-07\nEpoch 132/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 1.2207e-07\nEpoch 133/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 1.2207e-07\nEpoch 134/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 1.2207e-07\nEpoch 135/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 1.2207e-07\nEpoch 136/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 1.2207e-07\nEpoch 137/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 3.0518e-08\nEpoch 138/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 3.0518e-08\nEpoch 139/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 3.0518e-08\nEpoch 140/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 3.0518e-08\nEpoch 141/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 3.0518e-08\nEpoch 142/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 3.0518e-08\nEpoch 143/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 3.0518e-08\nEpoch 144/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6814 - val_loss: 0.8981 - learning_rate: 3.0518e-08\nEpoch 145/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6813 - val_loss: 0.8981 - learning_rate: 7.6294e-09\nEpoch 146/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6813 - val_loss: 0.8981 - learning_rate: 7.6294e-09\nEpoch 147/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6813 - val_loss: 0.8981 - learning_rate: 7.6294e-09\nEpoch 148/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6813 - val_loss: 0.8981 - learning_rate: 7.6294e-09\nEpoch 149/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6813 - val_loss: 0.8981 - learning_rate: 7.6294e-09\nEpoch 150/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6813 - val_loss: 0.8981 - learning_rate: 7.6294e-09\nEpoch 151/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6813 - val_loss: 0.8981 - learning_rate: 7.6294e-09\nEpoch 152/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6813 - val_loss: 0.8981 - learning_rate: 7.6294e-09\nEpoch 153/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6813 - val_loss: 0.8981 - learning_rate: 1.9073e-09\nEpoch 154/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6813 - val_loss: 0.8981 - learning_rate: 1.9073e-09\n\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\nMAE for Fold-1: 0.897\nMAPE for Fold-1: 0.033\n\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n********** Fold-2 **********\nEpoch 1/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 11.2199 - val_loss: 1.7155 - learning_rate: 0.0020\nEpoch 2/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5991 - val_loss: 1.4523 - learning_rate: 0.0020\nEpoch 3/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4194 - val_loss: 1.4122 - learning_rate: 0.0020\nEpoch 4/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4683 - val_loss: 1.4285 - learning_rate: 0.0020\nEpoch 5/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3508 - val_loss: 1.4198 - learning_rate: 0.0020\nEpoch 6/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2284 - val_loss: 1.4944 - learning_rate: 0.0020\nEpoch 7/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2910 - val_loss: 1.2640 - learning_rate: 0.0020\nEpoch 8/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2151 - val_loss: 1.3464 - learning_rate: 0.0020\nEpoch 9/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2067 - val_loss: 1.3993 - learning_rate: 0.0020\nEpoch 10/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2216 - val_loss: 1.2556 - learning_rate: 0.0020\nEpoch 11/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1381 - val_loss: 1.3430 - learning_rate: 0.0020\nEpoch 12/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1428 - val_loss: 1.2457 - learning_rate: 0.0020\nEpoch 13/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1463 - val_loss: 1.2276 - learning_rate: 0.0020\nEpoch 14/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0907 - val_loss: 1.1937 - learning_rate: 0.0020\nEpoch 15/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0732 - val_loss: 1.1720 - learning_rate: 0.0020\nEpoch 16/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0592 - val_loss: 1.1847 - learning_rate: 0.0020\nEpoch 17/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0580 - val_loss: 1.2019 - learning_rate: 0.0020\nEpoch 18/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0487 - val_loss: 1.0985 - learning_rate: 0.0020\nEpoch 19/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0764 - val_loss: 1.1177 - learning_rate: 0.0020\nEpoch 20/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0588 - val_loss: 1.2942 - learning_rate: 0.0020\nEpoch 21/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0789 - val_loss: 1.1549 - learning_rate: 0.0020\nEpoch 22/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0010 - val_loss: 1.1255 - learning_rate: 0.0020\nEpoch 23/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9968 - val_loss: 1.1506 - learning_rate: 0.0020\nEpoch 24/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0655 - val_loss: 1.1944 - learning_rate: 0.0020\nEpoch 25/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2407 - val_loss: 1.1558 - learning_rate: 0.0020\nEpoch 26/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0267 - val_loss: 1.1496 - learning_rate: 0.0020\nEpoch 27/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9488 - val_loss: 1.0136 - learning_rate: 5.0000e-04\nEpoch 28/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8945 - val_loss: 1.0099 - learning_rate: 5.0000e-04\nEpoch 29/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8882 - val_loss: 1.0045 - learning_rate: 5.0000e-04\nEpoch 30/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8824 - val_loss: 1.0031 - learning_rate: 5.0000e-04\nEpoch 31/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8800 - val_loss: 1.0015 - learning_rate: 5.0000e-04\nEpoch 32/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8752 - val_loss: 0.9973 - learning_rate: 5.0000e-04\nEpoch 33/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8696 - val_loss: 0.9938 - learning_rate: 5.0000e-04\nEpoch 34/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8655 - val_loss: 0.9914 - learning_rate: 5.0000e-04\nEpoch 35/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8624 - val_loss: 0.9851 - learning_rate: 5.0000e-04\nEpoch 36/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8589 - val_loss: 0.9850 - learning_rate: 5.0000e-04\nEpoch 37/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8554 - val_loss: 0.9849 - learning_rate: 5.0000e-04\nEpoch 38/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8532 - val_loss: 0.9770 - learning_rate: 5.0000e-04\nEpoch 39/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8521 - val_loss: 0.9867 - learning_rate: 5.0000e-04\nEpoch 40/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8498 - val_loss: 0.9780 - learning_rate: 5.0000e-04\nEpoch 41/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8436 - val_loss: 0.9764 - learning_rate: 5.0000e-04\nEpoch 42/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8407 - val_loss: 0.9762 - learning_rate: 5.0000e-04\nEpoch 43/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8404 - val_loss: 0.9780 - learning_rate: 5.0000e-04\nEpoch 44/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8373 - val_loss: 0.9801 - learning_rate: 5.0000e-04\nEpoch 45/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8360 - val_loss: 0.9713 - learning_rate: 5.0000e-04\nEpoch 46/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8318 - val_loss: 0.9726 - learning_rate: 5.0000e-04\nEpoch 47/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8304 - val_loss: 0.9746 - learning_rate: 5.0000e-04\nEpoch 48/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8300 - val_loss: 0.9643 - learning_rate: 5.0000e-04\nEpoch 49/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8292 - val_loss: 0.9760 - learning_rate: 5.0000e-04\nEpoch 50/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8227 - val_loss: 0.9677 - learning_rate: 5.0000e-04\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\nMAE for Fold-2: 1.716\nMAPE for Fold-2: 0.068\n\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n********** Fold-3 **********\nEpoch 1/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 11.2516 - val_loss: 1.7070 - learning_rate: 0.0020\nEpoch 2/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5312 - val_loss: 1.4274 - learning_rate: 0.0020\nEpoch 3/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3541 - val_loss: 1.4366 - learning_rate: 0.0020\nEpoch 4/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3520 - val_loss: 1.2653 - learning_rate: 0.0020\nEpoch 5/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2199 - val_loss: 1.2334 - learning_rate: 0.0020\nEpoch 6/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2292 - val_loss: 1.2775 - learning_rate: 0.0020\nEpoch 7/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2029 - val_loss: 1.1952 - learning_rate: 0.0020\nEpoch 8/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1394 - val_loss: 1.1843 - learning_rate: 0.0020\nEpoch 9/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1114 - val_loss: 1.1645 - learning_rate: 0.0020\nEpoch 10/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1377 - val_loss: 1.2836 - learning_rate: 0.0020\nEpoch 11/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0948 - val_loss: 1.1439 - learning_rate: 0.0020\nEpoch 12/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1189 - val_loss: 1.1302 - learning_rate: 0.0020\nEpoch 13/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1029 - val_loss: 1.1030 - learning_rate: 0.0020\nEpoch 14/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0893 - val_loss: 1.1223 - learning_rate: 0.0020\nEpoch 15/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0496 - val_loss: 1.1545 - learning_rate: 0.0020\nEpoch 16/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0549 - val_loss: 1.1179 - learning_rate: 0.0020\nEpoch 17/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0641 - val_loss: 1.1471 - learning_rate: 0.0020\nEpoch 18/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0419 - val_loss: 1.1470 - learning_rate: 0.0020\nEpoch 19/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1554 - val_loss: 1.2326 - learning_rate: 0.0020\nEpoch 20/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1954 - val_loss: 1.1427 - learning_rate: 0.0020\nEpoch 21/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0119 - val_loss: 1.1305 - learning_rate: 0.0020\nEpoch 22/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9449 - val_loss: 1.0109 - learning_rate: 5.0000e-04\nEpoch 23/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9187 - val_loss: 1.0059 - learning_rate: 5.0000e-04\nEpoch 24/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9123 - val_loss: 1.0038 - learning_rate: 5.0000e-04\nEpoch 25/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9081 - val_loss: 1.0005 - learning_rate: 5.0000e-04\nEpoch 26/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9051 - val_loss: 0.9985 - learning_rate: 5.0000e-04\nEpoch 27/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9011 - val_loss: 0.9919 - learning_rate: 5.0000e-04\nEpoch 28/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8984 - val_loss: 0.9968 - learning_rate: 5.0000e-04\nEpoch 29/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8935 - val_loss: 0.9922 - learning_rate: 5.0000e-04\nEpoch 30/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8925 - val_loss: 0.9879 - learning_rate: 5.0000e-04\nEpoch 31/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8917 - val_loss: 0.9881 - learning_rate: 5.0000e-04\nEpoch 32/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8931 - val_loss: 0.9886 - learning_rate: 5.0000e-04\nEpoch 33/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8840 - val_loss: 0.9884 - learning_rate: 5.0000e-04\nEpoch 34/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8837 - val_loss: 0.9801 - learning_rate: 5.0000e-04\nEpoch 35/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8811 - val_loss: 0.9734 - learning_rate: 5.0000e-04\nEpoch 36/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8761 - val_loss: 0.9781 - learning_rate: 5.0000e-04\nEpoch 37/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8766 - val_loss: 0.9752 - learning_rate: 5.0000e-04\nEpoch 38/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8731 - val_loss: 0.9846 - learning_rate: 5.0000e-04\nEpoch 39/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8722 - val_loss: 0.9745 - learning_rate: 5.0000e-04\nEpoch 40/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8674 - val_loss: 0.9882 - learning_rate: 5.0000e-04\nEpoch 41/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8702 - val_loss: 0.9791 - learning_rate: 5.0000e-04\nEpoch 42/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8639 - val_loss: 0.9813 - learning_rate: 5.0000e-04\nEpoch 43/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8628 - val_loss: 0.9734 - learning_rate: 5.0000e-04\nEpoch 44/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8525 - val_loss: 0.9571 - learning_rate: 1.2500e-04\nEpoch 45/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8450 - val_loss: 0.9575 - learning_rate: 1.2500e-04\nEpoch 46/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8406 - val_loss: 0.9576 - learning_rate: 1.2500e-04\nEpoch 47/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8396 - val_loss: 0.9573 - learning_rate: 1.2500e-04\nEpoch 48/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8383 - val_loss: 0.9576 - learning_rate: 1.2500e-04\nEpoch 49/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8371 - val_loss: 0.9561 - learning_rate: 1.2500e-04\nEpoch 50/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8347 - val_loss: 0.9573 - learning_rate: 1.2500e-04\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nMAE for Fold-3: 1.707\nMAPE for Fold-3: 0.066\n\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n********** Fold-4 **********\nEpoch 1/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 11.2970 - val_loss: 1.4239 - learning_rate: 0.0020\nEpoch 2/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5717 - val_loss: 1.3408 - learning_rate: 0.0020\nEpoch 3/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6069 - val_loss: 1.2245 - learning_rate: 0.0020\nEpoch 4/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3427 - val_loss: 1.1474 - learning_rate: 0.0020\nEpoch 5/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2965 - val_loss: 1.0962 - learning_rate: 0.0020\nEpoch 6/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2671 - val_loss: 1.0934 - learning_rate: 0.0020\nEpoch 7/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2101 - val_loss: 1.0949 - learning_rate: 0.0020\nEpoch 8/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2003 - val_loss: 1.0760 - learning_rate: 0.0020\nEpoch 9/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1947 - val_loss: 1.1821 - learning_rate: 0.0020\nEpoch 10/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1970 - val_loss: 1.0892 - learning_rate: 0.0020\nEpoch 11/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1769 - val_loss: 1.0040 - learning_rate: 0.0020\nEpoch 12/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1146 - val_loss: 1.0286 - learning_rate: 0.0020\nEpoch 13/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1431 - val_loss: 1.2260 - learning_rate: 0.0020\nEpoch 14/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1349 - val_loss: 1.2435 - learning_rate: 0.0020\nEpoch 15/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1931 - val_loss: 0.9811 - learning_rate: 0.0020\nEpoch 16/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0662 - val_loss: 0.9845 - learning_rate: 0.0020\nEpoch 17/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.0508 - val_loss: 0.9798 - learning_rate: 0.0020\nEpoch 18/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0705 - val_loss: 0.9705 - learning_rate: 0.0020\nEpoch 19/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0540 - val_loss: 1.1512 - learning_rate: 0.0020\nEpoch 20/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1723 - val_loss: 1.0086 - learning_rate: 0.0020\nEpoch 21/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0418 - val_loss: 0.9707 - learning_rate: 0.0020\nEpoch 22/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0232 - val_loss: 1.2168 - learning_rate: 0.0020\nEpoch 23/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0646 - val_loss: 1.0366 - learning_rate: 0.0020\nEpoch 24/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9990 - val_loss: 0.9403 - learning_rate: 0.0020\nEpoch 25/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9887 - val_loss: 0.9345 - learning_rate: 0.0020\nEpoch 26/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9736 - val_loss: 1.1522 - learning_rate: 0.0020\nEpoch 27/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0531 - val_loss: 1.0899 - learning_rate: 0.0020\nEpoch 28/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9885 - val_loss: 1.0013 - learning_rate: 0.0020\nEpoch 29/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9741 - val_loss: 1.0350 - learning_rate: 0.0020\nEpoch 30/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9978 - val_loss: 0.9022 - learning_rate: 0.0020\nEpoch 31/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9549 - val_loss: 0.9119 - learning_rate: 0.0020\nEpoch 32/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9723 - val_loss: 0.9102 - learning_rate: 0.0020\nEpoch 33/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9308 - val_loss: 0.9529 - learning_rate: 0.0020\nEpoch 34/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9487 - val_loss: 1.0206 - learning_rate: 0.0020\nEpoch 35/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9608 - val_loss: 0.9458 - learning_rate: 0.0020\nEpoch 36/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9156 - val_loss: 0.8940 - learning_rate: 0.0020\nEpoch 37/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9392 - val_loss: 1.0690 - learning_rate: 0.0020\nEpoch 38/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9742 - val_loss: 1.0002 - learning_rate: 0.0020\nEpoch 39/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9567 - val_loss: 0.9280 - learning_rate: 0.0020\nEpoch 40/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9119 - val_loss: 0.9078 - learning_rate: 0.0020\nEpoch 41/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9176 - val_loss: 0.9044 - learning_rate: 0.0020\nEpoch 42/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9156 - val_loss: 0.9629 - learning_rate: 0.0020\nEpoch 43/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0452 - val_loss: 0.9503 - learning_rate: 0.0020\nEpoch 44/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9058 - val_loss: 0.8705 - learning_rate: 0.0020\nEpoch 45/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8920 - val_loss: 0.8741 - learning_rate: 0.0020\nEpoch 46/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8995 - val_loss: 0.8718 - learning_rate: 0.0020\nEpoch 47/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8748 - val_loss: 0.9007 - learning_rate: 0.0020\nEpoch 48/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9239 - val_loss: 0.8808 - learning_rate: 0.0020\nEpoch 49/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8896 - val_loss: 0.9324 - learning_rate: 0.0020\nEpoch 50/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8919 - val_loss: 0.8806 - learning_rate: 0.0020\nEpoch 51/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8675 - val_loss: 0.9016 - learning_rate: 0.0020\nEpoch 52/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8874 - val_loss: 0.8737 - learning_rate: 0.0020\nEpoch 53/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8105 - val_loss: 0.8193 - learning_rate: 5.0000e-04\nEpoch 54/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7804 - val_loss: 0.8131 - learning_rate: 5.0000e-04\nEpoch 55/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7732 - val_loss: 0.8104 - learning_rate: 5.0000e-04\nEpoch 56/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7661 - val_loss: 0.8165 - learning_rate: 5.0000e-04\nEpoch 57/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7653 - val_loss: 0.8095 - learning_rate: 5.0000e-04\nEpoch 58/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7628 - val_loss: 0.8148 - learning_rate: 5.0000e-04\nEpoch 59/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7587 - val_loss: 0.8077 - learning_rate: 5.0000e-04\nEpoch 60/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7563 - val_loss: 0.8102 - learning_rate: 5.0000e-04\nEpoch 61/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7565 - val_loss: 0.8077 - learning_rate: 5.0000e-04\nEpoch 62/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7537 - val_loss: 0.8107 - learning_rate: 5.0000e-04\nEpoch 63/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7515 - val_loss: 0.8116 - learning_rate: 5.0000e-04\nEpoch 64/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7475 - val_loss: 0.8129 - learning_rate: 5.0000e-04\nEpoch 65/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7494 - val_loss: 0.8126 - learning_rate: 5.0000e-04\nEpoch 66/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7454 - val_loss: 0.8149 - learning_rate: 5.0000e-04\nEpoch 67/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7455 - val_loss: 0.8138 - learning_rate: 5.0000e-04\nEpoch 68/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7341 - val_loss: 0.7820 - learning_rate: 1.2500e-04\nEpoch 69/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7241 - val_loss: 0.7801 - learning_rate: 1.2500e-04\nEpoch 70/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7210 - val_loss: 0.7800 - learning_rate: 1.2500e-04\nEpoch 71/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7183 - val_loss: 0.7798 - learning_rate: 1.2500e-04\nEpoch 72/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7161 - val_loss: 0.7804 - learning_rate: 1.2500e-04\nEpoch 73/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7140 - val_loss: 0.7794 - learning_rate: 1.2500e-04\nEpoch 74/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7132 - val_loss: 0.7800 - learning_rate: 1.2500e-04\nEpoch 75/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7109 - val_loss: 0.7803 - learning_rate: 1.2500e-04\nEpoch 76/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7100 - val_loss: 0.7799 - learning_rate: 1.2500e-04\nEpoch 77/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7094 - val_loss: 0.7795 - learning_rate: 1.2500e-04\nEpoch 78/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7074 - val_loss: 0.7809 - learning_rate: 1.2500e-04\nEpoch 79/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7066 - val_loss: 0.7808 - learning_rate: 1.2500e-04\nEpoch 80/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7055 - val_loss: 0.7803 - learning_rate: 1.2500e-04\nEpoch 81/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7033 - val_loss: 0.7809 - learning_rate: 1.2500e-04\nEpoch 82/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7018 - val_loss: 0.7769 - learning_rate: 3.1250e-05\nEpoch 83/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6996 - val_loss: 0.7766 - learning_rate: 3.1250e-05\nEpoch 84/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6980 - val_loss: 0.7766 - learning_rate: 3.1250e-05\nEpoch 85/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6972 - val_loss: 0.7761 - learning_rate: 3.1250e-05\nEpoch 86/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6960 - val_loss: 0.7765 - learning_rate: 3.1250e-05\nEpoch 87/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6957 - val_loss: 0.7761 - learning_rate: 3.1250e-05\nEpoch 88/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6949 - val_loss: 0.7767 - learning_rate: 3.1250e-05\nEpoch 89/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6944 - val_loss: 0.7765 - learning_rate: 3.1250e-05\nEpoch 90/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6941 - val_loss: 0.7768 - learning_rate: 3.1250e-05\nEpoch 91/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6937 - val_loss: 0.7761 - learning_rate: 3.1250e-05\nEpoch 92/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6930 - val_loss: 0.7765 - learning_rate: 3.1250e-05\nEpoch 93/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6932 - val_loss: 0.7754 - learning_rate: 3.1250e-05\nEpoch 94/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6922 - val_loss: 0.7757 - learning_rate: 3.1250e-05\nEpoch 95/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6915 - val_loss: 0.7758 - learning_rate: 3.1250e-05\nEpoch 96/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6915 - val_loss: 0.7755 - learning_rate: 3.1250e-05\nEpoch 97/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6910 - val_loss: 0.7752 - learning_rate: 3.1250e-05\nEpoch 98/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6905 - val_loss: 0.7751 - learning_rate: 3.1250e-05\nEpoch 99/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6900 - val_loss: 0.7752 - learning_rate: 3.1250e-05\nEpoch 100/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6894 - val_loss: 0.7757 - learning_rate: 3.1250e-05\nEpoch 101/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6896 - val_loss: 0.7750 - learning_rate: 3.1250e-05\nEpoch 102/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6891 - val_loss: 0.7745 - learning_rate: 3.1250e-05\nEpoch 103/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6880 - val_loss: 0.7752 - learning_rate: 3.1250e-05\nEpoch 104/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6886 - val_loss: 0.7749 - learning_rate: 3.1250e-05\nEpoch 105/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6874 - val_loss: 0.7751 - learning_rate: 3.1250e-05\nEpoch 106/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6872 - val_loss: 0.7749 - learning_rate: 3.1250e-05\nEpoch 107/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6867 - val_loss: 0.7754 - learning_rate: 3.1250e-05\nEpoch 108/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6862 - val_loss: 0.7751 - learning_rate: 3.1250e-05\nEpoch 109/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6861 - val_loss: 0.7755 - learning_rate: 3.1250e-05\nEpoch 110/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6863 - val_loss: 0.7751 - learning_rate: 3.1250e-05\nEpoch 111/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6870 - val_loss: 0.7729 - learning_rate: 7.8125e-06\nEpoch 112/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6848 - val_loss: 0.7727 - learning_rate: 7.8125e-06\nEpoch 113/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6844 - val_loss: 0.7727 - learning_rate: 7.8125e-06\nEpoch 114/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6838 - val_loss: 0.7728 - learning_rate: 7.8125e-06\nEpoch 115/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6836 - val_loss: 0.7727 - learning_rate: 7.8125e-06\nEpoch 116/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6832 - val_loss: 0.7726 - learning_rate: 7.8125e-06\nEpoch 117/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6831 - val_loss: 0.7727 - learning_rate: 7.8125e-06\nEpoch 118/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6827 - val_loss: 0.7726 - learning_rate: 7.8125e-06\nEpoch 119/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6825 - val_loss: 0.7727 - learning_rate: 7.8125e-06\nEpoch 120/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6822 - val_loss: 0.7728 - learning_rate: 7.8125e-06\nEpoch 121/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6820 - val_loss: 0.7728 - learning_rate: 7.8125e-06\nEpoch 122/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6819 - val_loss: 0.7728 - learning_rate: 7.8125e-06\nEpoch 123/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6816 - val_loss: 0.7727 - learning_rate: 7.8125e-06\nEpoch 124/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6815 - val_loss: 0.7729 - learning_rate: 7.8125e-06\nEpoch 125/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6813 - val_loss: 0.7729 - learning_rate: 7.8125e-06\nEpoch 126/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6812 - val_loss: 0.7730 - learning_rate: 7.8125e-06\nEpoch 127/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6807 - val_loss: 0.7727 - learning_rate: 1.9531e-06\nEpoch 128/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6793 - val_loss: 0.7727 - learning_rate: 1.9531e-06\nEpoch 129/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.6791 - val_loss: 0.7727 - learning_rate: 1.9531e-06\nEpoch 130/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6790 - val_loss: 0.7728 - learning_rate: 1.9531e-06\nEpoch 131/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6789 - val_loss: 0.7728 - learning_rate: 1.9531e-06\nEpoch 132/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6788 - val_loss: 0.7728 - learning_rate: 1.9531e-06\nEpoch 133/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6787 - val_loss: 0.7728 - learning_rate: 1.9531e-06\nEpoch 134/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6787 - val_loss: 0.7728 - learning_rate: 1.9531e-06\nEpoch 135/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6784 - val_loss: 0.7726 - learning_rate: 4.8828e-07\nEpoch 136/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6784 - val_loss: 0.7726 - learning_rate: 4.8828e-07\nEpoch 137/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6783 - val_loss: 0.7726 - learning_rate: 4.8828e-07\nEpoch 138/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6783 - val_loss: 0.7726 - learning_rate: 4.8828e-07\nEpoch 139/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6783 - val_loss: 0.7726 - learning_rate: 4.8828e-07\nEpoch 140/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6783 - val_loss: 0.7727 - learning_rate: 4.8828e-07\nEpoch 141/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6782 - val_loss: 0.7727 - learning_rate: 4.8828e-07\nEpoch 142/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6782 - val_loss: 0.7727 - learning_rate: 4.8828e-07\nEpoch 143/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6782 - val_loss: 0.7726 - learning_rate: 1.2207e-07\nEpoch 144/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 1.2207e-07\nEpoch 145/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 1.2207e-07\nEpoch 146/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 1.2207e-07\nEpoch 147/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 1.2207e-07\nEpoch 148/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 1.2207e-07\nEpoch 149/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 1.2207e-07\nEpoch 150/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 1.2207e-07\nEpoch 151/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 3.0518e-08\nEpoch 152/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 3.0518e-08\nEpoch 153/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 3.0518e-08\nEpoch 154/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 3.0518e-08\nEpoch 155/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 3.0518e-08\nEpoch 156/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 3.0518e-08\nEpoch 157/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 3.0518e-08\nEpoch 158/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 3.0518e-08\nEpoch 159/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 7.6294e-09\nEpoch 160/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 7.6294e-09\nEpoch 161/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 7.6294e-09\nEpoch 162/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 7.6294e-09\nEpoch 163/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 7.6294e-09\nEpoch 164/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 7.6294e-09\nEpoch 165/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 7.6294e-09\nEpoch 166/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 7.6294e-09\nEpoch 167/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 1.9073e-09\nEpoch 168/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - val_loss: 0.7726 - learning_rate: 1.9073e-09\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\nMAE for Fold-4: 0.773\nMAPE for Fold-4: 0.032\n\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n********** Fold-5 **********\nEpoch 1/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 11.7126 - val_loss: 1.6370 - learning_rate: 0.0020\nEpoch 2/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6069 - val_loss: 1.7949 - learning_rate: 0.0020\nEpoch 3/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5852 - val_loss: 1.3408 - learning_rate: 0.0020\nEpoch 4/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3261 - val_loss: 1.7794 - learning_rate: 0.0020\nEpoch 5/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5834 - val_loss: 1.2770 - learning_rate: 0.0020\nEpoch 6/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2174 - val_loss: 1.3197 - learning_rate: 0.0020\nEpoch 7/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2163 - val_loss: 1.4796 - learning_rate: 0.0020\nEpoch 8/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2239 - val_loss: 1.3115 - learning_rate: 0.0020\nEpoch 9/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1656 - val_loss: 1.4617 - learning_rate: 0.0020\nEpoch 10/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1750 - val_loss: 1.2899 - learning_rate: 0.0020\nEpoch 11/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1224 - val_loss: 1.2060 - learning_rate: 0.0020\nEpoch 12/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1569 - val_loss: 1.3314 - learning_rate: 0.0020\nEpoch 13/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1449 - val_loss: 1.3161 - learning_rate: 0.0020\nEpoch 14/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1399 - val_loss: 1.3159 - learning_rate: 0.0020\nEpoch 15/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1201 - val_loss: 1.3728 - learning_rate: 0.0020\nEpoch 16/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1825 - val_loss: 1.0862 - learning_rate: 0.0020\nEpoch 17/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0955 - val_loss: 1.1076 - learning_rate: 0.0020\nEpoch 18/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0283 - val_loss: 1.3688 - learning_rate: 0.0020\nEpoch 19/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3531 - val_loss: 1.1049 - learning_rate: 0.0020\nEpoch 20/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0264 - val_loss: 1.1831 - learning_rate: 0.0020\nEpoch 21/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0373 - val_loss: 1.0657 - learning_rate: 0.0020\nEpoch 22/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0427 - val_loss: 1.0420 - learning_rate: 0.0020\nEpoch 23/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9861 - val_loss: 1.2445 - learning_rate: 0.0020\nEpoch 24/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1099 - val_loss: 1.1654 - learning_rate: 0.0020\nEpoch 25/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0049 - val_loss: 1.0591 - learning_rate: 0.0020\nEpoch 26/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9668 - val_loss: 1.1650 - learning_rate: 0.0020\nEpoch 27/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9761 - val_loss: 1.0580 - learning_rate: 0.0020\nEpoch 28/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9792 - val_loss: 1.0577 - learning_rate: 0.0020\nEpoch 29/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9413 - val_loss: 1.0207 - learning_rate: 0.0020\nEpoch 30/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9325 - val_loss: 1.0744 - learning_rate: 0.0020\nEpoch 31/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9446 - val_loss: 1.2962 - learning_rate: 0.0020\nEpoch 32/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0260 - val_loss: 1.1383 - learning_rate: 0.0020\nEpoch 33/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9487 - val_loss: 1.0731 - learning_rate: 0.0020\nEpoch 34/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9186 - val_loss: 1.0436 - learning_rate: 0.0020\nEpoch 35/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9243 - val_loss: 1.0963 - learning_rate: 0.0020\nEpoch 36/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9450 - val_loss: 1.0160 - learning_rate: 0.0020\nEpoch 37/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9351 - val_loss: 1.1051 - learning_rate: 0.0020\nEpoch 38/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9380 - val_loss: 1.0511 - learning_rate: 0.0020\nEpoch 39/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9108 - val_loss: 1.0577 - learning_rate: 0.0020\nEpoch 40/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8970 - val_loss: 1.1501 - learning_rate: 0.0020\nEpoch 41/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9057 - val_loss: 1.0841 - learning_rate: 0.0020\nEpoch 42/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8960 - val_loss: 1.0576 - learning_rate: 0.0020\nEpoch 43/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9264 - val_loss: 1.0553 - learning_rate: 0.0020\nEpoch 44/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9385 - val_loss: 1.0913 - learning_rate: 0.0020\nEpoch 45/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8671 - val_loss: 0.9275 - learning_rate: 5.0000e-04\nEpoch 46/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8084 - val_loss: 0.9341 - learning_rate: 5.0000e-04\nEpoch 47/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8048 - val_loss: 0.9318 - learning_rate: 5.0000e-04\nEpoch 48/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7965 - val_loss: 0.9304 - learning_rate: 5.0000e-04\nEpoch 49/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7915 - val_loss: 0.9328 - learning_rate: 5.0000e-04\nEpoch 50/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7887 - val_loss: 0.9307 - learning_rate: 5.0000e-04\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nMAE for Fold-5: 1.637\nMAPE for Fold-5: 0.063\n\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n********** Fold-6 **********\nEpoch 1/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 11.5293 - val_loss: 1.6466 - learning_rate: 0.0020\nEpoch 2/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5730 - val_loss: 1.4517 - learning_rate: 0.0020\nEpoch 3/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3768 - val_loss: 1.4061 - learning_rate: 0.0020\nEpoch 4/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3527 - val_loss: 1.2551 - learning_rate: 0.0020\nEpoch 5/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2855 - val_loss: 1.2326 - learning_rate: 0.0020\nEpoch 6/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2658 - val_loss: 1.2204 - learning_rate: 0.0020\nEpoch 7/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2067 - val_loss: 1.2791 - learning_rate: 0.0020\nEpoch 8/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1928 - val_loss: 1.1944 - learning_rate: 0.0020\nEpoch 9/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1971 - val_loss: 1.1379 - learning_rate: 0.0020\nEpoch 10/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1357 - val_loss: 1.1376 - learning_rate: 0.0020\nEpoch 11/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1152 - val_loss: 1.1210 - learning_rate: 0.0020\nEpoch 12/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1072 - val_loss: 1.1308 - learning_rate: 0.0020\nEpoch 13/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1389 - val_loss: 1.2271 - learning_rate: 0.0020\nEpoch 14/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3649 - val_loss: 1.1383 - learning_rate: 0.0020\nEpoch 15/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1535 - val_loss: 1.1490 - learning_rate: 0.0020\nEpoch 16/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1344 - val_loss: 1.1236 - learning_rate: 0.0020\nEpoch 17/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0592 - val_loss: 1.0811 - learning_rate: 0.0020\nEpoch 18/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0415 - val_loss: 1.0629 - learning_rate: 0.0020\nEpoch 19/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0243 - val_loss: 1.0753 - learning_rate: 0.0020\nEpoch 20/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0248 - val_loss: 1.0297 - learning_rate: 0.0020\nEpoch 21/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0077 - val_loss: 1.0319 - learning_rate: 0.0020\nEpoch 22/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0154 - val_loss: 1.0264 - learning_rate: 0.0020\nEpoch 23/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9871 - val_loss: 1.1218 - learning_rate: 0.0020\nEpoch 24/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0128 - val_loss: 1.0401 - learning_rate: 0.0020\nEpoch 25/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9758 - val_loss: 1.0469 - learning_rate: 0.0020\nEpoch 26/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9751 - val_loss: 1.0169 - learning_rate: 0.0020\nEpoch 27/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9826 - val_loss: 0.9845 - learning_rate: 0.0020\nEpoch 28/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9907 - val_loss: 1.0052 - learning_rate: 0.0020\nEpoch 29/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9928 - val_loss: 0.9894 - learning_rate: 0.0020\nEpoch 30/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9757 - val_loss: 1.0493 - learning_rate: 0.0020\nEpoch 31/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9446 - val_loss: 1.0495 - learning_rate: 0.0020\nEpoch 32/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9434 - val_loss: 1.0596 - learning_rate: 0.0020\nEpoch 33/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9693 - val_loss: 0.9910 - learning_rate: 0.0020\nEpoch 34/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9475 - val_loss: 0.9927 - learning_rate: 0.0020\nEpoch 35/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9395 - val_loss: 0.9473 - learning_rate: 0.0020\nEpoch 36/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9017 - val_loss: 0.9474 - learning_rate: 0.0020\nEpoch 37/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9579 - val_loss: 1.0358 - learning_rate: 0.0020\nEpoch 38/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9564 - val_loss: 1.1487 - learning_rate: 0.0020\nEpoch 39/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0013 - val_loss: 0.9628 - learning_rate: 0.0020\nEpoch 40/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9236 - val_loss: 1.0500 - learning_rate: 0.0020\nEpoch 41/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9732 - val_loss: 0.9958 - learning_rate: 0.0020\nEpoch 42/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8946 - val_loss: 1.0712 - learning_rate: 0.0020\nEpoch 43/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9289 - val_loss: 0.9947 - learning_rate: 0.0020\nEpoch 44/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8504 - val_loss: 0.8850 - learning_rate: 5.0000e-04\nEpoch 45/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8062 - val_loss: 0.8863 - learning_rate: 5.0000e-04\nEpoch 46/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8032 - val_loss: 0.8842 - learning_rate: 5.0000e-04\nEpoch 47/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8000 - val_loss: 0.8825 - learning_rate: 5.0000e-04\nEpoch 48/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7958 - val_loss: 0.8818 - learning_rate: 5.0000e-04\nEpoch 49/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7940 - val_loss: 0.8797 - learning_rate: 5.0000e-04\nEpoch 50/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7897 - val_loss: 0.8796 - learning_rate: 5.0000e-04\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nMAE for Fold-6: 1.647\nMAPE for Fold-6: 0.072\n\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n********** Fold-7 **********\nEpoch 1/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 11.1628 - val_loss: 1.5046 - learning_rate: 0.0020\nEpoch 2/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5347 - val_loss: 1.3549 - learning_rate: 0.0020\nEpoch 3/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.3972 - val_loss: 1.6482 - learning_rate: 0.0020\nEpoch 4/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4428 - val_loss: 1.1275 - learning_rate: 0.0020\nEpoch 5/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2212 - val_loss: 1.1091 - learning_rate: 0.0020\nEpoch 6/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2089 - val_loss: 1.1475 - learning_rate: 0.0020\nEpoch 7/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1842 - val_loss: 1.0808 - learning_rate: 0.0020\nEpoch 8/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2060 - val_loss: 1.1169 - learning_rate: 0.0020\nEpoch 9/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1614 - val_loss: 1.1432 - learning_rate: 0.0020\nEpoch 10/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2366 - val_loss: 1.1850 - learning_rate: 0.0020\nEpoch 11/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2730 - val_loss: 1.1092 - learning_rate: 0.0020\nEpoch 12/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1607 - val_loss: 1.0111 - learning_rate: 0.0020\nEpoch 13/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0617 - val_loss: 1.0480 - learning_rate: 0.0020\nEpoch 14/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0932 - val_loss: 1.0100 - learning_rate: 0.0020\nEpoch 15/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0733 - val_loss: 1.0537 - learning_rate: 0.0020\nEpoch 16/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0970 - val_loss: 1.0264 - learning_rate: 0.0020\nEpoch 17/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0735 - val_loss: 0.9796 - learning_rate: 0.0020\nEpoch 18/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0451 - val_loss: 0.9927 - learning_rate: 0.0020\nEpoch 19/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0354 - val_loss: 1.0665 - learning_rate: 0.0020\nEpoch 20/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1162 - val_loss: 1.0887 - learning_rate: 0.0020\nEpoch 21/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1336 - val_loss: 1.0118 - learning_rate: 0.0020\nEpoch 22/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0936 - val_loss: 1.0273 - learning_rate: 0.0020\nEpoch 23/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0773 - val_loss: 0.9735 - learning_rate: 0.0020\nEpoch 24/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0010 - val_loss: 0.9906 - learning_rate: 0.0020\nEpoch 25/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0061 - val_loss: 0.9552 - learning_rate: 0.0020\nEpoch 26/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9717 - val_loss: 0.9878 - learning_rate: 0.0020\nEpoch 27/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9995 - val_loss: 0.9471 - learning_rate: 0.0020\nEpoch 28/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9831 - val_loss: 0.9256 - learning_rate: 0.0020\nEpoch 29/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9721 - val_loss: 0.9376 - learning_rate: 0.0020\nEpoch 30/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9725 - val_loss: 0.9335 - learning_rate: 0.0020\nEpoch 31/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9396 - val_loss: 0.9333 - learning_rate: 0.0020\nEpoch 32/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9607 - val_loss: 0.9324 - learning_rate: 0.0020\nEpoch 33/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9345 - val_loss: 0.9230 - learning_rate: 0.0020\nEpoch 34/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9706 - val_loss: 0.9715 - learning_rate: 0.0020\nEpoch 35/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9477 - val_loss: 0.9797 - learning_rate: 0.0020\nEpoch 36/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0977 - val_loss: 1.0235 - learning_rate: 0.0020\nEpoch 37/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0618 - val_loss: 1.0855 - learning_rate: 0.0020\nEpoch 38/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0341 - val_loss: 0.9872 - learning_rate: 0.0020\nEpoch 39/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9527 - val_loss: 0.9926 - learning_rate: 0.0020\nEpoch 40/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9717 - val_loss: 0.9114 - learning_rate: 0.0020\nEpoch 41/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8867 - val_loss: 0.9053 - learning_rate: 0.0020\nEpoch 42/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8703 - val_loss: 0.8952 - learning_rate: 0.0020\nEpoch 43/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9394 - val_loss: 0.9568 - learning_rate: 0.0020\nEpoch 44/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9520 - val_loss: 0.9125 - learning_rate: 0.0020\nEpoch 45/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8868 - val_loss: 0.8620 - learning_rate: 0.0020\nEpoch 46/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8621 - val_loss: 0.8759 - learning_rate: 0.0020\nEpoch 47/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8551 - val_loss: 0.8880 - learning_rate: 0.0020\nEpoch 48/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8596 - val_loss: 0.9295 - learning_rate: 0.0020\nEpoch 49/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8704 - val_loss: 0.8925 - learning_rate: 0.0020\nEpoch 50/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8809 - val_loss: 0.8837 - learning_rate: 0.0020\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nMAE for Fold-7: 1.505\nMAPE for Fold-7: 0.068\n\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n********** Fold-8 **********\nEpoch 1/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 11.6263 - val_loss: 1.7590 - learning_rate: 0.0020\nEpoch 2/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5276 - val_loss: 1.5063 - learning_rate: 0.0020\nEpoch 3/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3672 - val_loss: 1.4017 - learning_rate: 0.0020\nEpoch 4/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3116 - val_loss: 1.3700 - learning_rate: 0.0020\nEpoch 5/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2897 - val_loss: 1.3609 - learning_rate: 0.0020\nEpoch 6/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2308 - val_loss: 1.4912 - learning_rate: 0.0020\nEpoch 7/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2060 - val_loss: 1.3038 - learning_rate: 0.0020\nEpoch 8/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2182 - val_loss: 1.8237 - learning_rate: 0.0020\nEpoch 9/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2837 - val_loss: 1.1772 - learning_rate: 0.0020\nEpoch 10/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1158 - val_loss: 1.1903 - learning_rate: 0.0020\nEpoch 11/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1200 - val_loss: 1.2281 - learning_rate: 0.0020\nEpoch 12/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0910 - val_loss: 1.1570 - learning_rate: 0.0020\nEpoch 13/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0920 - val_loss: 1.1590 - learning_rate: 0.0020\nEpoch 14/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0966 - val_loss: 1.1299 - learning_rate: 0.0020\nEpoch 15/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0522 - val_loss: 1.1459 - learning_rate: 0.0020\nEpoch 16/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0661 - val_loss: 1.1175 - learning_rate: 0.0020\nEpoch 17/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0443 - val_loss: 1.1967 - learning_rate: 0.0020\nEpoch 18/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0672 - val_loss: 1.1190 - learning_rate: 0.0020\nEpoch 19/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0360 - val_loss: 1.1713 - learning_rate: 0.0020\nEpoch 20/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0223 - val_loss: 1.0963 - learning_rate: 0.0020\nEpoch 21/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9832 - val_loss: 1.1244 - learning_rate: 0.0020\nEpoch 22/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0940 - val_loss: 1.1099 - learning_rate: 0.0020\nEpoch 23/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0513 - val_loss: 1.2234 - learning_rate: 0.0020\nEpoch 24/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1372 - val_loss: 1.1348 - learning_rate: 0.0020\nEpoch 25/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0042 - val_loss: 1.0582 - learning_rate: 0.0020\nEpoch 26/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9594 - val_loss: 1.0602 - learning_rate: 0.0020\nEpoch 27/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9731 - val_loss: 1.1006 - learning_rate: 0.0020\nEpoch 28/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0044 - val_loss: 1.1263 - learning_rate: 0.0020\nEpoch 29/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9961 - val_loss: 1.0649 - learning_rate: 0.0020\nEpoch 30/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9847 - val_loss: 1.2185 - learning_rate: 0.0020\nEpoch 31/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0005 - val_loss: 1.0845 - learning_rate: 0.0020\nEpoch 32/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9688 - val_loss: 1.0396 - learning_rate: 0.0020\nEpoch 33/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9328 - val_loss: 1.0205 - learning_rate: 0.0020\nEpoch 34/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9314 - val_loss: 1.0424 - learning_rate: 0.0020\nEpoch 35/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9465 - val_loss: 1.0832 - learning_rate: 0.0020\nEpoch 36/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.0594 - val_loss: 1.1322 - learning_rate: 0.0020\nEpoch 37/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9680 - val_loss: 1.0393 - learning_rate: 0.0020\nEpoch 38/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9439 - val_loss: 1.0201 - learning_rate: 0.0020\nEpoch 39/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9104 - val_loss: 1.2166 - learning_rate: 0.0020\nEpoch 40/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0418 - val_loss: 1.0159 - learning_rate: 0.0020\nEpoch 41/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9097 - val_loss: 1.0327 - learning_rate: 0.0020\nEpoch 42/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8974 - val_loss: 1.0462 - learning_rate: 0.0020\nEpoch 43/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8734 - val_loss: 1.0330 - learning_rate: 0.0020\nEpoch 44/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8761 - val_loss: 0.9899 - learning_rate: 0.0020\nEpoch 45/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8726 - val_loss: 0.9977 - learning_rate: 0.0020\nEpoch 46/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9050 - val_loss: 1.0471 - learning_rate: 0.0020\nEpoch 47/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9281 - val_loss: 1.0272 - learning_rate: 0.0020\nEpoch 48/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8987 - val_loss: 1.0084 - learning_rate: 0.0020\nEpoch 49/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8539 - val_loss: 1.0230 - learning_rate: 0.0020\nEpoch 50/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8554 - val_loss: 1.1049 - learning_rate: 0.0020\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nMAE for Fold-8: 1.759\nMAPE for Fold-8: 0.073\n\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n********** Fold-9 **********\nEpoch 1/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 11.0649 - val_loss: 1.9030 - learning_rate: 0.0020\nEpoch 2/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6392 - val_loss: 1.6778 - learning_rate: 0.0020\nEpoch 3/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4664 - val_loss: 1.4228 - learning_rate: 0.0020\nEpoch 4/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4278 - val_loss: 1.5613 - learning_rate: 0.0020\nEpoch 5/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3520 - val_loss: 1.4754 - learning_rate: 0.0020\nEpoch 6/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2636 - val_loss: 1.4000 - learning_rate: 0.0020\nEpoch 7/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2192 - val_loss: 1.3420 - learning_rate: 0.0020\nEpoch 8/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2866 - val_loss: 1.3220 - learning_rate: 0.0020\nEpoch 9/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1975 - val_loss: 1.2649 - learning_rate: 0.0020\nEpoch 10/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1710 - val_loss: 1.1820 - learning_rate: 0.0020\nEpoch 11/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1499 - val_loss: 1.1537 - learning_rate: 0.0020\nEpoch 12/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1010 - val_loss: 1.2312 - learning_rate: 0.0020\nEpoch 13/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1155 - val_loss: 1.1162 - learning_rate: 0.0020\nEpoch 14/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0948 - val_loss: 1.1740 - learning_rate: 0.0020\nEpoch 15/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0621 - val_loss: 1.1594 - learning_rate: 0.0020\nEpoch 16/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0701 - val_loss: 1.0742 - learning_rate: 0.0020\nEpoch 17/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0983 - val_loss: 1.2755 - learning_rate: 0.0020\nEpoch 18/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1314 - val_loss: 1.0556 - learning_rate: 0.0020\nEpoch 19/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9917 - val_loss: 1.0461 - learning_rate: 0.0020\nEpoch 20/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0214 - val_loss: 1.0906 - learning_rate: 0.0020\nEpoch 21/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0036 - val_loss: 1.0819 - learning_rate: 0.0020\nEpoch 22/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9890 - val_loss: 1.0797 - learning_rate: 0.0020\nEpoch 23/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0115 - val_loss: 1.1418 - learning_rate: 0.0020\nEpoch 24/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9987 - val_loss: 1.0849 - learning_rate: 0.0020\nEpoch 25/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9742 - val_loss: 1.0590 - learning_rate: 0.0020\nEpoch 26/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9798 - val_loss: 1.0292 - learning_rate: 0.0020\nEpoch 27/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9854 - val_loss: 1.1697 - learning_rate: 0.0020\nEpoch 28/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0082 - val_loss: 1.0295 - learning_rate: 0.0020\nEpoch 29/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9520 - val_loss: 1.0645 - learning_rate: 0.0020\nEpoch 30/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9348 - val_loss: 1.0685 - learning_rate: 0.0020\nEpoch 31/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9293 - val_loss: 1.1388 - learning_rate: 0.0020\nEpoch 32/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9648 - val_loss: 1.1197 - learning_rate: 0.0020\nEpoch 33/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9730 - val_loss: 1.0938 - learning_rate: 0.0020\nEpoch 34/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9606 - val_loss: 1.0878 - learning_rate: 0.0020\nEpoch 35/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8834 - val_loss: 0.9605 - learning_rate: 5.0000e-04\nEpoch 36/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8423 - val_loss: 0.9539 - learning_rate: 5.0000e-04\nEpoch 37/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8362 - val_loss: 0.9489 - learning_rate: 5.0000e-04\nEpoch 38/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8337 - val_loss: 0.9453 - learning_rate: 5.0000e-04\nEpoch 39/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8262 - val_loss: 0.9451 - learning_rate: 5.0000e-04\nEpoch 40/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8216 - val_loss: 0.9433 - learning_rate: 5.0000e-04\nEpoch 41/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8185 - val_loss: 0.9400 - learning_rate: 5.0000e-04\nEpoch 42/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8161 - val_loss: 0.9438 - learning_rate: 5.0000e-04\nEpoch 43/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8142 - val_loss: 0.9389 - learning_rate: 5.0000e-04\nEpoch 44/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8095 - val_loss: 0.9385 - learning_rate: 5.0000e-04\nEpoch 45/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8089 - val_loss: 0.9379 - learning_rate: 5.0000e-04\nEpoch 46/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8069 - val_loss: 0.9328 - learning_rate: 5.0000e-04\nEpoch 47/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8000 - val_loss: 0.9360 - learning_rate: 5.0000e-04\nEpoch 48/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7992 - val_loss: 0.9351 - learning_rate: 5.0000e-04\nEpoch 49/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7965 - val_loss: 0.9301 - learning_rate: 5.0000e-04\nEpoch 50/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7971 - val_loss: 0.9290 - learning_rate: 5.0000e-04\n\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\nMAE for Fold-9: 1.903\nMAPE for Fold-9: 0.075\n\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n********** Fold-10 **********\nEpoch 1/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 10.8193 - val_loss: 1.6680 - learning_rate: 0.0020\nEpoch 2/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6615 - val_loss: 1.6604 - learning_rate: 0.0020\nEpoch 3/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4903 - val_loss: 1.3298 - learning_rate: 0.0020\nEpoch 4/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3434 - val_loss: 1.2939 - learning_rate: 0.0020\nEpoch 5/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2921 - val_loss: 1.2242 - learning_rate: 0.0020\nEpoch 6/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2697 - val_loss: 1.2305 - learning_rate: 0.0020\nEpoch 7/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2652 - val_loss: 1.2205 - learning_rate: 0.0020\nEpoch 8/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3483 - val_loss: 1.1485 - learning_rate: 0.0020\nEpoch 9/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1889 - val_loss: 1.2167 - learning_rate: 0.0020\nEpoch 10/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2284 - val_loss: 1.1071 - learning_rate: 0.0020\nEpoch 11/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0966 - val_loss: 1.1344 - learning_rate: 0.0020\nEpoch 12/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0866 - val_loss: 1.1815 - learning_rate: 0.0020\nEpoch 13/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2566 - val_loss: 1.1466 - learning_rate: 0.0020\nEpoch 14/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1297 - val_loss: 1.1017 - learning_rate: 0.0020\nEpoch 15/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0645 - val_loss: 1.0603 - learning_rate: 0.0020\nEpoch 16/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0288 - val_loss: 1.0360 - learning_rate: 0.0020\nEpoch 17/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0295 - val_loss: 1.0776 - learning_rate: 0.0020\nEpoch 18/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0261 - val_loss: 1.0815 - learning_rate: 0.0020\nEpoch 19/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0051 - val_loss: 1.0594 - learning_rate: 0.0020\nEpoch 20/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0538 - val_loss: 1.0459 - learning_rate: 0.0020\nEpoch 21/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0161 - val_loss: 1.0353 - learning_rate: 0.0020\nEpoch 22/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0226 - val_loss: 1.0754 - learning_rate: 0.0020\nEpoch 23/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0025 - val_loss: 1.0158 - learning_rate: 0.0020\nEpoch 24/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9904 - val_loss: 1.1562 - learning_rate: 0.0020\nEpoch 25/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0259 - val_loss: 1.0210 - learning_rate: 0.0020\nEpoch 26/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9821 - val_loss: 1.0145 - learning_rate: 0.0020\nEpoch 27/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9685 - val_loss: 1.0312 - learning_rate: 0.0020\nEpoch 28/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9566 - val_loss: 1.0077 - learning_rate: 0.0020\nEpoch 29/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9711 - val_loss: 1.0044 - learning_rate: 0.0020\nEpoch 30/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1014 - val_loss: 0.9780 - learning_rate: 0.0020\nEpoch 31/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9393 - val_loss: 0.9985 - learning_rate: 0.0020\nEpoch 32/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9453 - val_loss: 0.9894 - learning_rate: 0.0020\nEpoch 33/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9271 - val_loss: 0.9555 - learning_rate: 0.0020\nEpoch 34/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9131 - val_loss: 0.9891 - learning_rate: 0.0020\nEpoch 35/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9333 - val_loss: 1.0023 - learning_rate: 0.0020\nEpoch 36/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9483 - val_loss: 1.0764 - learning_rate: 0.0020\nEpoch 37/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9241 - val_loss: 1.0192 - learning_rate: 0.0020\nEpoch 38/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8923 - val_loss: 0.9542 - learning_rate: 0.0020\nEpoch 39/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9279 - val_loss: 1.0130 - learning_rate: 0.0020\nEpoch 40/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9005 - val_loss: 0.9854 - learning_rate: 0.0020\nEpoch 41/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8977 - val_loss: 1.0072 - learning_rate: 0.0020\nEpoch 42/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8969 - val_loss: 0.9623 - learning_rate: 0.0020\nEpoch 43/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8815 - val_loss: 0.9430 - learning_rate: 0.0020\nEpoch 44/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9209 - val_loss: 1.2435 - learning_rate: 0.0020\nEpoch 45/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9934 - val_loss: 0.9461 - learning_rate: 0.0020\nEpoch 46/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9184 - val_loss: 0.9351 - learning_rate: 0.0020\nEpoch 47/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8940 - val_loss: 1.0135 - learning_rate: 0.0020\nEpoch 48/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9474 - val_loss: 0.9379 - learning_rate: 0.0020\nEpoch 49/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8561 - val_loss: 0.9203 - learning_rate: 0.0020\nEpoch 50/1000\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9291 - val_loss: 0.9814 - learning_rate: 0.0020\n\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nMAE for Fold-10: 1.668\nMAPE for Fold-10: 0.066\n\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\nOOF MAE: 1.521\nAverage MAE: 1.521+/-0.357\nOOF MAPE: 0.061\nAverage MAPE: 0.061+/-0.015\n","output_type":"stream"}],"execution_count":28},{"id":"8ed759d0","cell_type":"code","source":"set_seed(42)\n\nseed_everything(seed=42)\n\ntf.random.set_seed(42)\n\n\n\nsubmission_keras = pd.DataFrame(data = {'Time': test_df['ID'].values, 'Energy': pred_keras})\n\nprint(submission_keras.head())\n\nsubmission_keras.to_csv('/kaggle/working/submission_keras.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:58:42.401424Z","iopub.execute_input":"2024-11-07T10:58:42.401887Z","iopub.status.idle":"2024-11-07T10:58:42.567931Z","shell.execute_reply.started":"2024-11-07T10:58:42.401839Z","shell.execute_reply":"2024-11-07T10:58:42.566999Z"},"papermill":{"duration":0.960877,"end_time":"2023-10-12T12:21:17.989280","exception":false,"start_time":"2023-10-12T12:21:17.028403","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Seed set to 42\n                        Time     Energy\n0  2023-01-02 10:00:00_B_595  47.183208\n1   2023-01-01 06:00:00_B_21  12.494768\n2  2023-01-03 00:00:00_B_495  14.079122\n3  2023-01-06 09:00:00_B_728  54.874207\n4  2023-01-01 04:00:00_B_298  25.640276\n","output_type":"stream"}],"execution_count":29},{"id":"6e84400f","cell_type":"code","source":"# OOF MAE: 1.521\n# Average MAE: 1.521+/-0.357\n# OOF MAPE: 0.061\n# Average MAPE: 0.061+/-0.015","metadata":{"execution":{"iopub.execute_input":"2023-10-12T12:21:19.562939Z","iopub.status.busy":"2023-10-12T12:21:19.562550Z","iopub.status.idle":"2023-10-12T12:21:19.566980Z","shell.execute_reply":"2023-10-12T12:21:19.565919Z"},"papermill":{"duration":0.831547,"end_time":"2023-10-12T12:21:19.568673","exception":false,"start_time":"2023-10-12T12:21:18.737126","status":"completed"},"tags":[]},"outputs":[],"execution_count":22},{"id":"fd72f782","cell_type":"markdown","source":"### Writing output","metadata":{"papermill":{"duration":0.809726,"end_time":"2023-10-12T12:21:21.134295","exception":false,"start_time":"2023-10-12T12:21:20.324569","status":"completed"},"tags":[]}},{"id":"6dca7f4a","cell_type":"code","source":"set_seed(42)\n\nseed_everything(seed=42)\n\ntf.random.set_seed(42)\n\n\n\nw1_fastai = 0.5\n\nw1_keras = 0.5\n\nnew_pred_ens = train_df['oof_keras']*w1_keras + train_df['oof_fastai']*w1_fastai \n\nnew_pred_ens_hm = (2*train_df['oof_keras']*train_df['oof_fastai'])/(train_df['oof_keras']+train_df['oof_fastai'])\n\nprint(f'OOF MAE ENSEMBLE: {mean_absolute_error(train_df.Energy, new_pred_ens)}')\n\nprint(f'OOF MAPE ENSEMBLE: {mean_absolute_percentage_error(train_df.Energy, new_pred_ens)}')\n\n\n\nprint(f'OOF MAE ENSEMBLE HM: {mean_absolute_error(train_df.Energy, new_pred_ens_hm)}')\n\nprint(f'OOF MAPE ENSEMBLE HM: {mean_absolute_percentage_error(train_df.Energy, new_pred_ens_hm)}')\n\n\n\nnew_test_pred_ens = pred_keras*w1_keras + pred_fastai*w1_fastai\n\nnew_test_pred_ens_hm = (2*pred_keras*pred_fastai)/(pred_keras+pred_fastai)\n\n\n\nsubmission_ensemble = pd.DataFrame(data = {'Time': test_df['ID'].values, 'Energy': new_test_pred_ens})\n\nprint(submission_ensemble.head())\n\nsubmission_ensemble.to_csv('/kaggle/working/submission_ensemble.csv', index=False)\n\n\n\nsubmission_ensemble_hm = pd.DataFrame(data = {'Time': test_df['ID'].values, 'Energy': new_test_pred_ens_hm})\n\nprint(submission_ensemble_hm.head())\n\nsubmission_ensemble_hm.to_csv('/kaggle/working/submission_ensemble_hm.csv', index=False)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T11:00:29.060293Z","iopub.execute_input":"2024-11-07T11:00:29.061180Z","iopub.status.idle":"2024-11-07T11:00:29.420563Z","shell.execute_reply.started":"2024-11-07T11:00:29.061121Z","shell.execute_reply":"2024-11-07T11:00:29.417011Z"},"papermill":{"duration":0.976645,"end_time":"2023-10-12T12:21:22.921664","exception":false,"start_time":"2023-10-12T12:21:21.945019","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Seed set to 42\nOOF MAE ENSEMBLE: 1.1021223229244013\nOOF MAPE ENSEMBLE: 0.04364018391484199\nOOF MAE ENSEMBLE HM: 1.1256204011505098\nOOF MAPE ENSEMBLE HM: 0.04384145729648708\n                        Time     Energy\n0  2023-01-02 10:00:00_B_595  47.069479\n1   2023-01-01 06:00:00_B_21  16.090102\n2  2023-01-03 00:00:00_B_495  13.922225\n3  2023-01-06 09:00:00_B_728  56.340201\n4  2023-01-01 04:00:00_B_298  32.459161\n                        Time     Energy\n0  2023-01-02 10:00:00_B_595  47.069204\n1   2023-01-01 06:00:00_B_21  15.286725\n2  2023-01-03 00:00:00_B_495  13.920457\n3  2023-01-06 09:00:00_B_728  56.302055\n4  2023-01-01 04:00:00_B_298  31.026678\n","output_type":"stream"}],"execution_count":30},{"id":"552eaa4b","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.817359,"end_time":"2023-10-12T12:21:24.504798","exception":false,"start_time":"2023-10-12T12:21:23.687439","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"abb90533","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.753373,"end_time":"2023-10-12T12:21:26.144813","exception":false,"start_time":"2023-10-12T12:21:25.391440","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"47462474","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.757423,"end_time":"2023-10-12T12:21:27.708529","exception":false,"start_time":"2023-10-12T12:21:26.951106","status":"completed"},"tags":[]},"outputs":[],"execution_count":null}]}